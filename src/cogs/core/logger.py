"""
çµ±ä¸€æ—¥èªŒè¨˜éŒ„æ©Ÿåˆ¶
- æä¾›æ¨™æº–åŒ–çš„æ—¥èªŒè¨˜éŒ„å™¨
- æ”¯æ´æ—¥èªŒè¼ªè½‰å’Œæ¸…ç†
- çµ±ä¸€çš„æ—¥èªŒæ ¼å¼
- æ€§èƒ½ç›£æ§å’Œåˆ†æå·¥å…·
- å¥åº·æª¢æŸ¥å’Œå ±å‘Š
"""

import asyncio
import logging
import logging.handlers
import time
from collections import defaultdict, deque
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

import psutil

# å¸¸æ•¸å®šç¾©
MAX_PERFORMANCE_ISSUES = 5
DEFAULT_LOG_ANALYSIS_HOURS = 24
HIGH_CPU_THRESHOLD = 80
CRITICAL_MEMORY_THRESHOLD = 90
HIGH_CPU_RECOMMENDATION_THRESHOLD = 70
HIGH_MEMORY_RECOMMENDATION_THRESHOLD = 80
SLOW_RESPONSE_TIME_THRESHOLD = 1000


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™æ•¸æ“šé¡"""

    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_usage_mb: float
    response_time_ms: float | None = None
    active_connections: int | None = None
    error_rate: float | None = None

class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""

    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.metrics_history: deque = deque(maxlen=max_history)
        self.response_times: deque = deque(maxlen=100)  # æœ€è¿‘100æ¬¡éŸ¿æ‡‰æ™‚é–“
        self.start_time = time.time()

    def record_metrics(
        self,
        response_time_ms: float | None = None,
        active_connections: int | None = None,
        error_rate: float | None = None,
    ):
        """è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™"""
        try:
            # ç²å–ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
            cpu_percent = psutil.cpu_percent(interval=None)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_usage_mb = memory.used / (1024 * 1024)

            # è¨˜éŒ„éŸ¿æ‡‰æ™‚é–“
            if response_time_ms is not None:
                self.response_times.append(response_time_ms)

            # å‰µå»ºæ€§èƒ½æŒ‡æ¨™
            metrics = PerformanceMetrics(
                timestamp=datetime.utcnow(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                memory_usage_mb=memory_usage_mb,
                response_time_ms=response_time_ms,
                active_connections=active_connections,
                error_rate=error_rate,
            )

            self.metrics_history.append(metrics)

        except Exception:
            # æ€§èƒ½ç›£æ§ä¸æ‡‰è©²å½±éŸ¿ä¸»è¦åŠŸèƒ½
            pass

    def get_average_response_time(self) -> float:
        """ç²å–å¹³å‡éŸ¿æ‡‰æ™‚é–“"""
        if not self.response_times:
            return 0.0
        return sum(self.response_times) / len(self.response_times)

    def get_uptime_seconds(self) -> float:
        """ç²å–é‹è¡Œæ™‚é–“(ç§’)"""
        return time.time() - self.start_time

    def get_performance_summary(self) -> dict[str, Any]:
        """ç²å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return {"error": "æ²’æœ‰æ€§èƒ½æ•¸æ“š"}

        recent_metrics = list(self.metrics_history)[-10:]  # æœ€è¿‘10æ¢è¨˜éŒ„

        avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m.memory_percent for m in recent_metrics) / len(recent_metrics)
        avg_memory_mb = sum(m.memory_usage_mb for m in recent_metrics) / len(
            recent_metrics
        )

        return {
            "uptime_seconds": self.get_uptime_seconds(),
            "average_cpu_percent": round(avg_cpu, 2),
            "average_memory_percent": round(avg_memory, 2),
            "average_memory_usage_mb": round(avg_memory_mb, 2),
            "average_response_time_ms": round(self.get_average_response_time(), 2),
            "total_metrics_recorded": len(self.metrics_history),
            "latest_timestamp": recent_metrics[-1].timestamp.isoformat()
            if recent_metrics
            else None,
        }

class LogAnalyzer:
    """æ—¥èªŒåˆ†æå™¨"""

    def __init__(self, logs_dir: Path):
        self.logs_dir = logs_dir
        self.error_patterns = {
            "database": ["database", "connection", "timeout", "lock"],
            "network": ["network", "http", "connection", "timeout"],
            "permission": ["permission", "forbidden", "unauthorized"],
            "memory": ["memory", "outofmemory", "allocation"],
            "discord": ["discord", "gateway", "ratelimit"],
        }

    def analyze_log_file(self, filename: str, hours: int = 24) -> dict[str, Any]:
        """åˆ†ææŒ‡å®šæ—¥èªŒæ–‡ä»¶"""
        log_path = self.logs_dir / filename
        if not log_path.exists():
            return {"error": f"æ—¥èªŒæ–‡ä»¶ {filename} ä¸å­˜åœ¨"}

        datetime.utcnow() - timedelta(hours=hours)

        analysis = {
            "total_lines": 0,
            "error_count": 0,
            "warning_count": 0,
            "info_count": 0,
            "error_categories": defaultdict(int),
            "recent_errors": [],
            "performance_issues": [],
        }

        try:
            with log_path.open(encoding="utf-8") as f:
                for line in f:
                    analysis["total_lines"] += 1

                    # è§£ææ—¥èªŒç­‰ç´š
                    if "ERROR" in line:
                        analysis["error_count"] += 1
                        self._categorize_error(line, analysis["error_categories"])

                        # æ”¶é›†æœ€è¿‘çš„éŒ¯èª¤
                        MAX_RECENT_ERRORS = 10
                        if len(analysis["recent_errors"]) < MAX_RECENT_ERRORS:
                            analysis["recent_errors"].append(line.strip())

                    elif "WARNING" in line:
                        analysis["warning_count"] += 1
                    elif "INFO" in line:
                        analysis["info_count"] += 1

                    # æª¢æ¸¬æ€§èƒ½å•é¡Œ
                    if (
                        any(
                            keyword in line.lower()
                            for keyword in ["slow", "timeout", "memory", "cpu"]
                        )
                        and len(analysis["performance_issues"]) < MAX_PERFORMANCE_ISSUES
                    ):
                        analysis["performance_issues"].append(line.strip())

        except Exception as e:
            analysis["error"] = f"åˆ†æå¤±æ•—: {e!s}"

        return analysis

    def _categorize_error(self, log_line: str, categories: dict[str, int]):
        """å°‡éŒ¯èª¤åˆ†é¡"""
        line_lower = log_line.lower()

        for category, keywords in self.error_patterns.items():
            if any(keyword in line_lower for keyword in keywords):
                categories[category] += 1
                return

        categories["other"] += 1

    def generate_health_report(self) -> dict[str, Any]:
        """ç”Ÿæˆå¥åº·æª¢æŸ¥å ±å‘Š"""
        report = {
            "timestamp": datetime.utcnow().isoformat(),
            "log_files": {},
            "overall_status": "healthy",
            "issues": [],
            "recommendations": [],
        }

        # åˆ†ææ‰€æœ‰æ—¥èªŒæ–‡ä»¶
        for log_file in self.logs_dir.glob("*.log"):
            analysis = self.analyze_log_file(log_file.name, hours=1)
            report["log_files"][log_file.name] = analysis

            # æª¢æŸ¥å¥åº·ç‹€æ³
            ERROR_THRESHOLD = 10
            if analysis.get("error_count", 0) > ERROR_THRESHOLD:  # 1å°æ™‚å…§è¶…é10å€‹éŒ¯èª¤
                report["overall_status"] = "warning"
                report["issues"].append(
                    f"{log_file.name}: éŒ¯èª¤ç‡éé«˜ ({analysis['error_count']} éŒ¯èª¤/å°æ™‚)"
                )

            if analysis.get("performance_issues"):
                report["overall_status"] = "warning"
                report["issues"].append(f"{log_file.name}: æª¢æ¸¬åˆ°æ€§èƒ½å•é¡Œ")

        # ç”Ÿæˆå»ºè­°
        if report["overall_status"] == "warning":
            report["recommendations"].extend(
                ["æª¢æŸ¥éŒ¯èª¤æ—¥èªŒä¸­çš„å…·é«”å•é¡Œ", "ç›£æ§ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³", "è€ƒæ…®é‡å•Ÿç›¸é—œæœå‹™"]
            )

        return report

class DiscordBotLogger:
    """Discord æ©Ÿå™¨äººæ—¥èªŒç®¡ç†å™¨"""

    # æ—¥èªŒæ ¼å¼
    LOG_FORMAT = "%(asctime)s | %(levelname)-8s | %(name)s | %(funcName)s:%(lineno)d | %(message)s"
    SIMPLE_FORMAT = "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s"
    DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

    # æ—¥èªŒé…ç½®
    DEFAULT_MAX_BYTES = 5 * 1024 * 1024  # 5MB
    DEFAULT_BACKUP_COUNT = 3
    DEFAULT_LEVEL = logging.INFO

    def __init__(self, logs_dir: str = "logs"):
        """
        åˆå§‹åŒ–æ—¥èªŒç®¡ç†å™¨

        Args:
            logs_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘
        """
        self.logs_dir = Path(logs_dir)
        self.logs_dir.mkdir(exist_ok=True)

        # å·²å‰µå»ºçš„æ—¥èªŒè¨˜éŒ„å™¨ç·©å­˜
        self._loggers: dict[str, logging.Logger] = {}

        # æ€§èƒ½ç›£æ§å™¨
        self.performance_monitor = PerformanceMonitor()

        # æ—¥èªŒåˆ†æå™¨
        self.log_analyzer = LogAnalyzer(self.logs_dir)

        # è¨­ç½®æ ¹æ—¥èªŒè¨˜éŒ„å™¨
        self._setup_root_logger()

        # å•Ÿå‹•æ€§èƒ½ç›£æ§ä»»å‹™
        self._start_performance_monitoring()

    def _setup_root_logger(self):
        """è¨­ç½®æ ¹æ—¥èªŒè¨˜éŒ„å™¨"""
        root_logger = logging.getLogger()
        root_logger.setLevel(self.DEFAULT_LEVEL)

        # é¿å…é‡è¤‡æ·»åŠ è™•ç†å™¨
        if not root_logger.handlers:
            # æ§åˆ¶å°è™•ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_handler.setFormatter(self._get_formatter(simple=True))
            root_logger.addHandler(console_handler)

    def _get_formatter(self, simple: bool = False) -> logging.Formatter:
        """
        ç²å–æ—¥èªŒæ ¼å¼å™¨

        Args:
            simple: æ˜¯å¦ä½¿ç”¨ç°¡åŒ–æ ¼å¼

        Returns:
            logging.Formatter: æ—¥èªŒæ ¼å¼å™¨
        """
        format_string = self.SIMPLE_FORMAT if simple else self.LOG_FORMAT
        return logging.Formatter(fmt=format_string, datefmt=self.DATE_FORMAT)

    def _create_file_handler(
        self,
        filename: str,
        max_bytes: int | None = None,
        backup_count: int | None = None,
        detailed: bool = True,
    ) -> logging.handlers.RotatingFileHandler:
        """
        å‰µå»ºæ–‡ä»¶è™•ç†å™¨

        Args:
            filename: æ—¥èªŒæ–‡ä»¶å
            max_bytes: æœ€å¤§æ–‡ä»¶å¤§å°
            backup_count: å‚™ä»½æ–‡ä»¶æ•¸é‡
            detailed: æ˜¯å¦ä½¿ç”¨è©³ç´°æ ¼å¼

        Returns:
            logging.handlers.RotatingFileHandler: æ–‡ä»¶è™•ç†å™¨
        """
        file_path = self.logs_dir / filename

        handler = logging.handlers.RotatingFileHandler(
            file_path,
            encoding="utf-8",
            maxBytes=max_bytes or self.DEFAULT_MAX_BYTES,
            backupCount=backup_count or self.DEFAULT_BACKUP_COUNT,
        )

        handler.setFormatter(self._get_formatter(simple=not detailed))
        return handler

    def _start_performance_monitoring(self):
        """å•Ÿå‹•æ€§èƒ½ç›£æ§"""

        async def monitor_loop():
            while True:
                try:
                    self.performance_monitor.record_metrics()
                    await asyncio.sleep(60)  # æ¯åˆ†é˜è¨˜éŒ„ä¸€æ¬¡
                except Exception:
                    await asyncio.sleep(60)

        # åœ¨äº‹ä»¶å¾ªç’°ä¸­å•Ÿå‹•ç›£æ§ä»»å‹™
        try:
            loop = (
                asyncio.get_running_loop()
                if asyncio.get_event_loop_policy().get_event_loop().is_running()
                else asyncio.new_event_loop()
            )
            loop.create_task(monitor_loop())
        except RuntimeError:
            # å¦‚æœæ²’æœ‰äº‹ä»¶å¾ªç’°,è·³éæ€§èƒ½ç›£æ§
            pass

    def get_logger(
        self,
        name: str,
        filename: str | None = None,
        level: int | None = None,
        max_bytes: int | None = None,
        backup_count: int | None = None,
        detailed: bool = True,
    ) -> logging.Logger:
        """
        ç²å–æˆ–å‰µå»ºæ—¥èªŒè¨˜éŒ„å™¨

        Args:
            name: æ—¥èªŒè¨˜éŒ„å™¨åç¨±
            filename: æ—¥èªŒæ–‡ä»¶å(å¦‚æœç‚º None,å‰‡ä½¿ç”¨ name.log)
            level: æ—¥èªŒç­‰ç´š
            max_bytes: æœ€å¤§æ–‡ä»¶å¤§å°
            backup_count: å‚™ä»½æ–‡ä»¶æ•¸é‡
            detailed: æ˜¯å¦ä½¿ç”¨è©³ç´°æ ¼å¼

        Returns:
            logging.Logger: æ—¥èªŒè¨˜éŒ„å™¨
        """
        # å¦‚æœå·²å­˜åœ¨,ç›´æ¥è¿”å›
        if name in self._loggers:
            return self._loggers[name]

        # å‰µå»ºæ–°çš„æ—¥èªŒè¨˜éŒ„å™¨
        logger = logging.getLogger(name)
        logger.setLevel(level or self.DEFAULT_LEVEL)

        # é¿å…é‡è¤‡æ·»åŠ è™•ç†å™¨
        if not logger.handlers:
            # æ–‡ä»¶è™•ç†å™¨
            if filename is None:
                filename = f"{name}.log"

            file_handler = self._create_file_handler(
                filename, max_bytes, backup_count, detailed
            )
            logger.addHandler(file_handler)

        # ç·©å­˜æ—¥èªŒè¨˜éŒ„å™¨
        self._loggers[name] = logger
        return logger

    def create_module_logger(self, module_name: str, **kwargs) -> logging.Logger:
        """
        ç‚ºæ¨¡å¡Šå‰µå»ºå°ˆç”¨æ—¥èªŒè¨˜éŒ„å™¨

        Args:
            module_name: æ¨¡å¡Šåç¨±
            **kwargs: å…¶ä»–åƒæ•¸

        Returns:
            logging.Logger: æ¨¡å¡Šæ—¥èªŒè¨˜éŒ„å™¨
        """
        return self.get_logger(module_name, **kwargs)

    def log_startup(
        self, module_name: str, message: str, duration_ms: float | None = None
    ):
        """
        è¨˜éŒ„æ¨¡å¡Šå•Ÿå‹•ä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            message: å•Ÿå‹•ä¿¡æ¯
            duration_ms: å•Ÿå‹•è€—æ™‚(æ¯«ç§’)
        """
        logger = self.get_logger(module_name)
        if duration_ms is not None:
            logger.info(f"ğŸš€ {message} (è€—æ™‚: {duration_ms:.2f}ms)")
            self.performance_monitor.record_metrics(response_time_ms=duration_ms)
        else:
            logger.info(f"ğŸš€ {message}")

    def log_shutdown(self, module_name: str, message: str):
        """
        è¨˜éŒ„æ¨¡å¡Šé—œé–‰ä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            message: é—œé–‰ä¿¡æ¯
        """
        logger = self.get_logger(module_name)
        logger.info(f"ğŸ›‘ {message}")

    def log_error(
        self,
        module_name: str,
        error: Exception,
        context: str = "",
        tracking_id: str | None = None,
    ):
        """
        è¨˜éŒ„éŒ¯èª¤ä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            error: éŒ¯èª¤å°è±¡
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            tracking_id: è¿½è¹¤ç¢¼
        """
        logger = self.get_logger(module_name)

        error_msg = f"âŒ {context}: {error}" if context else f"âŒ {error}"
        if tracking_id:
            error_msg += f" (è¿½è¹¤ç¢¼: {tracking_id})"

        logger.error(error_msg, exc_info=True)

    def log_warning(self, module_name: str, message: str):
        """
        è¨˜éŒ„è­¦å‘Šä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            message: è­¦å‘Šä¿¡æ¯
        """
        logger = self.get_logger(module_name)
        logger.warning(f"âš ï¸ {message}")

    def log_debug(self, module_name: str, message: str):
        """
        è¨˜éŒ„èª¿è©¦ä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            message: èª¿è©¦ä¿¡æ¯
        """
        logger = self.get_logger(module_name)
        logger.debug(f"ğŸ” {message}")

    def log_performance(
        self,
        module_name: str,
        operation: str,
        duration_ms: float,
        additional_metrics: dict[str, Any | None] | None = None,
    ):
        """
        è¨˜éŒ„æ€§èƒ½ä¿¡æ¯

        Args:
            module_name: æ¨¡å¡Šåç¨±
            operation: æ“ä½œåç¨±
            duration_ms: è€—æ™‚(æ¯«ç§’)
            additional_metrics: é¡å¤–æŒ‡æ¨™
        """
        logger = self.get_logger(module_name)

        perf_msg = f"â±ï¸ {operation} è€—æ™‚: {duration_ms:.2f}ms"
        if additional_metrics:
            perf_msg += f" | é¡å¤–æŒ‡æ¨™: {additional_metrics}"

        # æ ¹æ“šè€—æ™‚åˆ¤æ–·æ—¥èªŒç­‰ç´š
        WARNING_THRESHOLD = 5000  # 5ç§’
        INFO_THRESHOLD = 1000     # 1ç§’
        if duration_ms > WARNING_THRESHOLD:
            logger.warning(perf_msg)
        elif duration_ms > INFO_THRESHOLD:
            logger.info(perf_msg)
        else:
            logger.debug(perf_msg)

        # è¨˜éŒ„åˆ°æ€§èƒ½ç›£æ§
        self.performance_monitor.record_metrics(response_time_ms=duration_ms)

    def cleanup_old_logs(self, days: int = 7):
        """
        æ¸…ç†èˆŠæ—¥èªŒæ–‡ä»¶

        Args:
            days: ä¿ç•™å¤©æ•¸
        """
        cutoff_date = datetime.now() - timedelta(days=days)
        cleaned_count = 0

        for log_file in self.logs_dir.glob("*.log.*"):  # å‚™ä»½æ—¥èªŒæ–‡ä»¶
            try:
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if file_time < cutoff_date:
                    log_file.unlink()
                    cleaned_count += 1
            except Exception as e:
                self.log_error("logger", e, f"æ¸…ç†æ—¥èªŒæ–‡ä»¶ {log_file} å¤±æ•—")

        if cleaned_count > 0:
            self.log_startup("logger", f"æ¸…ç†äº† {cleaned_count} å€‹èˆŠæ—¥èªŒæ–‡ä»¶")

    def get_log_stats(self) -> dict[str, Any]:
        """
        ç²å–æ—¥èªŒçµ±è¨ˆä¿¡æ¯

        Returns:
            Dict[str, Any]: æ—¥èªŒçµ±è¨ˆä¿¡æ¯
        """
        stats = {
            "logs_directory": str(self.logs_dir),
            "active_loggers": len(self._loggers),
            "logger_names": list(self._loggers.keys()),
            "log_files": [],
            "total_size_mb": 0,
            "performance_summary": self.performance_monitor.get_performance_summary(),
        }

        # çµ±è¨ˆæ—¥èªŒæ–‡ä»¶
        for log_file in self.logs_dir.glob("*.log*"):
            try:
                file_size = log_file.stat().st_size
                stats["log_files"].append(
                    {
                        "name": log_file.name,
                        "size_mb": round(file_size / (1024 * 1024), 2),
                        "modified": datetime.fromtimestamp(
                            log_file.stat().st_mtime
                        ).isoformat(),
                    }
                )
                stats["total_size_mb"] += file_size / (1024 * 1024)
            except Exception:
                pass

        stats["total_size_mb"] = round(stats["total_size_mb"], 2)
        return stats

    def analyze_logs(self, hours: int = DEFAULT_LOG_ANALYSIS_HOURS) -> dict[str, Any]:  # noqa: ARG002
        """
        åˆ†ææ—¥èªŒå…§å®¹

        Args:
            hours: åˆ†ææœ€è¿‘å¤šå°‘å°æ™‚çš„æ—¥èªŒ

        Returns:
            Dict[str, Any]: åˆ†æçµæœ
        """
        # TODO: æœªä¾†å¯èƒ½æœƒç”¨åˆ° hours åƒæ•¸ä¾†é™åˆ¶åˆ†ææ™‚é–“ç¯„åœ
        return self.log_analyzer.generate_health_report()

    def get_health_status(self) -> dict[str, Any]:
        """
        ç²å–ç³»çµ±å¥åº·ç‹€æ…‹

        Returns:
            Dict[str, Any]: å¥åº·ç‹€æ…‹å ±å‘Š
        """
        health_report = self.log_analyzer.generate_health_report()
        performance_summary = self.performance_monitor.get_performance_summary()

        # æ•´åˆå¥åº·ç‹€æ…‹
        overall_status = "healthy"

        if health_report.get("overall_status") == "warning":
            overall_status = "warning"

        # æª¢æŸ¥æ€§èƒ½æŒ‡æ¨™
        if performance_summary.get("average_cpu_percent", 0) > HIGH_CPU_THRESHOLD:
            overall_status = "warning"

        if performance_summary.get("average_memory_percent", 0) > CRITICAL_MEMORY_THRESHOLD:
            overall_status = "critical"

        return {
            "overall_status": overall_status,
            "timestamp": datetime.utcnow().isoformat(),
            "log_analysis": health_report,
            "performance": performance_summary,
            "recommendations": self._generate_recommendations(
                health_report, performance_summary
            ),
        }

    def _generate_recommendations(
        self, log_analysis: dict[str, Any], performance: dict[str, Any]
    ) -> list[str]:
        """ç”Ÿæˆç³»çµ±å»ºè­°"""
        recommendations = []

        if performance.get("average_cpu_percent", 0) > HIGH_CPU_RECOMMENDATION_THRESHOLD:
            recommendations.append("CPU ä½¿ç”¨ç‡è¼ƒé«˜,å»ºè­°æª¢æŸ¥æ˜¯å¦æœ‰æ€§èƒ½ç“¶é ¸")

        if performance.get("average_memory_percent", 0) > HIGH_MEMORY_RECOMMENDATION_THRESHOLD:
            recommendations.append("è¨˜æ†¶é«”ä½¿ç”¨ç‡è¼ƒé«˜,å»ºè­°æª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼")

        if performance.get("average_response_time_ms", 0) > SLOW_RESPONSE_TIME_THRESHOLD:
            recommendations.append("éŸ¿æ‡‰æ™‚é–“è¼ƒæ…¢,å»ºè­°å„ªåŒ–è™•ç†é‚è¼¯")

        if log_analysis.get("issues"):
            recommendations.append("æª¢æ¸¬åˆ°æ—¥èªŒç•°å¸¸,è«‹æŸ¥çœ‹è©³ç´°éŒ¯èª¤ä¿¡æ¯")

        if not recommendations:
            recommendations.append("ç³»çµ±é‹è¡Œæ­£å¸¸,ç„¡ç‰¹æ®Šå»ºè­°")

        return recommendations

class LoggerManager:
    """æ—¥èªŒç®¡ç†å™¨ç®¡ç†å™¨"""

    def __init__(self):
        self._logger_manager: DiscordBotLogger | None = None

    def get_logger_manager(self) -> DiscordBotLogger:
        """ç²å–æ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹"""
        if self._logger_manager is None:
            self._logger_manager = DiscordBotLogger()
        return self._logger_manager

# å…¨åŸŸç®¡ç†å™¨å¯¦ä¾‹
_logger_manager_instance = LoggerManager()

def get_logger_manager() -> DiscordBotLogger:
    """
    ç²å–å…¨åŸŸæ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹

    Returns:
        DiscordBotLogger: æ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹
    """
    return _logger_manager_instance.get_logger_manager()

def setup_module_logger(module_name: str, **kwargs) -> logging.Logger:
    """
    ç‚ºæ¨¡å¡Šè¨­ç½®æ—¥èªŒè¨˜éŒ„å™¨çš„ä¾¿æ·å‡½æ•¸

    Args:
        module_name: æ¨¡å¡Šåç¨±
        **kwargs: å…¶ä»–åƒæ•¸

    Returns:
        logging.Logger: æ—¥èªŒè¨˜éŒ„å™¨
    """
    manager = get_logger_manager()
    return manager.create_module_logger(module_name, **kwargs)
