"""
æ´»èºåº¦æ¸¬è©¦ç³»çµ±åŸ·è¡Œå™¨
ç”¨æ–¼é‹è¡Œå®Œæ•´çš„æ´»èºåº¦æ¸¬è©¦ç³»çµ±,ç›´æ¥èª¿ç”¨å¯¦éš›ç¨‹å¼é‚è¼¯é€²è¡Œæ¸¬è©¦
"""

import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Any

# ä½¿ç”¨çµ±ä¸€çš„æ ¸å¿ƒæ¨¡å¡Š
from ...core import create_error_handler, setup_module_logger

# å°å…¥æ¸¬è©¦æ¨¡å¡Š
from .activity_test_module import ActivityTestModule, TestReport
from .logic_apis import LogicAPIError

# è¨­ç½®æ¨¡å¡Šæ—¥èªŒè¨˜éŒ„å™¨
logger = setup_module_logger("activity_test_runner")
error_handler = create_error_handler("activity_test_runner", logger)


class ActivityTestRunner:
    """
    æ´»èºåº¦æ¸¬è©¦ç³»çµ±åŸ·è¡Œå™¨
    è² è²¬é‹è¡Œå®Œæ•´çš„æ´»èºåº¦æ¸¬è©¦ç³»çµ±,ç›´æ¥èª¿ç”¨å¯¦éš›ç¨‹å¼é‚è¼¯é€²è¡Œæ¸¬è©¦
    """

    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦åŸ·è¡Œå™¨"""
        self.logger = logger.getChild("test_runner")
        self.test_module = ActivityTestModule()

        # æ¸¬è©¦çµæœå­˜å„²è·¯å¾‘
        self.results_dir = Path("test_results")
        self.results_dir.mkdir(exist_ok=True)

    async def run_complete_test_suite(self) -> TestReport:
        """
        é‹è¡Œå®Œæ•´çš„æ¸¬è©¦å¥—ä»¶
        åŸ·è¡Œæ‰€æœ‰é¡å‹çš„æ¸¬è©¦,åŒ…æ‹¬åŠŸèƒ½æ¸¬è©¦ã€æ€§èƒ½æ¸¬è©¦ã€éŒ¯èª¤è™•ç†æ¸¬è©¦

        Returns:
            TestReport: å®Œæ•´çš„æ¸¬è©¦å ±å‘Š
        """
        try:
            self.logger.info("é–‹å§‹é‹è¡Œå®Œæ•´çš„æ´»èºåº¦æ¸¬è©¦å¥—ä»¶")
            start_time = time.time()

            # 1. é‹è¡ŒåŸºæœ¬åŠŸèƒ½æ¸¬è©¦
            self.logger.info("åŸ·è¡ŒåŸºæœ¬åŠŸèƒ½æ¸¬è©¦...")
            functional_test_config = {
                "test_types": [
                    "calculation",
                    "rendering",
                    "settings",
                    "panel",
                    "database",
                ],
                "test_count": 5,
                "timeout": 30,
            }

            functional_report = await self.test_module.test_real_logic(
                functional_test_config
            )

            # 2. é‹è¡Œæ€§èƒ½æ¸¬è©¦
            self.logger.info("åŸ·è¡Œæ€§èƒ½æ¸¬è©¦...")
            performance_results = {}

            performance_endpoints = [
                "calculate_activity_score",
                "get_unified_activity_api",
                "integrate_renderer_api",
            ]

            for endpoint in performance_endpoints:
                try:
                    performance_data = (
                        await self.test_module.test_real_logic_response_time(endpoint)
                    )
                    performance_results[endpoint] = performance_data
                except Exception as e:
                    self.logger.error(f"æ€§èƒ½æ¸¬è©¦ {endpoint} å¤±æ•—: {e}")
                    performance_results[endpoint] = {"error": str(e)}

            # 3. é‹è¡ŒéŒ¯èª¤è™•ç†æ¸¬è©¦
            self.logger.info("åŸ·è¡ŒéŒ¯èª¤è™•ç†æ¸¬è©¦...")
            error_scenarios = [
                {
                    "name": "ç„¡æ•ˆçš„è«‹æ±‚é¡å‹",
                    "test_data": {"request_type": "invalid_type"},
                    "expected_error": "æœªçŸ¥çš„è«‹æ±‚é¡å‹",
                },
                {
                    "name": "ç¼ºå°‘å¿…è¦åƒæ•¸",
                    "test_data": {"request_type": "get_activity_score"},
                    "expected_error": "ç¼ºå°‘å¿…è¦å­—æ®µ",
                },
                {
                    "name": "ç„¡æ•ˆçš„æ•¸æ“šæ ¼å¼",
                    "test_data": {
                        "request_type": "calculate_activity_score",
                        "parameters": "invalid",
                    },
                    "expected_error": "å¿…é ˆæ˜¯å­—å…¸æ ¼å¼",
                },
            ]

            try:
                error_handling_results = (
                    await self.test_module.test_real_logic_error_handling(
                        error_scenarios
                    )
                )
            except Exception as e:
                self.logger.error(f"éŒ¯èª¤è™•ç†æ¸¬è©¦å¤±æ•—: {e}")
                error_handling_results = {"error": str(e)}

            # 4. ç”Ÿæˆç¶œåˆæ¸¬è©¦å ±å‘Š
            end_time = time.time()
            total_execution_time = end_time - start_time

            # åˆä½µæ‰€æœ‰æ¸¬è©¦çµæœ
            all_test_results = functional_report.test_results

            # çµ±è¨ˆç¶œåˆçµæœ
            total_tests = functional_report.total_tests
            passed_tests = functional_report.passed_tests
            failed_tests = functional_report.failed_tests
            error_tests = functional_report.error_tests

            # æª¢æŸ¥æ€§èƒ½æ¸¬è©¦çµæœ
            performance_passed = all(
                result.get("passed", False)
                for result in performance_results.values()
                if "passed" in result
            )

            # æª¢æŸ¥éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœ
            error_handling_passed = error_handling_results.get("success_rate", 0) >= 80

            # ç”Ÿæˆç¶œåˆå ±å‘Š
            comprehensive_report = TestReport(
                report_id=f"comprehensive_test_{int(time.time())}",
                timestamp=time.time(),
                total_tests=total_tests,
                passed_tests=passed_tests,
                failed_tests=failed_tests,
                error_tests=error_tests,
                timeout_tests=0,
                total_execution_time=total_execution_time,
                average_execution_time=functional_report.average_execution_time,
                test_results=all_test_results,
                coverage_data=functional_report.coverage_data,
                performance_summary={
                    "performance_results": performance_results,
                    "performance_passed": performance_passed,
                    "error_handling_results": error_handling_results,
                    "error_handling_passed": error_handling_passed,
                },
            )

            # ä¿å­˜æ¸¬è©¦å ±å‘Š
            await self._save_test_report(comprehensive_report)

            self.logger.info(
                f"å®Œæ•´æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ: ç¸½æ™‚é–“ {total_execution_time:.2f}ç§’"
            )
            return comprehensive_report

        except Exception as e:
            self.logger.error(f"é‹è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise LogicAPIError("E3001", f"å®Œæ•´æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå¤±æ•—: {e!s}")

    async def run_functional_tests(self) -> TestReport:
        """
        é‹è¡ŒåŠŸèƒ½æ¸¬è©¦
        æ¸¬è©¦æ´»èºåº¦ç³»çµ±çš„åŸºæœ¬åŠŸèƒ½

        Returns:
            TestReport: åŠŸèƒ½æ¸¬è©¦å ±å‘Š
        """
        try:
            self.logger.info("é–‹å§‹é‹è¡ŒåŠŸèƒ½æ¸¬è©¦")

            test_config = {
                "test_types": [
                    "calculation",
                    "rendering",
                    "settings",
                    "panel",
                    "database",
                ],
                "test_count": 5,
                "timeout": 30,
            }

            test_report = await self.test_module.test_real_logic(test_config)

            # ä¿å­˜åŠŸèƒ½æ¸¬è©¦å ±å‘Š
            await self._save_test_report(test_report, "functional")

            self.logger.info(
                f"åŠŸèƒ½æ¸¬è©¦å®Œæˆ: {test_report.passed_tests}/{test_report.total_tests} é€šé"
            )
            return test_report

        except Exception as e:
            self.logger.error(f"é‹è¡ŒåŠŸèƒ½æ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise LogicAPIError("E3002", f"åŠŸèƒ½æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e!s}")

    async def run_performance_tests(self) -> dict[str, Any]:
        """
        é‹è¡Œæ€§èƒ½æ¸¬è©¦
        æ¸¬è©¦æ´»èºåº¦ç³»çµ±çš„æ€§èƒ½è¡¨ç¾

        Returns:
            Dict[str, Any]: æ€§èƒ½æ¸¬è©¦çµæœ
        """
        try:
            self.logger.info("é–‹å§‹é‹è¡Œæ€§èƒ½æ¸¬è©¦")

            performance_results = {}

            # æ¸¬è©¦å„å€‹ç«¯é»çš„æ€§èƒ½
            endpoints = [
                "calculate_activity_score",
                "get_unified_activity_api",
                "integrate_renderer_api",
                "integrate_settings_api",
                "integrate_panel_api",
            ]

            for endpoint in endpoints:
                try:
                    performance_data = (
                        await self.test_module.test_real_logic_response_time(endpoint)
                    )
                    performance_results[endpoint] = performance_data
                    self.logger.info(f"ç«¯é» {endpoint} æ€§èƒ½æ¸¬è©¦å®Œæˆ")
                except Exception as e:
                    self.logger.error(f"ç«¯é» {endpoint} æ€§èƒ½æ¸¬è©¦å¤±æ•—: {e}")
                    performance_results[endpoint] = {"error": str(e)}

            # ä¿å­˜æ€§èƒ½æ¸¬è©¦çµæœ
            await self._save_performance_results(performance_results)

            # çµ±è¨ˆæ€§èƒ½æ¸¬è©¦çµæœ
            successful_tests = len(
                [r for r in performance_results.values() if "error" not in r]
            )
            total_tests = len(performance_results)

            self.logger.info(f"æ€§èƒ½æ¸¬è©¦å®Œæˆ: {successful_tests}/{total_tests} æˆåŠŸ")
            return performance_results

        except Exception as e:
            self.logger.error(f"é‹è¡Œæ€§èƒ½æ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise LogicAPIError("E3003", f"æ€§èƒ½æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e!s}")

    async def run_error_handling_tests(self) -> dict[str, Any]:
        """
        é‹è¡ŒéŒ¯èª¤è™•ç†æ¸¬è©¦
        æ¸¬è©¦æ´»èºåº¦ç³»çµ±çš„éŒ¯èª¤è™•ç†èƒ½åŠ›

        Returns:
            Dict[str, Any]: éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœ
        """
        try:
            self.logger.info("é–‹å§‹é‹è¡ŒéŒ¯èª¤è™•ç†æ¸¬è©¦")

            # å®šç¾©éŒ¯èª¤æ¸¬è©¦å ´æ™¯
            error_scenarios = [
                {
                    "name": "ç„¡æ•ˆçš„è«‹æ±‚é¡å‹",
                    "test_data": {"request_type": "invalid_type"},
                    "expected_error": "æœªçŸ¥çš„è«‹æ±‚é¡å‹",
                },
                {
                    "name": "ç¼ºå°‘å¿…è¦åƒæ•¸",
                    "test_data": {"request_type": "get_activity_score"},
                    "expected_error": "ç¼ºå°‘å¿…è¦å­—æ®µ",
                },
                {
                    "name": "ç„¡æ•ˆçš„æ•¸æ“šæ ¼å¼",
                    "test_data": {
                        "request_type": "calculate_activity_score",
                        "parameters": "invalid",
                    },
                    "expected_error": "å¿…é ˆæ˜¯å­—å…¸æ ¼å¼",
                },
                {
                    "name": "ç„¡æ•ˆçš„æ´»èºåº¦åˆ†æ•¸",
                    "test_data": {
                        "request_type": "render_activity",
                        "user_name": "æ¸¬è©¦ç”¨æˆ¶",
                        "activity_score": 150,  # è¶…å‡ºç¯„åœ
                    },
                    "expected_error": "æ´»èºåº¦åˆ†æ•¸å¿…é ˆåœ¨0-100ç¯„åœå…§",
                },
                {
                    "name": "ç„¡æ•ˆçš„ç”¨æˆ¶ID",
                    "test_data": {
                        "request_type": "get_activity_score",
                        "guild_id": "invalid",
                        "user_id": "invalid",
                    },
                    "expected_error": "å¿…é ˆæ˜¯æ•¸å­—",
                },
            ]

            error_handling_results = (
                await self.test_module.test_real_logic_error_handling(error_scenarios)
            )

            # ä¿å­˜éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœ
            await self._save_error_handling_results(error_handling_results)

            self.logger.info(
                f"éŒ¯èª¤è™•ç†æ¸¬è©¦å®Œæˆ: {error_handling_results.get('passed_error_tests', 0)}/{error_handling_results.get('total_error_tests', 0)} é€šé"
            )
            return error_handling_results

        except Exception as e:
            self.logger.error(f"é‹è¡ŒéŒ¯èª¤è™•ç†æ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise LogicAPIError("E3004", f"éŒ¯èª¤è™•ç†æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e!s}")

    async def run_coverage_analysis(self) -> dict[str, Any]:
        """
        é‹è¡Œè¦†è“‹ç‡åˆ†æ
        åˆ†ææ¸¬è©¦å°å¯¦éš›ç¨‹å¼é‚è¼¯çš„è¦†è“‹ç‡

        Returns:
            Dict[str, Any]: è¦†è“‹ç‡åˆ†æçµæœ
        """
        try:
            self.logger.info("é–‹å§‹é‹è¡Œè¦†è“‹ç‡åˆ†æ")

            # é‹è¡ŒåŸºæœ¬æ¸¬è©¦ä»¥ç²å–æ¸¬è©¦çµæœ
            test_config = {
                "test_types": [
                    "calculation",
                    "rendering",
                    "settings",
                    "panel",
                    "database",
                ],
                "test_count": 5,
                "timeout": 30,
            }

            test_report = await self.test_module.test_real_logic(test_config)

            # åˆ†æè¦†è“‹ç‡
            coverage_data = await self.test_module.analyze_test_coverage(
                test_report.test_results
            )

            # ä¿å­˜è¦†è“‹ç‡åˆ†æçµæœ
            await self._save_coverage_results(coverage_data)

            self.logger.info(
                f"è¦†è“‹ç‡åˆ†æå®Œæˆ: æ¨¡å¡Šè¦†è“‹ç‡ {coverage_data.get('module_coverage', 0):.1f}%, APIè¦†è“‹ç‡ {coverage_data.get('api_coverage', 0):.1f}%"
            )
            return coverage_data

        except Exception as e:
            self.logger.error(f"é‹è¡Œè¦†è“‹ç‡åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise LogicAPIError("E3005", f"è¦†è“‹ç‡åˆ†æåŸ·è¡Œå¤±æ•—: {e!s}")

    async def _save_test_report(
        self, test_report: TestReport, report_type: str = "comprehensive"
    ):
        """ä¿å­˜æ¸¬è©¦å ±å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{report_type}_test_report_{timestamp}.json"
            filepath = self.results_dir / filename

            # è½‰æ›æ¸¬è©¦å ±å‘Šç‚ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            report_data = {
                "report_id": test_report.report_id,
                "timestamp": test_report.timestamp,
                "total_tests": test_report.total_tests,
                "passed_tests": test_report.passed_tests,
                "failed_tests": test_report.failed_tests,
                "error_tests": test_report.error_tests,
                "timeout_tests": test_report.timeout_tests,
                "total_execution_time": test_report.total_execution_time,
                "average_execution_time": test_report.average_execution_time,
                "coverage_data": test_report.coverage_data,
                "performance_summary": test_report.performance_summary,
                "test_results": [
                    {
                        "test_id": result.test_id,
                        "test_name": result.test_name,
                        "status": result.status.value,
                        "execution_time": result.execution_time,
                        "error_message": result.error_message,
                    }
                    for result in test_report.test_results
                ],
            }

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)

            self.logger.info(f"æ¸¬è©¦å ±å‘Šå·²ä¿å­˜: {filepath}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ¸¬è©¦å ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    async def _save_performance_results(self, performance_results: dict[str, Any]):
        """ä¿å­˜æ€§èƒ½æ¸¬è©¦çµæœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"performance_results_{timestamp}.json"
            filepath = self.results_dir / filename

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(performance_results, f, ensure_ascii=False, indent=2)

            self.logger.info(f"æ€§èƒ½æ¸¬è©¦çµæœå·²ä¿å­˜: {filepath}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ€§èƒ½æ¸¬è©¦çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    async def _save_error_handling_results(
        self, error_handling_results: dict[str, Any]
    ):
        """ä¿å­˜éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"error_handling_results_{timestamp}.json"
            filepath = self.results_dir / filename

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(error_handling_results, f, ensure_ascii=False, indent=2)

            self.logger.info(f"éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœå·²ä¿å­˜: {filepath}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    async def _save_coverage_results(self, coverage_results: dict[str, Any]):
        """ä¿å­˜è¦†è“‹ç‡åˆ†æçµæœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"coverage_results_{timestamp}.json"
            filepath = self.results_dir / filename

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(coverage_results, f, ensure_ascii=False, indent=2)

            self.logger.info(f"è¦†è“‹ç‡åˆ†æçµæœå·²ä¿å­˜: {filepath}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜è¦†è“‹ç‡åˆ†æçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    async def close(self):
        """é—œé–‰æ¸¬è©¦åŸ·è¡Œå™¨,æ¸…ç†è³‡æº"""
        try:
            await self.test_module.close()
            self.logger.info("æ´»èºåº¦æ¸¬è©¦åŸ·è¡Œå™¨å·²é—œé–‰")
        except Exception as e:
            self.logger.error(f"é—œé–‰æ´»èºåº¦æ¸¬è©¦åŸ·è¡Œå™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


# ç•°æ­¥ä¸»å‡½æ•¸,ç”¨æ–¼ç›´æ¥é‹è¡Œæ¸¬è©¦
async def main():
    """ä¸»å‡½æ•¸,ç”¨æ–¼ç›´æ¥é‹è¡Œæ´»èºåº¦æ¸¬è©¦ç³»çµ±"""
    runner = ActivityTestRunner()

    try:
        print("ğŸš€ é–‹å§‹é‹è¡Œ Discord ADR Bot æ´»èºåº¦æ¸¬è©¦ç³»çµ±")
        print("=" * 60)

        # é‹è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶
        print("ğŸ“‹ åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶...")
        comprehensive_report = await runner.run_complete_test_suite()

        print("âœ… æ¸¬è©¦å®Œæˆ!")
        print("ğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
        print(f"   - ç¸½æ¸¬è©¦æ•¸: {comprehensive_report.total_tests}")
        print(f"   - é€šéæ¸¬è©¦: {comprehensive_report.passed_tests}")
        print(f"   - å¤±æ•—æ¸¬è©¦: {comprehensive_report.failed_tests}")
        print(f"   - éŒ¯èª¤æ¸¬è©¦: {comprehensive_report.error_tests}")
        print(f"   - ç¸½åŸ·è¡Œæ™‚é–“: {comprehensive_report.total_execution_time:.2f}ç§’")
        print(f"   - å¹³å‡åŸ·è¡Œæ™‚é–“: {comprehensive_report.average_execution_time:.2f}ç§’")

        if comprehensive_report.coverage_data:
            coverage = comprehensive_report.coverage_data
            print("ğŸ“ˆ è¦†è“‹ç‡åˆ†æ:")
            print(f"   - æ¨¡å¡Šè¦†è“‹ç‡: {coverage.get('module_coverage', 0):.1f}%")
            print(f"   - APIè¦†è“‹ç‡: {coverage.get('api_coverage', 0):.1f}%")

        if comprehensive_report.performance_summary:
            perf_summary = comprehensive_report.performance_summary
            print("âš¡ æ€§èƒ½æ¸¬è©¦:")
            if "performance_results" in perf_summary:
                for endpoint, result in perf_summary["performance_results"].items():
                    if "avg_response_time" in result:
                        print(f"   - {endpoint}: {result['avg_response_time']:.3f}ç§’")

        print("=" * 60)
        print("ğŸ‰ æ´»èºåº¦æ¸¬è©¦ç³»çµ±é‹è¡Œå®Œæˆ!")

    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")

    finally:
        await runner.close()


if __name__ == "__main__":
    # é‹è¡Œæ¸¬è©¦ç³»çµ±
    asyncio.run(main())
