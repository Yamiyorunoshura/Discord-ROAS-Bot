name: Discord Bot CI/CD Pipeline
# Task ID: T7 - 環境與依賴管理系統：CI流程遷移至uv

on:
  push:
    branches: [ main, restore/specs-2.4.1 ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.10'
  TESTING: true

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 25  # 總測試時間限制 25 分鐘
    
    strategy:
      fail-fast: false  # 不要因為一個測試失敗就取消其他
      matrix:
        test-type: [unit, integration, dpytest, docker]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Cache uv dependencies  
      uses: actions/cache@v3
      with:
        path: ~/.cache/uv
        key: ${{ runner.os }}-uv-${{ hashFiles('**/uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-uv-
          
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Set up test environment
      run: |
        mkdir -p logs test_reports tests/dpytest
        export LOG_LEVEL=WARNING
        
    - name: Run unit tests
      if: matrix.test-type == 'unit'
      run: |
        uv run python -m pytest tests/unit/ -v \
          --cov=services --cov=panels --cov=core \
          --cov-report=xml --cov-report=html \
          --junit-xml=test_reports/unit-results.xml \
          -m "unit and not slow"
          
    - name: Run integration tests  
      if: matrix.test-type == 'integration'
      run: |
        uv run python -m pytest tests/integration/ -v \
          --junit-xml=test_reports/integration-results.xml \
          -m "integration and not slow" \
          --timeout=300
          
    - name: Run dpytest Discord tests
      if: matrix.test-type == 'dpytest'
      run: |
        # dpytest Discord測試現在已修復輔助函數問題
        uv run python -m pytest tests/dpytest/ -v \
          --junit-xml=test_reports/dpytest-results.xml \
          -m "dpytest" \
          --timeout=180 \
          --tb=short \
          --disable-warnings
      # 移除continue-on-error，因為問題已修復
      
    - name: Run Docker tests
      if: matrix.test-type == 'docker'
      run: |
        # 設置 Docker 測試環境
        export DOCKER_AVAILABLE=true
        export TESTING=true
        export CI_DOCKER_TEST=true
        export DOCKER_BUILDKIT=1
        
        # 檢查 Docker 可用性
        docker version
        docker system info
        
        # 預先構建測試鏡像以節省時間
        docker build -t roas-bot:test .
        
        # 運行增強的 Docker 測試套件
        uv run python -m pytest tests/docker/ -v \
          --cov=tests.docker --cov=services --cov=panels --cov=core \
          --cov-report=xml:test_reports/docker-coverage.xml \
          --cov-report=json:test_reports/docker-coverage.json \
          --cov-report=html:test_reports/docker-htmlcov \
          --junit-xml=test_reports/docker-results.xml \
          -m "docker" \
          --timeout=600 \
          --tb=short \
          --maxfail=5 \
          --durations=10 \
          --strict-markers \
          -x
        
        # 運行容器基礎功能驗證
        uv run python -m pytest tests/docker/test_container_basics.py -v \
          --junit-xml=test_reports/docker-basics-results.xml \
          --timeout=300
        
        # 運行基礎設施驗證測試
        uv run python tests/docker/validate_infrastructure.py
      
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.test-type }}
        path: |
          test_reports/
          htmlcov/
          coverage.xml
          
    - name: Upload coverage to Codecov (unit tests)
      if: matrix.test-type == 'unit'
      uses: codecov/codecov-action@v3
      with:
        file: coverage.xml
        flags: unittests
        name: codecov-umbrella
        
    - name: Upload Docker test coverage to Codecov
      if: matrix.test-type == 'docker'
      uses: codecov/codecov-action@v3
      with:
        files: test_reports/docker-coverage.xml
        flags: dockertests
        name: codecov-docker
        fail_ci_if_error: false
        verbose: true
        
    - name: Generate enhanced Docker coverage report with mandatory quality gates
      if: matrix.test-type == 'docker'
      run: |
        # 生成詳細的 Docker 測試覆蓋率報告並實施強制品質門檻檢查
        uv run python -c "
        import json
        import xml.etree.ElementTree as ET
        import sys
        from datetime import datetime
        from pathlib import Path
        
        def parse_coverage_xml():
            xml_path = Path('test_reports/docker-coverage.xml')
            if not xml_path.exists():
                return {'error': 'Coverage XML file not found'}
                
            tree = ET.parse(xml_path)
            root = tree.getroot()
            
            line_rate = float(root.get('line-rate', 0)) * 100
            branch_rate = float(root.get('branch-rate', 0)) * 100
            
            # 計算總行數
            total_lines = 0
            covered_lines = 0
            
            for package in root.findall('.//package'):
                for class_elem in package.findall('classes/class'):
                    for line in class_elem.findall('lines/line'):
                        total_lines += 1
                        if int(line.get('hits', '0')) > 0:
                            covered_lines += 1
            
            return {
                'line_coverage': round(line_rate, 2),
                'branch_coverage': round(branch_rate, 2),
                'total_lines': total_lines,
                'covered_lines': covered_lines,
                'overall_coverage': round((line_rate + branch_rate) / 2, 2)
            }
        
        # 強制性品質門檻設定
        MANDATORY_COVERAGE_THRESHOLD = 90.0
        MANDATORY_LINE_COVERAGE_THRESHOLD = 85.0
        MANDATORY_BRANCH_COVERAGE_THRESHOLD = 80.0
        
        coverage_data = parse_coverage_xml()
        
        # 檢查是否有錯誤
        if 'error' in coverage_data:
            print(f'::error title=Coverage Analysis Failed::{coverage_data[\"error\"]}')
            sys.exit(1)
        
        overall_cov = coverage_data.get('overall_coverage', 0)
        line_cov = coverage_data.get('line_coverage', 0)
        branch_cov = coverage_data.get('branch_coverage', 0)
        
        # 生成增強報告
        enhanced_report = {
            'task_id': 'T1',
            'test_type': 'docker',
            'timestamp': datetime.now().isoformat(),
            'coverage_metrics': coverage_data,
            'quality_gates': {
                'minimum_coverage': MANDATORY_COVERAGE_THRESHOLD,
                'minimum_line_coverage': MANDATORY_LINE_COVERAGE_THRESHOLD,
                'minimum_branch_coverage': MANDATORY_BRANCH_COVERAGE_THRESHOLD,
                'actual_coverage': overall_cov,
                'actual_line_coverage': line_cov,
                'actual_branch_coverage': branch_cov,
                'overall_passed': overall_cov >= MANDATORY_COVERAGE_THRESHOLD,
                'line_passed': line_cov >= MANDATORY_LINE_COVERAGE_THRESHOLD,
                'branch_passed': branch_cov >= MANDATORY_BRANCH_COVERAGE_THRESHOLD
            }
        }
        
        # 強制品質門檻檢查
        quality_failures = []
        
        if overall_cov < MANDATORY_COVERAGE_THRESHOLD:
            quality_failures.append(f'整體覆蓋率 {overall_cov}% < {MANDATORY_COVERAGE_THRESHOLD}%')
            
        if line_cov < MANDATORY_LINE_COVERAGE_THRESHOLD:
            quality_failures.append(f'行覆蓋率 {line_cov}% < {MANDATORY_LINE_COVERAGE_THRESHOLD}%')
            
        if branch_cov < MANDATORY_BRANCH_COVERAGE_THRESHOLD:
            quality_failures.append(f'分支覆蓋率 {branch_cov}% < {MANDATORY_BRANCH_COVERAGE_THRESHOLD}%')
        
        # 保存增強報告
        with open('test_reports/docker-coverage-enhanced.json', 'w') as f:
            json.dump(enhanced_report, f, indent=2)
        
        # 輸出詳細覆蓋率資訊
        print(f'📊 覆蓋率詳細報告:')
        print(f'   整體覆蓋率: {overall_cov}% (門檻: {MANDATORY_COVERAGE_THRESHOLD}%)')
        print(f'   行覆蓋率: {line_cov}% (門檻: {MANDATORY_LINE_COVERAGE_THRESHOLD}%)')
        print(f'   分支覆蓋率: {branch_cov}% (門檻: {MANDATORY_BRANCH_COVERAGE_THRESHOLD}%)')
        print(f'   總行數: {coverage_data.get(\"total_lines\", 0)}')
        print(f'   已覆蓋行數: {coverage_data.get(\"covered_lines\", 0)}')
        print(f'   未覆蓋行數: {coverage_data.get(\"total_lines\", 0) - coverage_data.get(\"covered_lines\", 0)}')
        
        # 強制品質門檻執行
        if quality_failures:
            print(f'::error title=MANDATORY QUALITY GATE FAILED::❌ Docker測試覆蓋率未達強制要求！')
            for failure in quality_failures:
                print(f'::error title=Quality Gate Failure::{failure}')
            print(f'::error title=Action Required::必須提升測試覆蓋率才能繼續CI流程')
            
            # 生成修復建議
            print(f'🔧 修復建議:')
            if overall_cov < MANDATORY_COVERAGE_THRESHOLD:
                needed_coverage = MANDATORY_COVERAGE_THRESHOLD - overall_cov
                print(f'   - 需要增加 {needed_coverage:.2f}% 的覆蓋率')
            
            # 記錄品質門檻失敗
            enhanced_report['quality_gates']['failure_timestamp'] = datetime.now().isoformat()
            enhanced_report['quality_gates']['failure_details'] = quality_failures
            
            with open('test_reports/docker-coverage-enhanced.json', 'w') as f:
                json.dump(enhanced_report, f, indent=2)
            
            # 強制失敗CI
            sys.exit(1)
        else:
            print(f'::notice title=Quality Gates PASSED::✅ 所有Docker測試覆蓋率門檻檢查通過！')
            print(f'::notice title=Coverage Excellent::Docker 測試覆蓋率達 {overall_cov}% (≥{MANDATORY_COVERAGE_THRESHOLD}%)')
        "

  random-interaction-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 12  # 隨機測試時間限制 12 分鐘
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Run random interaction tests
      run: |
        # 設置固定種子進行可重現的隨機測試
        uv run python -m pytest tests/random/ -v \
          --junit-xml=test_reports/random-results.xml \
          -m "random_interaction" \
          --timeout=600 \
          --seed=12345 \
          --max-steps=50
      continue-on-error: true
      
    - name: Generate reproduction report
      if: failure()
      run: |
        # 生成失敗重現報告
        uv run python scripts/generate_failure_report.py \
          --test-results test_reports/random-results.xml \
          --output test_reports/reproduction-report.json
        
    - name: Upload random test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: random-test-results
        path: test_reports/

  stability-check:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # 穩定性檢查時間限制 15 分鐘
    needs: test
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Run stability tests (3x repeat)
      run: |
        # 運行3次以檢測flaky測試
        for i in {1..3}; do
          echo "Stability run $i/3"
          uv run python -m pytest tests/dpytest/ tests/random/ \
            --junit-xml=test_reports/stability-run-$i.xml \
            -m "stability or random_interaction" \
            --timeout=300 || true
        done
        
    - name: Analyze stability
      run: |
        uv run python scripts/analyze_stability.py \
          --input-dir test_reports/ \
          --output test_reports/stability-analysis.json
      continue-on-error: true
        
    - name: Upload stability results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: stability-results
        path: test_reports/

  lint-and-format:
    runs-on: ubuntu-latest
    timeout-minutes: 8  # 程式碼檢查時間限制 8 分鐘
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Run Black formatter check
      run: |
        uv run black --check --diff .
        
    - name: Run isort import sorting check
      run: |
        uv run isort --check-only --diff .
        
    - name: Run Flake8 linting
      run: |
        uv run flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        
    - name: Run MyPy type checking
      run: |
        uv run mypy services/ panels/ core/ --ignore-missing-imports
      continue-on-error: true

  security-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # 增加安全掃描時間限制以支援 Docker 掃描
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        uv add safety bandit --no-sync
        
    - name: Run dependency security check
      run: |
        uv run safety check
        
    - name: Run code security analysis
      run: |
        uv run bandit -r services/ panels/ core/ -f json -o security-report.json || true

    - name: Install Trivy for container security scanning
      run: |
        # 安裝 Trivy 容器安全掃描器
        sudo apt-get update
        sudo apt-get install wget apt-transport-https gnupg lsb-release -y
        wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
        echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
        sudo apt-get update
        sudo apt-get install trivy -y
        
    - name: Build Docker image for security scanning
      run: |
        # 構建 Docker 鏡像以進行安全掃描
        docker build -t roas-bot:security-scan . || echo "Docker build failed, will use existing image"
        
    - name: Run comprehensive Docker security scan with Trivy
      run: |
        # 執行全面的 Docker 安全掃描
        echo "::group::Docker Security Scanning with Trivy"
        
        mkdir -p security-reports
        
        # 檢查鏡像是否存在
        if docker image inspect roas-bot:security-scan >/dev/null 2>&1; then
          echo "使用構建的鏡像進行掃描: roas-bot:security-scan"
          IMAGE_NAME="roas-bot:security-scan"
        else
          echo "使用備用鏡像進行掃描: python:3.10"
          IMAGE_NAME="python:3.10"
          docker pull python:3.10 || true
        fi
        
        # Trivy 漏洞掃描 (高嚴重性和關鍵漏洞)
        echo "🔍 執行漏洞掃描..."
        trivy image \
          --format json \
          --output security-reports/trivy-vulnerabilities.json \
          --severity HIGH,CRITICAL \
          --no-progress \
          "$IMAGE_NAME" || echo "漏洞掃描完成，可能包含警告"
          
        # Trivy 設定錯誤掃描
        echo "⚙️ 執行配置錯誤掃描..."
        trivy image \
          --format json \
          --output security-reports/trivy-misconfigurations.json \
          --scanners misconfig \
          --severity HIGH,CRITICAL \
          --no-progress \
          "$IMAGE_NAME" || echo "配置掃描完成，可能包含警告"
        
        # Trivy 秘密掃描
        echo "🔐 執行秘密掃描..."
        trivy image \
          --format json \
          --output security-reports/trivy-secrets.json \
          --scanners secret \
          --no-progress \
          "$IMAGE_NAME" || echo "秘密掃描完成，可能包含警告"
          
        echo "::endgroup::"
        
    - name: Analyze Docker security scan results
      run: |
        # 分析 Docker 安全掃描結果並生成報告
        uv run python -c "
        import json
        import sys
        from pathlib import Path
        from datetime import datetime
        
        security_reports_dir = Path('security-reports')
        
        def analyze_trivy_results():
            results = {
                'vulnerabilities': {'count': 0, 'critical': 0, 'high': 0, 'details': []},
                'misconfigurations': {'count': 0, 'critical': 0, 'high': 0, 'details': []},
                'secrets': {'count': 0, 'details': []},
                'overall_risk_level': 'LOW'
            }
            
            # 分析漏洞報告
            vuln_file = security_reports_dir / 'trivy-vulnerabilities.json'
            if vuln_file.exists():
                try:
                    with open(vuln_file) as f:
                        data = json.load(f)
                    
                    for result in data.get('Results', []):
                        vulnerabilities = result.get('Vulnerabilities', [])
                        for vuln in vulnerabilities:
                            severity = vuln.get('Severity', '').upper()
                            results['vulnerabilities']['count'] += 1
                            
                            if severity == 'CRITICAL':
                                results['vulnerabilities']['critical'] += 1
                            elif severity == 'HIGH':
                                results['vulnerabilities']['high'] += 1
                            
                            results['vulnerabilities']['details'].append({
                                'id': vuln.get('VulnerabilityID'),
                                'severity': severity,
                                'package': vuln.get('PkgName'),
                                'version': vuln.get('InstalledVersion'),
                                'title': vuln.get('Title', '')[:100]
                            })
                except Exception as e:
                    print(f'分析漏洞報告時出錯: {e}')
            
            # 分析配置錯誤報告
            misconfig_file = security_reports_dir / 'trivy-misconfigurations.json'
            if misconfig_file.exists():
                try:
                    with open(misconfig_file) as f:
                        data = json.load(f)
                    
                    for result in data.get('Results', []):
                        misconfigs = result.get('Misconfigurations', [])
                        for misconfig in misconfigs:
                            severity = misconfig.get('Severity', '').upper()
                            results['misconfigurations']['count'] += 1
                            
                            if severity == 'CRITICAL':
                                results['misconfigurations']['critical'] += 1
                            elif severity == 'HIGH':
                                results['misconfigurations']['high'] += 1
                            
                            results['misconfigurations']['details'].append({
                                'id': misconfig.get('ID'),
                                'severity': severity,
                                'title': misconfig.get('Title', '')[:100],
                                'message': misconfig.get('Message', '')[:200]
                            })
                except Exception as e:
                    print(f'分析配置錯誤報告時出錯: {e}')
            
            # 分析秘密掃描報告
            secrets_file = security_reports_dir / 'trivy-secrets.json'
            if secrets_file.exists():
                try:
                    with open(secrets_file) as f:
                        data = json.load(f)
                    
                    for result in data.get('Results', []):
                        secrets = result.get('Secrets', [])
                        for secret in secrets:
                            results['secrets']['count'] += 1
                            results['secrets']['details'].append({
                                'rule_id': secret.get('RuleID'),
                                'category': secret.get('Category'),
                                'severity': secret.get('Severity', '').upper(),
                                'title': secret.get('Title', '')[:100]
                            })
                except Exception as e:
                    print(f'分析秘密掃描報告時出錯: {e}')
            
            # 計算整體風險等級
            total_critical = (results['vulnerabilities']['critical'] + 
                            results['misconfigurations']['critical'])
            total_high = (results['vulnerabilities']['high'] + 
                        results['misconfigurations']['high'])
            secret_count = results['secrets']['count']
            
            if total_critical > 0 or secret_count > 0:
                results['overall_risk_level'] = 'CRITICAL'
            elif total_high > 5:
                results['overall_risk_level'] = 'HIGH'
            elif total_high > 0:
                results['overall_risk_level'] = 'MEDIUM'
            
            return results
        
        # 執行分析
        analysis_results = analyze_trivy_results()
        
        # 生成綜合安全報告
        security_report = {
            'timestamp': datetime.now().isoformat(),
            'scan_type': 'docker_comprehensive',
            'task_id': 'T1',
            'trivy_analysis': analysis_results,
            'risk_assessment': {
                'overall_risk_level': analysis_results['overall_risk_level'],
                'total_vulnerabilities': analysis_results['vulnerabilities']['count'],
                'critical_vulnerabilities': analysis_results['vulnerabilities']['critical'],
                'high_vulnerabilities': analysis_results['vulnerabilities']['high'],
                'total_misconfigurations': analysis_results['misconfigurations']['count'],
                'total_secrets': analysis_results['secrets']['count'],
                'security_score': max(0, 100 - (analysis_results['vulnerabilities']['critical'] * 10) - (analysis_results['vulnerabilities']['high'] * 5) - (analysis_results['secrets']['count'] * 20))
            }
        }
        
        # 保存報告
        with open('security-reports/comprehensive-security-analysis.json', 'w') as f:
            json.dump(security_report, f, indent=2)
        
        # 輸出結果到 GitHub Actions
        risk_level = analysis_results['overall_risk_level']
        total_critical = analysis_results['vulnerabilities']['critical'] + analysis_results['misconfigurations']['critical']
        total_high = analysis_results['vulnerabilities']['high'] + analysis_results['misconfigurations']['high']
        total_secrets = analysis_results['secrets']['count']
        security_score = security_report['risk_assessment']['security_score']
        
        print(f'🛡️ Docker 安全掃描完成')
        print(f'   風險等級: {risk_level}')
        print(f'   安全分數: {security_score}/100')
        print(f'   關鍵漏洞: {total_critical}')
        print(f'   高風險問題: {total_high}')
        print(f'   發現秘密: {total_secrets}')
        
        if risk_level == 'CRITICAL':
            print(f'::error title=CRITICAL Security Issues::發現 {total_critical} 個關鍵安全問題和 {total_secrets} 個秘密洩露')
            print(f'::error title=Action Required::必須修復關鍵安全問題才能部署到生產環境')
            # 注意：這裡不強制失敗 CI，但會產生警告
        elif risk_level == 'HIGH':
            print(f'::warning title=HIGH Security Risk::發現 {total_high} 個高風險安全問題')
            print(f'::warning title=Recommendation::建議在部署前修復高風險問題')
        elif risk_level == 'MEDIUM':
            print(f'::notice title=MEDIUM Security Risk::發現少量安全問題，建議定期檢查')
        else:
            print(f'::notice title=Security Scan PASSED::✅ Docker 安全掃描通過，風險等級較低')
        "
        
    - name: Upload security results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: comprehensive-security-results
        path: |
          security-report.json
          security-reports/

  docker-cross-platform:
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15  # 跨平台測試時間限制 15 分鐘
    needs: test
    if: github.event_name == 'pull_request'
    
    strategy:
      fail-fast: false  # 不要因為一個平台失敗就取消其他
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        include:
          - os: ubuntu-latest
            platform: linux
            docker_available: true
          - os: windows-latest
            platform: windows  
            docker_available: true
          - os: macos-latest
            platform: darwin
            docker_available: true
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
    
    - name: Check Docker availability (Linux/macOS)
      if: runner.os != 'Windows'
      run: |
        docker version || echo "Docker not available"
        docker system info || echo "Docker system info failed"
        
    - name: Check Docker availability (Windows)
      if: runner.os == 'Windows'
      run: |
        docker version
        docker system info
        
    - name: Run cross-platform Docker tests
      run: |
        # 設置跨平台測試環境
        export DOCKER_AVAILABLE=${{ matrix.docker_available }}
        export TESTING=true
        export CI_PLATFORM="${{ matrix.platform }}"
        export CURRENT_PLATFORM="${{ matrix.platform }}"
        
        # 創建測試報告目錄
        mkdir -p test_reports
        
        # 運行跨平台 Docker 測試
        uv run python -m pytest tests/docker/test_cross_platform.py -v \
          --junit-xml=test_reports/cross-platform-${{ matrix.platform }}-results.xml \
          -m "cross_platform" \
          --timeout=600 \
          --tb=short \
          --maxfail=3 \
          --durations=5
      continue-on-error: false
      
    - name: Generate cross-platform compatibility report
      if: always()
      run: |
        # 生成跨平台相容性報告
        uv run python -c "
        import json
        from pathlib import Path
        from datetime import datetime
        
        report = {
            'platform': '${{ matrix.platform }}',
            'os': '${{ matrix.os }}',
            'timestamp': datetime.now().isoformat(),
            'docker_available': '${{ matrix.docker_available }}',
            'test_status': 'completed'
        }
        
        Path('test_reports').mkdir(exist_ok=True)
        with open('test_reports/platform-compatibility-${{ matrix.platform }}.json', 'w') as f:
            json.dump(report, f, indent=2)
        "
        
    - name: Upload cross-platform test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: cross-platform-results-${{ matrix.platform }}
        path: test_reports/

  test-failure-notification:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [test, docker-cross-platform]
    if: always() && (needs.test.result == 'failure' || needs.docker-cross-platform.result == 'failure')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv (fast mode)
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install minimal dependencies for analysis
      run: |
        # 只安裝分析需要的最小依賴
        uv sync --extra dev --no-progress --no-cache --frozen
        
    - name: Download all test artifacts for failure analysis
      uses: actions/download-artifact@v3
      with:
        path: failure-analysis-artifacts
      continue-on-error: true
        
    - name: Comprehensive test failure analysis and notifications
      run: |
        # 執行全面的測試失敗分析和通知
        uv run python -c "
        import sys
        import json
        import xml.etree.ElementTree as ET
        from pathlib import Path
        from datetime import datetime
        from collections import defaultdict
        
        def parse_junit_results(xml_path):
            '''解析 JUnit XML 結果'''
            if not xml_path.exists():
                return None
                
            try:
                tree = ET.parse(xml_path)
                root = tree.getroot()
                
                results = {
                    'total': int(root.get('tests', 0)),
                    'failures': int(root.get('failures', 0)),
                    'errors': int(root.get('errors', 0)),
                    'skipped': int(root.get('skipped', 0)),
                    'time': float(root.get('time', 0)),
                    'failed_cases': []
                }
                
                # 收集失敗的測試案例詳情
                for testcase in root.findall('.//testcase'):
                    failure = testcase.find('failure')
                    error = testcase.find('error')
                    
                    if failure is not None or error is not None:
                        case_info = {
                            'name': testcase.get('name', 'unknown'),
                            'classname': testcase.get('classname', 'unknown'),
                            'time': float(testcase.get('time', 0)),
                            'type': 'failure' if failure is not None else 'error'
                        }
                        
                        if failure is not None:
                            case_info['message'] = failure.get('message', '')
                            case_info['details'] = (failure.text or '')[:500]
                        else:
                            case_info['message'] = error.get('message', '')
                            case_info['details'] = (error.text or '')[:500]
                            
                        results['failed_cases'].append(case_info)
                        
                return results
            except Exception as e:
                print(f'解析 {xml_path} 時發生錯誤: {e}')
                return None
        
        # 分析所有測試結果
        artifact_dir = Path('failure-analysis-artifacts')
        all_results = {}
        failure_summary = defaultdict(list)
        
        # 搜尋所有 JUnit XML 檔案
        for xml_file in artifact_dir.rglob('*-results.xml'):
            test_type = xml_file.stem.replace('-results', '')
            print(f'分析 {test_type} 測試結果: {xml_file}')
            
            results = parse_junit_results(xml_file)
            if results:
                all_results[test_type] = results
                
                if results['failures'] > 0 or results['errors'] > 0:
                    failure_summary[test_type] = results['failed_cases']
        
        # 生成全面的失敗報告
        total_failures = sum(len(cases) for cases in failure_summary.values())
        
        if total_failures > 0:
            print(f'::error title=Critical: {total_failures} Test Failures::在多個測試類型中檢測到 {total_failures} 個測試失敗')
            
            # 按測試類型分類通知
            for test_type, failed_cases in failure_summary.items():
                print(f'::error title={test_type.upper()} Failures::{len(failed_cases)} 個 {test_type} 測試失敗')
                
                # 顯示前 3 個最重要的失敗
                for i, case in enumerate(failed_cases[:3]):
                    short_msg = case['message'][:100] + '...' if len(case['message']) > 100 else case['message']
                    print(f'::error title=Failure {i+1} in {test_type}::{case[\"name\"]} - {short_msg}')
            
            # 生成詳細失敗分析報告
            failure_report = {
                'analysis_timestamp': datetime.now().isoformat(),
                'total_test_failures': total_failures,
                'failure_breakdown': dict(failure_summary),
                'test_statistics': all_results,
                'ci_context': {
                    'workflow_run': '${{ github.run_id }}',
                    'commit_sha': '${{ github.sha }}',
                    'branch': '${{ github.ref }}',
                    'actor': '${{ github.actor }}'
                },
                'recommendations': []
            }
            
            # 添加修復建議
            if 'docker' in failure_summary:
                failure_report['recommendations'].append('檢查 Docker 環境和容器配置')
            if 'unit' in failure_summary:
                failure_report['recommendations'].append('檢查單元測試邏輯和模擬設置')
            if 'integration' in failure_summary:
                failure_report['recommendations'].append('檢查服務整合和依賴項')
            if 'cross-platform' in failure_summary:
                failure_report['recommendations'].append('檢查跨平台相容性問題')
            
            # 保存詳細報告
            with open('comprehensive-failure-report.json', 'w') as f:
                json.dump(failure_report, f, indent=2, ensure_ascii=False)
            
            # 發送摘要通知
            print(f'::warning title=Failure Analysis Complete::已生成詳細失敗分析報告，共 {total_failures} 個失敗')
            
        else:
            print('::notice title=No Test Failures Detected::所有測試執行成功或未檢測到失敗')
        "
        
    - name: Upload comprehensive failure analysis
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: comprehensive-failure-analysis
        path: |
          comprehensive-failure-report.json
          failure-analysis-artifacts/
          
    - name: Notify development team on critical failures
      if: failure()
      run: |
        echo "::error title=Development Team Alert::測試失敗需要立即關注 - 請查看詳細分析報告"
        echo "📋 失敗分析報告已上傳至 artifacts"
        echo "🔧 建議檢查最近的程式碼變更和環境配置"
        echo "⚠️ 在修復前請勿合併此 PR"

  docker-test-notification:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: test
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Download test results
      uses: actions/download-artifact@v3
      with:
        name: test-results-docker
        path: test_reports/
      continue-on-error: true
        
    - name: Process Docker test results and send notifications
      run: |
        # 檢查測試結果檔案
        if [ ! -f test_reports/docker-results.xml ]; then
          echo "::warning title=Missing Docker Test Results::Docker測試結果檔案未找到，可能測試未執行"
          exit 0
        fi
        
        # 運行增強的 CI 整合模組進行測試結果處理和通知
        uv run python -c "
        import sys
        import xml.etree.ElementTree as ET
        from pathlib import Path
        sys.path.append('tests/docker')
        from ci_integration import CIIntegration
        
        ci = CIIntegration()
        
        # 解析測試結果統計
        try:
            tree = ET.parse('test_reports/docker-results.xml')
            root = tree.getroot()
            tests = int(root.get('tests', 0))
            failures = int(root.get('failures', 0))
            errors = int(root.get('errors', 0))
            skipped = int(root.get('skipped', 0))
            
            success_rate = ((tests - failures - errors) / tests * 100) if tests > 0 else 0
            
            print(f'::notice title=Docker Test Statistics::執行 {tests} 個測試，成功率 {success_rate:.1f}%')
            
            if failures > 0 or errors > 0:
                print(f'::error title=Docker Test Failures::{failures} 個失敗，{errors} 個錯誤')
            
            if skipped > 5:  # 超過 5 個測試跳過時警告
                print(f'::warning title=Many Tests Skipped::{skipped} 個測試被跳過，請檢查測試環境')
                
        except Exception as e:
            print(f'::warning title=Cannot Parse Test Results::無法解析測試結果: {e}')
        
        # 執行完整管道
        try:
            success = ci.run_full_test_pipeline()
            
            if not success:
                print('::error title=Docker Test Pipeline Failed::Docker 測試管道執行失敗，請檢查測試結果和覆蓋率')
                sys.exit(1)
            else:
                print('::notice title=Docker Test Pipeline Successful::Docker 測試管道執行成功')
        except Exception as e:
            print(f'::error title=Pipeline Execution Failed::管道執行異常: {e}')
            sys.exit(1)
        "
        
    - name: Upload notification results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: docker-test-notifications
        path: test_reports/

  documentation-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 5  # 文檔驗證時間限制 5 分鐘
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Validate documentation link integrity
      run: |
        # T3任務: 文檔連結有效性檢查
        echo "::group::Documentation Link Validation"
        echo "🔍 開始文檔連結有效性檢查..."
        
        # 設置檢查環境
        export TESTING=true
        export CI_LINK_CHECK=true
        
        # 執行連結檢查 (使用內部連結檢查，跳過外部連結以提升速度)
        uv run python scripts/link_checker.py check docs/ \
          --format json \
          --project-root . \
          2>&1 | tee docs_link_check.log || {
            echo "::error title=Link Check Failed::文檔連結檢查失敗"
            echo "::group::Error Details"
            cat docs_link_check.log
            echo "::endgroup::"
            exit 1
          }
        
        # 檢查連結檢查結果並提供詳細錯誤報告
        if grep -q "❌" docs_link_check.log; then
          echo "::error title=Broken Links Found::發現無效連結，請修復後重新提交"
          echo "::group::Broken Links Details"
          
          # 提取並顯示詳細的無效連結信息
          if grep -q "無效連結詳情" docs_link_check.log; then
            sed -n '/無效連結詳情/,/^$/p' docs_link_check.log | head -20
          else
            grep "❌" docs_link_check.log | head -10
          fi
          
          echo "::endgroup::"
          
          # 提供修復建議
          echo "::group::Link Fix Recommendations"
          echo "📋 修復建議："
          echo "   1. 檢查檔案路徑是否正確存在"
          echo "   2. 確認錨點連結的標題是否準確"
          echo "   3. 檢查相對路徑是否從正確目錄開始"
          echo "   4. 考慮將暫時無效的連結添加到 .linkcheckignore 文件"
          echo "   5. 如需檢查外部連結，請在本地執行：python scripts/link_checker.py check docs/ --external"
          echo "::endgroup::"
          
          # 生成錯誤摘要
          broken_count=$(grep -c "❌" docs_link_check.log || echo "0")
          echo "::error title=Link Check Summary::共發現 $broken_count 個無效連結需要修復"
          
          exit 1
        fi
        
        # 顯示檢查摘要
        if grep -q "✅ 所有連結檢查通過" docs_link_check.log; then
          echo "::notice title=Link Validation PASSED::✅ 所有文檔連結驗證通過"
          
          # 提取檢查統計
          if grep -q "📊 檢查結果摘要:" docs_link_check.log; then
            echo "::group::Link Check Summary"
            sed -n '/📊 檢查結果摘要:/,/^$/p' docs_link_check.log
            echo "::endgroup::"
          fi
        else
          echo "::warning title=Link Check Incomplete::連結檢查可能未完全完成"
        fi
        
        echo "::endgroup::"
        
    - name: Upload documentation validation results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: documentation-validation-results
        path: |
          docs_link_check.log
          docs/reports/

  docker-infrastructure-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: test
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install uv
      uses: astral-sh/setup-uv@v4
      with:
        version: "latest"
        
    - name: Install dependencies with uv
      run: |
        uv sync --extra dev --no-progress
        
    - name: Validate Docker infrastructure setup
      run: |
        # 驗證 Docker 基礎設施配置
        echo "::group::Docker Infrastructure Validation"
        
        # 檢查 Docker 測試檔案結構
        echo "檢查 Docker 測試目錄結構..."
        test -d tests/docker || { echo "::error::tests/docker 目錄不存在"; exit 1; }
        test -f tests/docker/conftest.py || { echo "::error::Docker conftest.py 不存在"; exit 1; }
        test -f tests/docker/ci_integration.py || { echo "::error::CI 整合模組不存在"; exit 1; }
        
        # 檢查 Dockerfile
        test -f Dockerfile || { echo "::error::Dockerfile 不存在"; exit 1; }
        
        # 驗證測試框架配置
        uv run python -c "
        import sys
        sys.path.append('tests/docker')
        try:
            from conftest import DOCKER_TEST_CONFIG, DockerTestFixture
            from ci_integration import CIIntegration, CoverageReporter
            print('✅ Docker 測試模組導入成功')
            print(f'✅ 測試配置驗證: {DOCKER_TEST_CONFIG[\"image_name\"]}')
        except ImportError as e:
            print(f'::error::Docker 測試模組導入失敗: {e}')
            sys.exit(1)
        "
        
        echo "::endgroup::"
        echo "::notice title=Infrastructure Validation::Docker 基礎設施驗證通過"

  build-status:
    runs-on: ubuntu-latest
    needs: [test, lint-and-format, security-scan, docker-test-notification, docker-infrastructure-validation, documentation-validation]
    if: always()
    
    steps:
    - name: Check build status with enhanced quality gates
      run: |
        echo "::group::Build Status Summary with Quality Gates"
        echo "Test: ${{ needs.test.result }}"
        echo "Lint: ${{ needs.lint-and-format.result }}"
        echo "Security (Enhanced with Trivy): ${{ needs.security-scan.result }}"
        echo "Docker Notification: ${{ needs.docker-test-notification.result }}"
        echo "Docker Infrastructure: ${{ needs.docker-infrastructure-validation.result }}"
        echo "Documentation Validation: ${{ needs.documentation-validation.result }}"
        echo "::endgroup::"
        
        # 檢查核心構建階段
        CORE_SUCCESS=true
        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "::error title=Test Stage Failed::測試階段失敗"
          CORE_SUCCESS=false
        fi
        
        if [[ "${{ needs.lint-and-format.result }}" != "success" ]]; then
          echo "::error title=Lint Stage Failed::程式碼檢查階段失敗"
          CORE_SUCCESS=false
        fi
        
        if [[ "${{ needs.security-scan.result }}" != "success" ]]; then
          echo "::warning title=Security Scan Issues::安全掃描階段出現問題，請檢查安全報告"
          # 不設為失敗，但記錄警告
        fi
        
        if [[ "${{ needs.docker-test-notification.result }}" != "success" ]]; then
          echo "::error title=Docker Test Notification Failed::Docker測試通知階段失敗"
          CORE_SUCCESS=false
        fi
        
        if [[ "${{ needs.docker-infrastructure-validation.result }}" != "success" ]]; then
          echo "::error title=Docker Infrastructure Validation Failed::Docker基礎設施驗證失敗"
          CORE_SUCCESS=false
        fi
        
        if [[ "${{ needs.documentation-validation.result }}" != "success" ]]; then
          echo "::error title=Documentation Validation Failed::文檔連結驗證失敗"
          CORE_SUCCESS=false
        fi
        
        # 輸出最終結果
        if [[ "$CORE_SUCCESS" == "true" ]]; then
          echo "::notice title=Build Successful with Enhanced Quality Gates::✅ 所有關鍵構建階段成功完成"
          echo "✅ Build passed - All critical stages completed successfully"
          
          # 生成增強的構建摘要
          echo "::group::Enhanced Build Summary"
          echo "🔬 測試執行: ✅ 成功 (包含強制覆蓋率檢查)"
          echo "🔍 程式碼檢查: ✅ 成功" 
          echo "🛡️ 增強安全掃描: 🔄 完成 (包含Trivy容器掃描)"
          echo "🐳 Docker 測試: ✅ 成功 (包含品質門檻驗證)"
          echo "🏗️ 基礎設施驗證: ✅ 成功"
          echo "📚 文檔連結驗證: ✅ 成功 (T3任務整合)"
          echo "📊 品質門檻: 🚀 已實施強制性檢查機制"
          echo "🔐 安全防護: 🔒 已整合多層容器安全掃描"
          echo "::endgroup::"
          
          # 輸出基礎設施修復摘要
          echo "::group::Infrastructure Enhancement Summary (T1 & T3 Tasks)"
          echo "✅ 強制性品質門檻檢查 - 已實施90%覆蓋率門檻"
          echo "✅ Trivy容器安全掃描 - 已整合漏洞/配置/秘密掃描"
          echo "✅ CI/CD管道優化 - 已實施自動品質驗證"
          echo "✅ 測試基礎設施強化 - Docker測試框架持續優化"
          echo "✅ 文檔品質保證 - 已整合連結有效性自動檢查"
          echo "✅ 文檔CI整合 - T3任務基礎設施層完成"
          echo "::endgroup::"
          
          exit 0
        else
          echo "::error title=Build Failed with Quality Issues::❌ 關鍵構建階段失敗 - 請檢查失敗的階段"
          echo "❌ Build failed - Check failed stages above"
          echo "🚨 注意：強制品質門檻現已生效，必須修復所有關鍵問題"
          exit 1
        fi