#!/usr/bin/env python3
"""
Discord ADR Bot å“è³ªæ”¹é€²å·¥å…·åŒ…
æ”¯æ´PRD-1.64.1-optimizedçš„åŸ·è¡Œ
"""

import json
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path


class QualityImprovementToolkit:
    """å“è³ªæ”¹é€²å·¥å…·åŒ…"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.reports_dir = self.project_root / "reports"
        self.reports_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–å ±å‘Š
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "stages": {},
            "metrics": {},
            "issues": [],
        }

    def log_progress(self, stage: str, task: str, status: str = "completed"):
        """è¨˜éŒ„é€²åº¦"""
        if stage not in self.report["stages"]:
            self.report["stages"][stage] = {}

        self.report["stages"][stage][task] = {
            "status": status,
            "timestamp": datetime.now().isoformat(),
        }

        print(f"[{datetime.now().strftime('%H:%M:%S')}] {stage}: {task} - {status}")

    def run_security_scan(self) -> dict:
        """åŸ·è¡Œå®‰å…¨æŽƒæ"""
        print("ðŸ” åŸ·è¡Œå®‰å…¨æŽƒæ...")

        try:
            # åŸ·è¡ŒBanditæŽƒæ
            result = subprocess.run(
                [
                    "bandit",
                    "-r",
                    "cogs/",
                    "-f",
                    "json",
                    "-o",
                    "reports/security_scan.json",
                ],
                check=False,
                capture_output=True,
                text=True,
            )

            if result.returncode == 0:
                with open("reports/security_scan.json") as f:
                    security_data = json.load(f)

                high_risk = len(
                    [
                        issue
                        for issue in security_data.get("results", [])
                        if issue.get("issue_severity") == "HIGH"
                    ]
                )
                medium_risk = len(
                    [
                        issue
                        for issue in security_data.get("results", [])
                        if issue.get("issue_severity") == "MEDIUM"
                    ]
                )
                low_risk = len(
                    [
                        issue
                        for issue in security_data.get("results", [])
                        if issue.get("issue_severity") == "LOW"
                    ]
                )

                self.report["metrics"]["security"] = {
                    "high_risk": high_risk,
                    "medium_risk": medium_risk,
                    "low_risk": low_risk,
                    "total": high_risk + medium_risk + low_risk,
                }

                self.log_progress("security", "bandit_scan")
                return self.report["metrics"]["security"]
            else:
                self.report["issues"].append(f"å®‰å…¨æŽƒæå¤±æ•—: {result.stderr}")
                return {"error": "å®‰å…¨æŽƒæå¤±æ•—"}

        except FileNotFoundError:
            print("âš ï¸  Banditæœªå®‰è£,è«‹åŸ·è¡Œ: pip install bandit")
            return {"error": "Banditæœªå®‰è£"}

    def run_type_check(self) -> dict:
        """åŸ·è¡Œé¡žåž‹æª¢æŸ¥"""
        print("ðŸ” åŸ·è¡Œé¡žåž‹æª¢æŸ¥...")

        try:
            result = subprocess.run(
                ["mypy", "cogs/", "--strict"],
                check=False,
                capture_output=True,
                text=True,
            )

            # åˆ†æžMyPyè¼¸å‡º
            error_lines = [
                line
                for line in result.stdout.split("\n")
                if "error:" in line and "cogs/" in line
            ]

            # çµ±è¨ˆéŒ¯èª¤é¡žåž‹
            error_types = {}
            for line in error_lines:
                if "Union" in line:
                    error_types["union"] = error_types.get("union", 0) + 1
                elif "type annotation" in line:
                    error_types["annotation"] = error_types.get("annotation", 0) + 1
                elif "incompatible" in line:
                    error_types["incompatible"] = error_types.get("incompatible", 0) + 1
                else:
                    error_types["other"] = error_types.get("other", 0) + 1

            self.report["metrics"]["type_check"] = {
                "total_errors": len(error_lines),
                "error_types": error_types,
                "files_with_errors": len(
                    set(line.split(":")[0] for line in error_lines)
                ),
            }

            self.log_progress("type_check", "mypy_analysis")
            return self.report["metrics"]["type_check"]

        except FileNotFoundError:
            print("âš ï¸  MyPyæœªå®‰è£,è«‹åŸ·è¡Œ: pip install mypy")
            return {"error": "MyPyæœªå®‰è£"}

    def run_test_coverage(self) -> dict:
        """åŸ·è¡Œæ¸¬è©¦è¦†è“‹çŽ‡æª¢æŸ¥"""
        print("ðŸ” åŸ·è¡Œæ¸¬è©¦è¦†è“‹çŽ‡æª¢æŸ¥...")

        try:
            result = subprocess.run(
                [
                    "pytest",
                    "--cov=cogs",
                    "--cov-report=json",
                    "--cov-report=term-missing",
                ],
                check=False,
                capture_output=True,
                text=True,
            )

            if os.path.exists("coverage.json"):
                with open("coverage.json") as f:
                    coverage_data = json.load(f)

                total_coverage = coverage_data["totals"]["percent_covered"]
                missing_lines = coverage_data["totals"]["missing_lines"]

                self.report["metrics"]["test_coverage"] = {
                    "total_coverage": total_coverage,
                    "missing_lines": missing_lines,
                    "files_covered": len(coverage_data["files"]),
                }

                self.log_progress("test_coverage", "pytest_coverage")
                return self.report["metrics"]["test_coverage"]
            else:
                return {"error": "coverage.jsonæœªç”Ÿæˆ"}

        except FileNotFoundError:
            print("âš ï¸  pytestæˆ–pytest-covæœªå®‰è£")
            return {"error": "pytestå·¥å…·æœªå®‰è£"}

    def fix_md5_usage(self) -> int:
        """è‡ªå‹•ä¿®å¾©MD5ä½¿ç”¨"""
        print("ðŸ”§ ä¿®å¾©MD5ä½¿ç”¨...")

        fixed_count = 0
        md5_pattern = re.compile(r"hashlib\.md5\(([^)]+)\)")

        for py_file in self.project_root.glob("cogs/**/*.py"):
            try:
                with open(py_file, encoding="utf-8") as f:
                    content = f.read()

                if "hashlib.md5" in content:
                    # æ›¿æ›MD5ç‚ºSHA256
                    new_content = md5_pattern.sub(r"hashlib.sha256(\1)", content)

                    # ç¢ºä¿å°Žå…¥äº†hashlib
                    if (
                        "import hashlib" not in new_content
                        and "from hashlib import" not in new_content
                    ):
                        new_content = "import hashlib\n" + new_content

                    with open(py_file, "w", encoding="utf-8") as f:
                        f.write(new_content)

                    fixed_count += 1
                    print(f"  ä¿®å¾©: {py_file}")

            except Exception as e:
                self.report["issues"].append(f"ä¿®å¾©{py_file}æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        self.log_progress("security", "md5_fix", f"ä¿®å¾©{fixed_count}å€‹æª”æ¡ˆ")
        return fixed_count

    def fix_sql_injection(self) -> int:
        """ä¿®å¾©SQLæ³¨å…¥é¢¨éšª"""
        print("ðŸ”§ ä¿®å¾©SQLæ³¨å…¥é¢¨éšª...")

        fixed_count = 0
        # å¸¸è¦‹çš„SQLæ³¨å…¥æ¨¡å¼
        patterns = [
            (r'f"SELECT.*?{.*?}"', "ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢"),
            (r'f"INSERT.*?{.*?}"', "ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢"),
            (r'f"UPDATE.*?{.*?}"', "ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢"),
            (r'f"DELETE.*?{.*?}"', "ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢"),
        ]

        for py_file in self.project_root.glob("cogs/**/database/*.py"):
            try:
                with open(py_file, encoding="utf-8") as f:
                    content = f.read()

                for pattern, suggestion in patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        self.report["issues"].append(
                            f"SQLæ³¨å…¥é¢¨éšª in {py_file}: {suggestion}"
                        )
                        fixed_count += len(matches)

            except Exception as e:
                self.report["issues"].append(f"æª¢æŸ¥{py_file}æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        self.log_progress("security", "sql_injection_check", f"ç™¼ç¾{fixed_count}å€‹é¢¨éšª")
        return fixed_count

    def create_test_fixtures(self):
        """å‰µå»ºæ¸¬è©¦å¤¾å…·"""
        print("ðŸ”§ å‰µå»ºæ¸¬è©¦å¤¾å…·...")

        fixtures_dir = self.project_root / "tests" / "fixtures"
        fixtures_dir.mkdir(parents=True, exist_ok=True)

        # Discord mocks
        discord_mocks = '''
import pytest
from unittest.mock import AsyncMock, MagicMock
import discord

@pytest.fixture
def mock_bot():
    """æ¨¡æ“¬Discord Bot"""
    bot = MagicMock()
    bot.user = MagicMock()
    bot.user.id = 123456789
    bot.user.name = "TestBot"
    bot.get_guild = MagicMock()
    bot.guilds = []
    return bot

@pytest.fixture
def mock_guild():
    """æ¨¡æ“¬Discord Guild"""
    guild = MagicMock()
    guild.id = 987654321
    guild.name = "Test Guild"
    guild.members = []
    guild.channels = []
    return guild

@pytest.fixture
def mock_channel():
    """æ¨¡æ“¬Discord Channel"""
    channel = MagicMock()
    channel.id = 111222333
    channel.name = "test-channel"
    channel.send = AsyncMock()
    return channel

@pytest.fixture
def mock_member():
    """æ¨¡æ“¬Discord Member"""
    member = MagicMock()
    member.id = 444555666
    member.name = "TestUser"
    member.display_name = "Test User"
    member.avatar = None
    return member

@pytest.fixture
def mock_database():
    """æ¨¡æ“¬è³‡æ–™åº«"""
    db = AsyncMock()
    db.fetch_one = AsyncMock()
    db.fetch_all = AsyncMock()
    db.execute = AsyncMock()
    db.executemany = AsyncMock()
    return db
'''

        with open(fixtures_dir / "discord_mocks.py", "w") as f:
            f.write(discord_mocks)

        self.log_progress("test_infrastructure", "create_fixtures")

    def setup_pytest_config(self):
        """è¨­ç½®pytesté…ç½®"""
        print("ðŸ”§ è¨­ç½®pytesté…ç½®...")

        pytest_config = """
[tool.pytest.ini_options]
asyncio_mode = "auto"
timeout = 30
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "--cov=cogs --cov-report=html --cov-report=term-missing --cov-fail-under=70"
markers = [
    "unit: å–®å…ƒæ¸¬è©¦",
    "integration: æ•´åˆæ¸¬è©¦", 
    "slow: æ…¢é€Ÿæ¸¬è©¦",
    "security: å®‰å…¨æ¸¬è©¦"
]
"""

        # æª¢æŸ¥æ˜¯å¦å·²æœ‰pyproject.toml
        pyproject_path = self.project_root / "pyproject.toml"
        if pyproject_path.exists():
            with open(pyproject_path) as f:
                content = f.read()

            if "[tool.pytest.ini_options]" not in content:
                with open(pyproject_path, "a") as f:
                    f.write("\n" + pytest_config)
        else:
            with open(pyproject_path, "w") as f:
                f.write(pytest_config)

        self.log_progress("test_infrastructure", "setup_pytest")

    def generate_daily_report(self, stage: str) -> str:
        """ç”Ÿæˆæ¯æ—¥å ±å‘Š"""
        report_path = (
            self.reports_dir
            / f"daily_report_{stage}_{datetime.now().strftime('%Y%m%d')}.json"
        )

        with open(report_path, "w") as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)

        # ç”Ÿæˆå¯è®€æ€§å ±å‘Š
        readable_report = f"""
# æ¯æ—¥å“è³ªæ”¹é€²å ±å‘Š - {stage}
ç”Ÿæˆæ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## éšŽæ®µé€²åº¦
"""

        for stage_name, tasks in self.report["stages"].items():
            readable_report += f"\n### {stage_name}\n"
            for task, info in tasks.items():
                status_emoji = "âœ…" if info["status"] == "completed" else "ðŸ”„"
                readable_report += f"- {status_emoji} {task}: {info['status']}\n"

        if self.report["metrics"]:
            readable_report += "\n## å“è³ªæŒ‡æ¨™\n"
            for metric_name, values in self.report["metrics"].items():
                readable_report += f"\n### {metric_name}\n"
                for key, value in values.items():
                    readable_report += f"- {key}: {value}\n"

        if self.report["issues"]:
            readable_report += "\n## ç™¼ç¾å•é¡Œ\n"
            for issue in self.report["issues"]:
                readable_report += f"- âš ï¸ {issue}\n"

        readable_path = (
            self.reports_dir
            / f"daily_report_{stage}_{datetime.now().strftime('%Y%m%d')}.md"
        )
        with open(readable_path, "w", encoding="utf-8") as f:
            f.write(readable_report)

        return str(readable_path)

    def run_stage_1_security_fixes(self):
        """åŸ·è¡ŒéšŽæ®µ1:å®‰å…¨ä¿®å¾©"""
        print("ðŸš€ é–‹å§‹éšŽæ®µ1:å®‰å…¨ä¿®å¾©")

        # å®‰å…¨æŽƒæ
        security_metrics = self.run_security_scan()

        # ä¿®å¾©MD5ä½¿ç”¨
        md5_fixed = self.fix_md5_usage()

        # æª¢æŸ¥SQLæ³¨å…¥
        sql_risks = self.fix_sql_injection()

        # ç”Ÿæˆå ±å‘Š
        report_path = self.generate_daily_report("stage1_security")
        print(f"ðŸ“Š éšŽæ®µ1å ±å‘Šå·²ç”Ÿæˆ: {report_path}")

        return {
            "security_metrics": security_metrics,
            "md5_fixed": md5_fixed,
            "sql_risks": sql_risks,
            "report_path": report_path,
        }

    def run_stage_2_type_fixes(self):
        """åŸ·è¡ŒéšŽæ®µ2:é¡žåž‹ä¿®å¾©"""
        print("ðŸš€ é–‹å§‹éšŽæ®µ2:é¡žåž‹ä¿®å¾©")

        # é¡žåž‹æª¢æŸ¥
        type_metrics = self.run_type_check()

        # ç”Ÿæˆå ±å‘Š
        report_path = self.generate_daily_report("stage2_types")
        print(f"ðŸ“Š éšŽæ®µ2å ±å‘Šå·²ç”Ÿæˆ: {report_path}")

        return {"type_metrics": type_metrics, "report_path": report_path}

    def run_stage_3_test_infrastructure(self):
        """åŸ·è¡ŒéšŽæ®µ3:æ¸¬è©¦åŸºç¤Žè¨­æ–½"""
        print("ðŸš€ é–‹å§‹éšŽæ®µ3:æ¸¬è©¦åŸºç¤Žè¨­æ–½")

        # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
        self.setup_pytest_config()

        # å‰µå»ºæ¸¬è©¦å¤¾å…·
        self.create_test_fixtures()

        # åŸ·è¡Œæ¸¬è©¦è¦†è“‹çŽ‡
        coverage_metrics = self.run_test_coverage()

        # ç”Ÿæˆå ±å‘Š
        report_path = self.generate_daily_report("stage3_tests")
        print(f"ðŸ“Š éšŽæ®µ3å ±å‘Šå·²ç”Ÿæˆ: {report_path}")

        return {"coverage_metrics": coverage_metrics, "report_path": report_path}

    def run_full_assessment(self):
        """åŸ·è¡Œå®Œæ•´è©•ä¼°"""
        print("ðŸ” åŸ·è¡Œå®Œæ•´å“è³ªè©•ä¼°...")

        # åŸ·è¡Œæ‰€æœ‰æª¢æŸ¥
        security_metrics = self.run_security_scan()
        type_metrics = self.run_type_check()
        coverage_metrics = self.run_test_coverage()

        # è¨ˆç®—æ•´é«”åˆ†æ•¸
        security_score = max(
            0,
            100
            - (
                security_metrics.get("high_risk", 0) * 10
                + security_metrics.get("medium_risk", 0) * 5
                + security_metrics.get("low_risk", 0) * 2
            ),
        )

        type_score = max(0, 100 - type_metrics.get("total_errors", 0) * 1.5)
        coverage_score = coverage_metrics.get("total_coverage", 0)

        overall_score = (security_score + type_score + coverage_score) / 3

        self.report["metrics"]["overall"] = {
            "security_score": security_score,
            "type_score": type_score,
            "coverage_score": coverage_score,
            "overall_score": overall_score,
            "grade": self.get_grade(overall_score),
        }

        # ç”Ÿæˆå®Œæ•´å ±å‘Š
        report_path = self.generate_daily_report("full_assessment")
        print(f"ðŸ“Š å®Œæ•´è©•ä¼°å ±å‘Šå·²ç”Ÿæˆ: {report_path}")

        return self.report["metrics"]["overall"]

    def get_grade(self, score: float) -> str:
        """æ ¹æ“šåˆ†æ•¸è¨ˆç®—ç­‰ç´š"""
        if score >= 90:
            return "A"
        elif score >= 85:
            return "A-"
        elif score >= 80:
            return "B+"
        elif score >= 75:
            return "B"
        elif score >= 70:
            return "B-"
        elif score >= 65:
            return "C+"
        elif score >= 60:
            return "C"
        else:
            return "D"


def main():
    """ä¸»å‡½æ•¸"""
    toolkit = QualityImprovementToolkit()

    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python quality_improvement_toolkit.py assessment  # å®Œæ•´è©•ä¼°")
        print("  python quality_improvement_toolkit.py stage1     # éšŽæ®µ1:å®‰å…¨ä¿®å¾©")
        print("  python quality_improvement_toolkit.py stage2     # éšŽæ®µ2:é¡žåž‹ä¿®å¾©")
        print(
            "  python quality_improvement_toolkit.py stage3     # éšŽæ®µ3:æ¸¬è©¦åŸºç¤Žè¨­æ–½"
        )
        return

    command = sys.argv[1]

    if command == "assessment":
        result = toolkit.run_full_assessment()
        print(
            f"\nðŸŽ¯ æ•´é«”å“è³ªè©•åˆ†: {result['overall_score']:.1f}/100 ({result['grade']})"
        )

    elif command == "stage1":
        result = toolkit.run_stage_1_security_fixes()
        print(f"\nâœ… éšŽæ®µ1å®Œæˆ - ä¿®å¾©äº† {result['md5_fixed']} å€‹MD5ä½¿ç”¨")

    elif command == "stage2":
        result = toolkit.run_stage_2_type_fixes()
        print(
            f"\nâœ… éšŽæ®µ2å®Œæˆ - ç™¼ç¾ {result['type_metrics'].get('total_errors', 0)} å€‹é¡žåž‹éŒ¯èª¤"
        )

    elif command == "stage3":
        result = toolkit.run_stage_3_test_infrastructure()
        print(
            f"\nâœ… éšŽæ®µ3å®Œæˆ - æ¸¬è©¦è¦†è“‹çŽ‡: {result['coverage_metrics'].get('total_coverage', 0):.1f}%"
        )

    else:
        print(f"æœªçŸ¥å‘½ä»¤: {command}")


if __name__ == "__main__":
    main()
