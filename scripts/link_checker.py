#!/usr/bin/env python3
"""
é€£çµæª¢æŸ¥è…³æœ¬ç¯„ä¾‹
Task ID: T3 - æ–‡æª”é€£çµæœ‰æ•ˆæ€§ä¿®å¾©

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨é€£çµæª¢æŸ¥APIæœå‹™çš„å¯¦ç”¨è…³æœ¬
æ”¯æ´é…ç½®æ–‡ä»¶å’ŒCIç’°å¢ƒæ•´åˆ
"""

import asyncio
import argparse
import json
import sys
import yaml
import os
from pathlib import Path
from typing import List, Optional, Dict, Any

# å‡è¨­æœå‹™å·²æ­£ç¢ºå®‰è£
try:
    from services.documentation.api_endpoints import LinkCheckAPI
    from services.documentation.link_checker_models import LinkCheckConfig
except ImportError:
    print("éŒ¯èª¤ï¼šç„¡æ³•å°å…¥é€£çµæª¢æŸ¥æœå‹™ï¼Œè«‹ç¢ºä¿å·²æ­£ç¢ºå®‰è£")
    sys.exit(1)


def load_config(project_root: str = ".") -> Dict[str, Any]:
    """
    è¼‰å…¥é…ç½®æ–‡ä»¶
    
    å„ªå…ˆé †åºï¼š
    1. CIå°ˆç”¨é…ç½® (.github/linkcheck-ci.json) - å¦‚æœåœ¨CIç’°å¢ƒä¸­
    2. ä¸»é…ç½®æ–‡ä»¶ (.linkcheckrc.yml)
    3. é è¨­é…ç½®
    """
    config = {
        # é è¨­é…ç½®
        "check_settings": {
            "check_external_links": False,
            "check_anchors": True,
            "timeout_seconds": 10,
            "max_concurrent_checks": 3
        },
        "performance_optimization": {
            "max_execution_time_seconds": 300
        },
        "error_handling": {
            "max_broken_links_allowed": 0
        }
    }
    
    project_path = Path(project_root)
    
    # æª¢æŸ¥æ˜¯å¦åœ¨CIç’°å¢ƒ
    is_ci = os.getenv("CI") == "true" or os.getenv("CI_LINK_CHECK") == "true"
    
    if is_ci:
        # å„ªå…ˆä½¿ç”¨CIé…ç½®
        ci_config_path = project_path / ".github" / "linkcheck-ci.json"
        if ci_config_path.exists():
            try:
                with open(ci_config_path, 'r', encoding='utf-8') as f:
                    ci_config = json.load(f)
                    config.update(ci_config)
                    print(f"âœ… å·²è¼‰å…¥CIé…ç½®: {ci_config_path}")
                    return config
            except Exception as e:
                print(f"âš ï¸  è¼‰å…¥CIé…ç½®å¤±æ•—: {e}")
    
    # è¼‰å…¥ä¸»é…ç½®æ–‡ä»¶
    main_config_path = project_path / ".linkcheckrc.yml"
    if main_config_path.exists():
        try:
            with open(main_config_path, 'r', encoding='utf-8') as f:
                yaml_config = yaml.safe_load(f)
                if yaml_config:
                    # è½‰æ›YAMLé…ç½®æ ¼å¼ç‚ºçµ±ä¸€æ ¼å¼
                    if 'base_settings' in yaml_config:
                        config['check_settings'].update(yaml_config['base_settings'])
                    if 'ci_settings' in yaml_config and is_ci:
                        config['check_settings'].update(yaml_config['ci_settings'])
                    print(f"âœ… å·²è¼‰å…¥ä¸»é…ç½®: {main_config_path}")
        except Exception as e:
            print(f"âš ï¸  è¼‰å…¥ä¸»é…ç½®å¤±æ•—: {e}")
    
    return config


def load_ignore_rules(project_root: str = ".") -> List[str]:
    """è¼‰å…¥å¿½ç•¥è¦å‰‡"""
    ignore_rules = []
    ignore_file = Path(project_root) / ".linkcheckignore"
    
    if ignore_file.exists():
        try:
            with open(ignore_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        ignore_rules.append(line)
            print(f"âœ… å·²è¼‰å…¥ {len(ignore_rules)} æ¢å¿½ç•¥è¦å‰‡")
        except Exception as e:
            print(f"âš ï¸  è¼‰å…¥å¿½ç•¥è¦å‰‡å¤±æ•—: {e}")
    
    return ignore_rules


async def check_links_command(
    target_paths: List[str],
    check_external: bool = False,
    check_anchors: bool = True,
    output_format: str = "text",
    export_report: bool = False,
    project_root: str = "."
) -> None:
    """åŸ·è¡Œé€£çµæª¢æŸ¥å‘½ä»¤"""
    
    # è¼‰å…¥é…ç½®
    config = load_config(project_root)
    ignore_rules = load_ignore_rules(project_root)
    
    # å¾é…ç½®è¦†è“‹åƒæ•¸
    check_settings = config.get('check_settings', {})
    if not check_external:  # åªæœ‰åœ¨æœªæ˜ç¢ºæŒ‡å®šæ™‚æ‰ä½¿ç”¨é…ç½®
        check_external = check_settings.get('check_external_links', False)
    if check_anchors is True:  # ä½¿ç”¨é…ç½®å€¼
        check_anchors = check_settings.get('check_anchors', True)
    
    print(f"ğŸ” é–‹å§‹æª¢æŸ¥æ–‡æª”é€£çµ...")
    print(f"ğŸ“ é …ç›®æ ¹ç›®éŒ„: {project_root}")
    print(f"ğŸ“‚ æª¢æŸ¥è·¯å¾‘: {', '.join(target_paths)}")
    print(f"ğŸŒ æª¢æŸ¥å¤–éƒ¨é€£çµ: {'æ˜¯' if check_external else 'å¦'}")
    print(f"âš“ æª¢æŸ¥éŒ¨é»é€£çµ: {'æ˜¯' if check_anchors else 'å¦'}")
    
    # æª¢æŸ¥åŸ·è¡Œæ™‚é–“é™åˆ¶ï¼ˆCIç’°å¢ƒï¼‰
    max_execution_time = config.get('performance_optimization', {}).get('max_execution_time_seconds', 300)
    if os.getenv("CI_LINK_CHECK") == "true":
        print(f"â±ï¸  æœ€å¤§åŸ·è¡Œæ™‚é–“: {max_execution_time}ç§’")
    
    # åˆå§‹åŒ–API
    api = LinkCheckAPI(project_root)
    await api.initialize()
    
    try:
        # è¨­ç½®åŸ·è¡Œæ™‚é–“é™åˆ¶
        async def run_check():
            return await api.check_links(
                target_paths=target_paths,
                check_external=check_external,
                check_anchors=check_anchors,
                output_format="json"  # å…§éƒ¨ä½¿ç”¨JSONæ ¼å¼
            )
        
        # åœ¨CIç’°å¢ƒä¸­æ‡‰ç”¨æ™‚é–“é™åˆ¶
        if os.getenv("CI_LINK_CHECK") == "true":
            result = await asyncio.wait_for(run_check(), timeout=max_execution_time)
        else:
            result = await run_check()
        
        if not result["success"]:
            print(f"âŒ æª¢æŸ¥å¤±æ•—: {result['error']['message']}")
            return
        
        # è§£æçµæœ
        data = result["data"]
        summary = data["summary"]
        
        # é¡¯ç¤ºæ‘˜è¦
        print(f"\nğŸ“Š æª¢æŸ¥çµæœæ‘˜è¦:")
        print(f"   ğŸ“„ æª¢æŸ¥æ–‡æª”æ•¸: {summary['documents_checked']}")
        print(f"   ğŸ”— ç¸½é€£çµæ•¸: {summary['total_links']}")
        print(f"   âœ… æœ‰æ•ˆé€£çµ: {summary['valid_links']}")
        print(f"   âŒ ç„¡æ•ˆé€£çµ: {summary['broken_links']}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"   â±ï¸  åŸ·è¡Œæ™‚é–“: {summary['duration_ms']:.0f}ms")
        
        # é¡¯ç¤ºé€£çµé¡å‹åˆ†å¸ƒ
        if "details" in data:
            dist = data["details"]["link_distribution"]
            print(f"\nğŸ”— é€£çµé¡å‹åˆ†å¸ƒ:")
            print(f"   ğŸ“ å…§éƒ¨é€£çµ: {dist['internal_links']}")
            print(f"   ğŸŒ å¤–éƒ¨é€£çµ: {dist['external_links']}")
            print(f"   âš“ éŒ¨é»é€£çµ: {dist['anchor_links']}")
            print(f"   ğŸ“„ æª”æ¡ˆé€£çµ: {dist['file_links']}")
        
        # é¡¯ç¤ºç„¡æ•ˆé€£çµè©³æƒ…
        if summary["has_failures"] and "details" in data:
            broken_links = data["details"]["broken_links"]
            print(f"\nâŒ ç„¡æ•ˆé€£çµè©³æƒ… ({len(broken_links)} å€‹):")
            
            for i, link in enumerate(broken_links[:10], 1):  # æœ€å¤šé¡¯ç¤º10å€‹
                print(f"   {i}. [{link['text']}]({link['url']})")
                print(f"      ğŸ“ ä½ç½®: ç¬¬ {link['line_number']} è¡Œ")
                print(f"      ğŸ” é¡å‹: {link['link_type']}")
                if link.get('error_message'):
                    print(f"      ğŸ’¬ éŒ¯èª¤: {link['error_message']}")
                print()
            
            if len(broken_links) > 10:
                print(f"   ... é‚„æœ‰ {len(broken_links) - 10} å€‹ç„¡æ•ˆé€£çµ")
        
        # é¡¯ç¤ºè­¦å‘Š
        if "details" in data and data["details"]["warnings"]:
            warnings = data["details"]["warnings"]
            print(f"\nâš ï¸  è­¦å‘Šä¿¡æ¯ ({len(warnings)} å€‹):")
            for warning in warnings[:5]:
                print(f"   â€¢ {warning}")
        
        # é¡¯ç¤ºå»ºè­°
        if "recommendations" in data:
            recommendations = data["recommendations"]
            print(f"\nğŸ’¡ ä¿®å¾©å»ºè­°:")
            for rec in recommendations:
                print(f"   â€¢ {rec}")
        
        # åŒ¯å‡ºå ±å‘Š
        if export_report:
            print(f"\nğŸ“„ åŒ¯å‡ºå ±å‘Š...")
            
            formats = ["markdown", "json", "csv"] if output_format == "all" else [output_format]
            
            for fmt in formats:
                try:
                    export_result = await api.export_report(data["check_id"], fmt)
                    if export_result["success"]:
                        report_path = export_result["data"]["report_path"]
                        file_size = export_result["data"]["file_size"]
                        print(f"   âœ… {fmt.upper()} å ±å‘Šå·²ä¿å­˜: {report_path} ({file_size} bytes)")
                    else:
                        print(f"   âŒ {fmt.upper()} å ±å‘ŠåŒ¯å‡ºå¤±æ•—")
                except Exception as e:
                    print(f"   âŒ {fmt.upper()} å ±å‘ŠåŒ¯å‡ºéŒ¯èª¤: {e}")
        
        # æª¢æŸ¥CIç’°å¢ƒçš„å®¹å¿åº¦
        max_broken_allowed = config.get('error_handling', {}).get('max_broken_links_allowed', 0)
        
        # è¿”å›ç‹€æ…‹ç¢¼
        if summary["broken_links"] > max_broken_allowed:
            print(f"\nâŒ æª¢æŸ¥å®Œæˆä½†æœ‰ {summary['broken_links']} å€‹å¤±æ•—é …ç›®")
            print(f"ğŸ’¥ è¶…éå…è¨±çš„æœ€å¤§å¤±æ•—æ•¸é‡ ({max_broken_allowed})")
            sys.exit(1)
        else:
            print(f"\nâœ… æ‰€æœ‰é€£çµæª¢æŸ¥é€šéï¼")
    
    except asyncio.TimeoutError:
        print(f"\nâ° æª¢æŸ¥è¶…æ™‚ (è¶…é {max_execution_time}ç§’)")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æª¢æŸ¥éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)
    finally:
        await api.shutdown()


async def list_history_command(limit: int = 10, project_root: str = ".") -> None:
    """åˆ—å‡ºæª¢æŸ¥æ­·å²å‘½ä»¤"""
    
    print(f"ğŸ“œ æª¢æŸ¥æ­·å²è¨˜éŒ„ (æœ€è¿‘ {limit} æ¬¡)")
    
    api = LinkCheckAPI(project_root)
    await api.initialize()
    
    try:
        result = await api.list_check_history(limit=limit)
        
        if not result["success"]:
            print(f"âŒ ç²å–æ­·å²å¤±æ•—: {result['error']['message']}")
            return
        
        history = result["data"]["history"]
        
        if not history:
            print("ğŸ“ æš«ç„¡æª¢æŸ¥è¨˜éŒ„")
            return
        
        print(f"\nğŸ“Š å…±æ‰¾åˆ° {len(history)} æ¢è¨˜éŒ„:")
        print("-" * 80)
        
        for i, record in enumerate(history, 1):
            timestamp = record["timestamp"][:19].replace("T", " ")
            status = "âœ… é€šé" if not record["has_failures"] else "âŒ å¤±æ•—"
            
            print(f"{i:2}. {timestamp} | {status} | "
                  f"æ–‡æª”:{record['documents_checked']:2} | "
                  f"é€£çµ:{record['total_links']:3} | "
                  f"æˆåŠŸç‡:{record['success_rate']:5.1f}% | "
                  f"è€—æ™‚:{record['duration_ms']:4.0f}ms")
    
    finally:
        await api.shutdown()


async def manage_schedule_command(
    action: str,
    name: Optional[str] = None,
    interval_hours: Optional[int] = None,
    schedule_id: Optional[str] = None,
    project_root: str = "."
) -> None:
    """ç®¡ç†å®šæœŸæª¢æŸ¥æ’ç¨‹å‘½ä»¤"""
    
    api = LinkCheckAPI(project_root)
    await api.initialize()
    
    try:
        if action == "create":
            if not name or not interval_hours:
                print("âŒ å‰µå»ºæ’ç¨‹éœ€è¦æä¾› --name å’Œ --interval åƒæ•¸")
                return
            
            print(f"ğŸ“… å‰µå»ºå®šæœŸæª¢æŸ¥æ’ç¨‹...")
            
            result = await api.create_periodic_schedule(
                name=name,
                interval_hours=interval_hours,
                target_directories=["docs/"]
            )
            
            if result["success"]:
                data = result["data"]
                print(f"âœ… æ’ç¨‹å‰µå»ºæˆåŠŸ!")
                print(f"   ğŸ“‹ æ’ç¨‹ID: {data['schedule_id']}")
                print(f"   ğŸ“› åç¨±: {data['name']}")
                print(f"   â° é–“éš”: {data['interval_hours']} å°æ™‚")
                print(f"   ğŸ“ ç›®æ¨™: {', '.join(data['target_directories'])}")
            else:
                print(f"âŒ å‰µå»ºæ’ç¨‹å¤±æ•—: {result['error']['message']}")
        
        elif action == "list":
            print("ğŸ“‹ å®šæœŸæª¢æŸ¥æ’ç¨‹åˆ—è¡¨")
            
            result = await api.list_schedules()
            
            if not result["success"]:
                print(f"âŒ ç²å–æ’ç¨‹åˆ—è¡¨å¤±æ•—: {result['error']['message']}")
                return
            
            schedules = result["data"]["schedules"]
            
            if not schedules:
                print("ğŸ“ æš«ç„¡æ´»èºæ’ç¨‹")
                return
            
            print(f"\nğŸ“Š å…±æ‰¾åˆ° {len(schedules)} å€‹æ’ç¨‹:")
            print("-" * 100)
            
            for i, schedule in enumerate(schedules, 1):
                status = "ğŸŸ¢ å•Ÿç”¨" if schedule["enabled"] else "ğŸ”´ åœç”¨"
                next_check = schedule["next_check_time"][:19].replace("T", " ")
                last_check = "æœªåŸ·è¡Œ"
                if schedule["last_check_time"]:
                    last_check = schedule["last_check_time"][:19].replace("T", " ")
                
                print(f"{i:2}. {schedule['name']:20} | {status} | "
                      f"é–“éš”:{schedule['interval_hours']:2}h | "
                      f"ä¸‹æ¬¡:{next_check} | ä¸Šæ¬¡:{last_check}")
        
        elif action == "cancel":
            if not schedule_id:
                print("âŒ å–æ¶ˆæ’ç¨‹éœ€è¦æä¾› --schedule-id åƒæ•¸")
                return
            
            print(f"ğŸ—‘ï¸  å–æ¶ˆæ’ç¨‹: {schedule_id}")
            
            result = await api.cancel_schedule(schedule_id)
            
            if result["success"]:
                print("âœ… æ’ç¨‹å·²å–æ¶ˆ")
            else:
                print(f"âŒ å–æ¶ˆæ’ç¨‹å¤±æ•—: {result['error']['message']}")
        
        else:
            print(f"âŒ ä¸æ”¯æ´çš„æ’ç¨‹æ“ä½œ: {action}")
    
    finally:
        await api.shutdown()


async def status_command(project_root: str = ".") -> None:
    """é¡¯ç¤ºæœå‹™ç‹€æ…‹å‘½ä»¤"""
    
    print("ğŸ“Š é€£çµæª¢æŸ¥æœå‹™ç‹€æ…‹")
    
    api = LinkCheckAPI(project_root)
    await api.initialize()
    
    try:
        result = await api.get_service_status()
        
        if not result["success"]:
            print(f"âŒ ç²å–ç‹€æ…‹å¤±æ•—: {result['error']['message']}")
            return
        
        data = result["data"]
        service = data["service"]
        cache = data["cache"]
        errors = data["errors"]
        
        print(f"\nğŸ”§ æœå‹™ç‹€æ…‹:")
        print(f"   ğŸ“¡ ç‹€æ…‹: {'ğŸŸ¢ é‹è¡Œä¸­' if service['initialized'] else 'ğŸ”´ æœªåˆå§‹åŒ–'}")
        print(f"   ğŸ“ åŸºç¤è·¯å¾‘: {service['base_path']}")
        print(f"   ğŸ”„ é‹è¡Œä¸­æª¢æŸ¥: {service['running_checks']}")
        print(f"   ğŸ“… å®šæœŸæ’ç¨‹: {service['periodic_schedules']} å€‹ ({service['active_schedules']} å€‹æ´»èº)")
        print(f"   ğŸ“œ æ­·å²è¨˜éŒ„: {service['history_count']} æ¢")
        
        print(f"\nğŸ’¾ å¿«å–ç‹€æ…‹:")
        print(f"   ğŸ“ˆ å‘½ä¸­ç‡: {cache['hit_rate_percent']:.1f}% ({cache['hits']} å‘½ä¸­ / {cache['misses']} æœªå‘½ä¸­)")
        print(f"   ğŸ“¦ ç•¶å‰å¤§å°: {cache['current_size']} / {cache['max_size']}")
        
        print(f"\nâš ï¸  éŒ¯èª¤çµ±è¨ˆ:")
        print(f"   ğŸ“Š ç¸½éŒ¯èª¤æ•¸: {errors['total_errors']}")
        print(f"   ğŸ• æœ€è¿‘1å°æ™‚: {errors['recent_errors_1h']}")
        
        if errors.get('top_error_codes'):
            print(f"   ğŸ” å¸¸è¦‹éŒ¯èª¤:")
            for error in errors['top_error_codes'][:3]:
                print(f"      â€¢ {error['code']}: {error['count']} æ¬¡")
        
        print(f"\nğŸ·ï¸  APIç‰ˆæœ¬: {data['api_version']}")
    
    finally:
        await api.shutdown()


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    
    parser = argparse.ArgumentParser(
        description="æ–‡æª”é€£çµæª¢æŸ¥å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  %(prog)s check docs/                     # æª¢æŸ¥docsç›®éŒ„
  %(prog)s check docs/ README.md --export # æª¢æŸ¥ä¸¦åŒ¯å‡ºå ±å‘Š
  %(prog)s check docs/ --external         # æª¢æŸ¥åŒ…æ‹¬å¤–éƒ¨é€£çµ
  %(prog)s history --limit 20             # é¡¯ç¤ºæœ€è¿‘20æ¬¡æª¢æŸ¥è¨˜éŒ„
  %(prog)s schedule create --name daily --interval 24  # å‰µå»ºæ¯æ—¥æ’ç¨‹
  %(prog)s schedule list                   # åˆ—å‡ºæ‰€æœ‰æ’ç¨‹
  %(prog)s status                         # é¡¯ç¤ºæœå‹™ç‹€æ…‹
        """
    )
    
    parser.add_argument("--project-root", default=".", help="é …ç›®æ ¹ç›®éŒ„ (é è¨­: ç•¶å‰ç›®éŒ„)")
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # æª¢æŸ¥å‘½ä»¤
    check_parser = subparsers.add_parser("check", help="æª¢æŸ¥æ–‡æª”é€£çµ")
    check_parser.add_argument("paths", nargs="+", help="è¦æª¢æŸ¥çš„æ–‡æª”è·¯å¾‘")
    check_parser.add_argument("--external", action="store_true", help="æª¢æŸ¥å¤–éƒ¨é€£çµ")
    check_parser.add_argument("--no-anchors", action="store_true", help="ä¸æª¢æŸ¥éŒ¨é»é€£çµ")
    check_parser.add_argument("--export", action="store_true", help="åŒ¯å‡ºå ±å‘Š")
    check_parser.add_argument("--format", choices=["markdown", "json", "csv", "all"], 
                             default="markdown", help="å ±å‘Šæ ¼å¼")
    
    # æ­·å²å‘½ä»¤
    history_parser = subparsers.add_parser("history", help="æª¢è¦–æª¢æŸ¥æ­·å²")
    history_parser.add_argument("--limit", type=int, default=10, help="é¡¯ç¤ºè¨˜éŒ„æ•¸é‡")
    
    # æ’ç¨‹å‘½ä»¤
    schedule_parser = subparsers.add_parser("schedule", help="ç®¡ç†å®šæœŸæª¢æŸ¥æ’ç¨‹")
    schedule_subparsers = schedule_parser.add_subparsers(dest="schedule_action", help="æ’ç¨‹æ“ä½œ")
    
    create_parser = schedule_subparsers.add_parser("create", help="å‰µå»ºæ’ç¨‹")
    create_parser.add_argument("--name", required=True, help="æ’ç¨‹åç¨±")
    create_parser.add_argument("--interval", type=int, required=True, help="æª¢æŸ¥é–“éš” (å°æ™‚)")
    
    schedule_subparsers.add_parser("list", help="åˆ—å‡ºæ’ç¨‹")
    
    cancel_parser = schedule_subparsers.add_parser("cancel", help="å–æ¶ˆæ’ç¨‹")
    cancel_parser.add_argument("--schedule-id", required=True, help="è¦å–æ¶ˆçš„æ’ç¨‹ID")
    
    # ç‹€æ…‹å‘½ä»¤
    subparsers.add_parser("status", help="é¡¯ç¤ºæœå‹™ç‹€æ…‹")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # åŸ·è¡Œå°æ‡‰å‘½ä»¤
    try:
        if args.command == "check":
            asyncio.run(check_links_command(
                target_paths=args.paths,
                check_external=args.external,
                check_anchors=not args.no_anchors,
                output_format=args.format,
                export_report=args.export,
                project_root=args.project_root
            ))
        
        elif args.command == "history":
            asyncio.run(list_history_command(
                limit=args.limit,
                project_root=args.project_root
            ))
        
        elif args.command == "schedule":
            if not args.schedule_action:
                schedule_parser.print_help()
                return
            
            asyncio.run(manage_schedule_command(
                action=args.schedule_action,
                name=getattr(args, "name", None),
                interval_hours=getattr(args, "interval", None),
                schedule_id=getattr(args, "schedule_id", None),
                project_root=args.project_root
            ))
        
        elif args.command == "status":
            asyncio.run(status_command(project_root=args.project_root))
    
    except KeyboardInterrupt:
        print("\nâ¸ï¸  æ“ä½œå·²å–æ¶ˆ")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()