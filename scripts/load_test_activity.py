#!/usr/bin/env python3
"""
Activity Meter ä½µç™¼å£“æ¸¬è…³æœ¬
T3 - ä½µç™¼èˆ‡è³‡æ–™åº«é–å®šç©©å®šæ€§å¯¦æ–½

æ¨¡æ“¬é«˜ä½µç™¼æ´»èºåº¦æ›´æ–°å ´æ™¯ï¼Œæ¸¬è©¦ç³»çµ±åœ¨å£“åŠ›ä¸‹çš„è¡¨ç¾
ç”Ÿæˆè©³ç´°çš„æ€§èƒ½æŒ‡æ¨™å ±å‘Šï¼Œç”¨æ–¼æŒçºŒç›£æ§å’ŒåŸºæº–æ¯”è¼ƒ
"""

import os
import sys
import time
import json
import argparse
import logging
import statistics
from datetime import datetime
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from dataclasses import dataclass, asdict
import multiprocessing as mp

# ç¢ºä¿èƒ½å°å…¥å°ˆæ¡ˆæ¨¡çµ„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.activity.concurrent_activity_meter import ConcurrentActivityMeterService


@dataclass
class LoadTestConfig:
    """å£“æ¸¬é…ç½®"""
    db_path: str
    total_operations: int = 10000
    concurrent_workers: int = 10
    guilds_count: int = 5
    users_per_guild: int = 1000
    duration_seconds: Optional[int] = None
    worker_type: str = "thread"  # "thread" or "process"
    report_interval: int = 1000
    enable_batch_operations: bool = False
    batch_size: int = 50


@dataclass
class OperationResult:
    """å–®æ¬¡æ“ä½œçµæœ"""
    success: bool
    duration: float
    operation_type: str
    worker_id: int
    timestamp: float
    error_message: Optional[str] = None


@dataclass
class LoadTestReport:
    """å£“æ¸¬å ±å‘Š"""
    config: LoadTestConfig
    start_time: str
    end_time: str
    duration_seconds: float
    total_operations: int
    successful_operations: int
    failed_operations: int
    success_rate: float
    operations_per_second: float
    
    # å»¶é²çµ±è¨ˆ (æ¯«ç§’)
    latency_p50: float
    latency_p95: float
    latency_p99: float
    latency_min: float
    latency_max: float
    latency_mean: float
    
    # éŒ¯èª¤çµ±è¨ˆ
    error_distribution: Dict[str, int]
    
    # å·¥ä½œè€…çµ±è¨ˆ
    worker_performance: Dict[int, Dict[str, Any]]
    
    # è³‡æ–™åº«çµ±è¨ˆ
    final_record_count: int
    database_file_size: int


class ActivityLoadTester:
    """æ´»èºåº¦ç³»çµ±å£“æ¸¬å™¨"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.results: List[OperationResult] = []
        self.logger = self._setup_logger()
        
        # ç¢ºä¿è³‡æ–™åº«ç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(config.db_path), exist_ok=True)
        
        self.logger.info(f"åˆå§‹åŒ–å£“æ¸¬å™¨ï¼Œç›®æ¨™ï¼š{config.total_operations} æ¬¡æ“ä½œï¼Œ{config.concurrent_workers} å€‹å·¥ä½œè€…")
    
    def _setup_logger(self) -> logging.Logger:
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„"""
        logger = logging.getLogger('activity_load_test')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def run_load_test(self) -> LoadTestReport:
        """åŸ·è¡Œå£“æ¸¬"""
        self.logger.info("é–‹å§‹å£“æ¸¬...")
        start_time = time.time()
        start_time_str = datetime.now().isoformat()
        
        if self.config.worker_type == "process":
            results = self._run_process_based_test()
        else:
            results = self._run_thread_based_test()
        
        end_time = time.time()
        end_time_str = datetime.now().isoformat()
        duration = end_time - start_time
        
        self.logger.info(f"å£“æ¸¬å®Œæˆï¼Œè€—æ™‚ {duration:.2f} ç§’")
        
        # ç”Ÿæˆå ±å‘Š
        report = self._generate_report(results, start_time_str, end_time_str, duration)
        return report
    
    def _run_thread_based_test(self) -> List[OperationResult]:
        """åŸ·è¡ŒåŸºæ–¼åŸ·è¡Œç·’çš„å£“æ¸¬"""
        operations_per_worker = self.config.total_operations // self.config.concurrent_workers
        remaining_operations = self.config.total_operations % self.config.concurrent_workers
        
        with ThreadPoolExecutor(max_workers=self.config.concurrent_workers) as executor:
            futures = []
            
            for worker_id in range(self.config.concurrent_workers):
                operations_count = operations_per_worker
                if worker_id < remaining_operations:
                    operations_count += 1
                
                future = executor.submit(
                    self._worker_function, 
                    worker_id, 
                    operations_count,
                    self.config
                )
                futures.append(future)
            
            # æ”¶é›†çµæœ
            all_results = []
            completed_count = 0
            
            for future in as_completed(futures):
                try:
                    worker_results = future.result()
                    all_results.extend(worker_results)
                    completed_count += 1
                    
                    if completed_count % max(1, self.config.concurrent_workers // 4) == 0:
                        self.logger.info(f"å·²å®Œæˆ {completed_count}/{self.config.concurrent_workers} å€‹å·¥ä½œè€…")
                
                except Exception as e:
                    self.logger.error(f"å·¥ä½œè€…åŸ·è¡Œå¤±æ•—ï¼š{e}")
        
        return all_results
    
    def _run_process_based_test(self) -> List[OperationResult]:
        """åŸ·è¡ŒåŸºæ–¼å¤šé€²ç¨‹çš„å£“æ¸¬"""
        operations_per_worker = self.config.total_operations // self.config.concurrent_workers
        remaining_operations = self.config.total_operations % self.config.concurrent_workers
        
        with ProcessPoolExecutor(max_workers=self.config.concurrent_workers) as executor:
            futures = []
            
            for worker_id in range(self.config.concurrent_workers):
                operations_count = operations_per_worker
                if worker_id < remaining_operations:
                    operations_count += 1
                
                future = executor.submit(
                    worker_process_function,
                    worker_id,
                    operations_count,
                    self.config
                )
                futures.append(future)
            
            # æ”¶é›†çµæœ
            all_results = []
            for future in as_completed(futures):
                try:
                    worker_results = future.result()
                    all_results.extend(worker_results)
                except Exception as e:
                    self.logger.error(f"é€²ç¨‹å·¥ä½œè€…åŸ·è¡Œå¤±æ•—ï¼š{e}")
        
        return all_results
    
    @staticmethod
    def _worker_function(worker_id: int, operations_count: int, config: LoadTestConfig) -> List[OperationResult]:
        """å·¥ä½œè€…å‡½æ•¸ - åŸ·è¡ŒæŒ‡å®šæ•¸é‡çš„æ“ä½œ"""
        service = ConcurrentActivityMeterService(config.db_path)
        results = []
        
        try:
            for i in range(operations_count):
                result = ActivityLoadTester._perform_operation(service, worker_id, config)
                results.append(result)
                
                # å®šæœŸå ±å‘Šé€²åº¦
                if (i + 1) % config.report_interval == 0:
                    success_count = sum(1 for r in results if r.success)
                    success_rate = success_count / len(results)
                    print(f"å·¥ä½œè€… {worker_id}: {i + 1}/{operations_count} æ“ä½œå®Œæˆï¼ŒæˆåŠŸç‡ {success_rate:.2%}")
        
        finally:
            service.close()
        
        return results
    
    @staticmethod
    def _perform_operation(service: ConcurrentActivityMeterService, worker_id: int, config: LoadTestConfig) -> OperationResult:
        """åŸ·è¡Œå–®æ¬¡æ“ä½œ"""
        import random
        
        start_time = time.time()
        timestamp = start_time
        
        try:
            # éš¨æ©Ÿé¸æ“‡ guild å’Œ user
            guild_id = random.randint(1, config.guilds_count)
            user_id = random.randint(1, config.users_per_guild)
            score_delta = random.uniform(0.5, 3.0)
            last_msg_time = int(time.time() * 1000)
            
            if config.enable_batch_operations and random.random() < 0.3:
                # 30% æ¦‚ç‡åŸ·è¡Œæ‰¹æ¬¡æ“ä½œ
                activities = [
                    (guild_id, user_id + j, score_delta, last_msg_time + j)
                    for j in range(min(config.batch_size, 10))
                ]
                result = service.batch_upsert_activities(activities)
                operation_type = "batch_upsert"
                success = result['success'] and result['processed'] > 0
            else:
                # åŸ·è¡Œå–®æ¬¡ UPSERT
                result = service.upsert_activity_score(guild_id, user_id, score_delta, last_msg_time)
                operation_type = "upsert"
                success = result['success']
            
            duration = (time.time() - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
            
            return OperationResult(
                success=success,
                duration=duration,
                operation_type=operation_type,
                worker_id=worker_id,
                timestamp=timestamp
            )
        
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            return OperationResult(
                success=False,
                duration=duration,
                operation_type="upsert",
                worker_id=worker_id,
                timestamp=timestamp,
                error_message=str(e)
            )
    
    def _generate_report(self, results: List[OperationResult], start_time: str, end_time: str, duration: float) -> LoadTestReport:
        """ç”Ÿæˆè©³ç´°çš„æ¸¬è©¦å ±å‘Š"""
        if not results:
            raise ValueError("æ²’æœ‰æ¸¬è©¦çµæœå¯ä»¥ç”Ÿæˆå ±å‘Š")
        
        successful_results = [r for r in results if r.success]
        failed_results = [r for r in results if not r.success]
        
        # å»¶é²çµ±è¨ˆ
        latencies = [r.duration for r in results]
        latencies.sort()
        
        # éŒ¯èª¤çµ±è¨ˆ
        error_distribution = {}
        for result in failed_results:
            error_key = result.error_message or "Unknown Error"
            error_distribution[error_key] = error_distribution.get(error_key, 0) + 1
        
        # å·¥ä½œè€…æ€§èƒ½çµ±è¨ˆ
        worker_performance = {}
        for worker_id in range(self.config.concurrent_workers):
            worker_results = [r for r in results if r.worker_id == worker_id]
            if worker_results:
                worker_latencies = [r.duration for r in worker_results]
                worker_performance[worker_id] = {
                    'total_operations': len(worker_results),
                    'successful_operations': len([r for r in worker_results if r.success]),
                    'success_rate': len([r for r in worker_results if r.success]) / len(worker_results),
                    'average_latency': statistics.mean(worker_latencies),
                    'p95_latency': statistics.quantiles(worker_latencies, n=20)[18] if len(worker_latencies) >= 20 else max(worker_latencies)
                }
        
        # è³‡æ–™åº«çµ±è¨ˆ
        try:
            service = ConcurrentActivityMeterService(self.config.db_path)
            stats = service.get_statistics()
            final_record_count = stats['total_activity_records']
            service.close()
        except:
            final_record_count = -1
        
        try:
            database_file_size = os.path.getsize(self.config.db_path)
        except:
            database_file_size = -1
        
        return LoadTestReport(
            config=self.config,
            start_time=start_time,
            end_time=end_time,
            duration_seconds=duration,
            total_operations=len(results),
            successful_operations=len(successful_results),
            failed_operations=len(failed_results),
            success_rate=len(successful_results) / len(results),
            operations_per_second=len(results) / duration if duration > 0 else 0,
            
            latency_p50=statistics.quantiles(latencies, n=2)[0] if len(latencies) >= 2 else latencies[0],
            latency_p95=statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else max(latencies),
            latency_p99=statistics.quantiles(latencies, n=100)[98] if len(latencies) >= 100 else max(latencies),
            latency_min=min(latencies),
            latency_max=max(latencies),
            latency_mean=statistics.mean(latencies),
            
            error_distribution=error_distribution,
            worker_performance=worker_performance,
            final_record_count=final_record_count,
            database_file_size=database_file_size
        )
    
    def save_report(self, report: LoadTestReport, output_path: str):
        """ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶"""
        # ä¿å­˜ç‚º JSON
        json_path = output_path.replace('.txt', '.json').replace('.md', '.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(report), f, indent=2, ensure_ascii=False, default=str)
        
        # ä¿å­˜ç‚º Markdown å ±å‘Š
        md_path = output_path.replace('.json', '.md').replace('.txt', '.md')
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(self._generate_markdown_report(report))
        
        self.logger.info(f"å ±å‘Šå·²ä¿å­˜åˆ° {json_path} å’Œ {md_path}")
    
    def _generate_markdown_report(self, report: LoadTestReport) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„å ±å‘Š"""
        md_content = f"""# Activity Meter ä½µç™¼å£“æ¸¬å ±å‘Š

## æ¸¬è©¦é…ç½®

- **è³‡æ–™åº«è·¯å¾‘**: `{report.config.db_path}`
- **ç¸½æ“ä½œæ•¸**: {report.total_operations:,}
- **ä½µç™¼å·¥ä½œè€…**: {report.config.concurrent_workers}
- **ç›®æ¨™ä¼ºæœå™¨æ•¸**: {report.config.guilds_count}
- **æ¯ä¼ºæœå™¨ç”¨æˆ¶æ•¸**: {report.config.users_per_guild:,}
- **å·¥ä½œè€…é¡å‹**: {report.config.worker_type}
- **æ‰¹æ¬¡æ“ä½œ**: {'å•Ÿç”¨' if report.config.enable_batch_operations else 'åœç”¨'}

## åŸ·è¡Œçµæœ

- **é–‹å§‹æ™‚é–“**: {report.start_time}
- **çµæŸæ™‚é–“**: {report.end_time}
- **åŸ·è¡Œæ™‚é•·**: {report.duration_seconds:.2f} ç§’
- **æˆåŠŸæ“ä½œ**: {report.successful_operations:,} ({report.success_rate:.2%})
- **å¤±æ•—æ“ä½œ**: {report.failed_operations:,}
- **å¹³å‡ TPS**: {report.operations_per_second:.2f} ops/sec

## å»¶é²çµ±è¨ˆ

| æŒ‡æ¨™ | å€¼ (æ¯«ç§’) |
|------|----------|
| P50 | {report.latency_p50:.2f} |
| P95 | {report.latency_p95:.2f} |
| P99 | {report.latency_p99:.2f} |
| æœ€å°å€¼ | {report.latency_min:.2f} |
| æœ€å¤§å€¼ | {report.latency_max:.2f} |
| å¹³å‡å€¼ | {report.latency_mean:.2f} |

## éŒ¯èª¤åˆ†ä½ˆ

"""
        
        if report.error_distribution:
            for error, count in report.error_distribution.items():
                md_content += f"- **{error}**: {count} æ¬¡\n"
        else:
            md_content += "ç„¡éŒ¯èª¤ç™¼ç”Ÿ âœ…\n"
        
        md_content += f"""
## å·¥ä½œè€…æ€§èƒ½

| å·¥ä½œè€… ID | ç¸½æ“ä½œ | æˆåŠŸæ“ä½œ | æˆåŠŸç‡ | å¹³å‡å»¶é² (ms) | P95 å»¶é² (ms) |
|----------|--------|----------|--------|---------------|---------------|
"""
        
        for worker_id, perf in report.worker_performance.items():
            md_content += f"| {worker_id} | {perf['total_operations']} | {perf['successful_operations']} | {perf['success_rate']:.2%} | {perf['average_latency']:.2f} | {perf['p95_latency']:.2f} |\n"
        
        md_content += f"""
## è³‡æ–™åº«ç‹€æ…‹

- **æœ€çµ‚è¨˜éŒ„æ•¸**: {report.final_record_count:,}
- **è³‡æ–™åº«æ–‡ä»¶å¤§å°**: {report.database_file_size / 1024 / 1024:.2f} MB

## æ•ˆèƒ½è©•ä¼°

"""
        
        # æ•ˆèƒ½è©•ä¼°é‚è¼¯
        if report.success_rate >= 0.99:
            md_content += "âœ… **å„ªç§€**: æˆåŠŸç‡ â‰¥ 99%\n"
        elif report.success_rate >= 0.95:
            md_content += "ğŸŸ¡ **è‰¯å¥½**: æˆåŠŸç‡ â‰¥ 95%\n"
        else:
            md_content += "ğŸ”´ **éœ€è¦æ”¹é€²**: æˆåŠŸç‡ < 95%\n"
        
        if report.latency_p99 <= 100:
            md_content += "âœ… **å„ªç§€**: P99 å»¶é² â‰¤ 100ms\n"
        elif report.latency_p99 <= 500:
            md_content += "ğŸŸ¡ **å¯æ¥å—**: P99 å»¶é² â‰¤ 500ms\n"
        else:
            md_content += "ğŸ”´ **éœ€è¦å„ªåŒ–**: P99 å»¶é² > 500ms\n"
        
        if report.operations_per_second >= 1000:
            md_content += "âœ… **é«˜æ€§èƒ½**: TPS â‰¥ 1000\n"
        elif report.operations_per_second >= 500:
            md_content += "ğŸŸ¡ **ä¸­ç­‰æ€§èƒ½**: TPS â‰¥ 500\n"
        else:
            md_content += "ğŸ”´ **ä½æ€§èƒ½**: TPS < 500\n"
        
        md_content += f"""
---
å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().isoformat()}
"""
        
        return md_content


def worker_process_function(worker_id: int, operations_count: int, config: LoadTestConfig) -> List[OperationResult]:
    """å¤šé€²ç¨‹å·¥ä½œè€…å‡½æ•¸"""
    return ActivityLoadTester._worker_function(worker_id, operations_count, config)


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='Activity Meter ä½µç™¼å£“æ¸¬å·¥å…·')
    
    parser.add_argument('--db-path', default='dbs/load_test.db', help='è³‡æ–™åº«æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--operations', type=int, default=10000, help='ç¸½æ“ä½œæ•¸')
    parser.add_argument('--workers', type=int, default=10, help='ä½µç™¼å·¥ä½œè€…æ•¸é‡')
    parser.add_argument('--guilds', type=int, default=5, help='æ¸¬è©¦ä¼ºæœå™¨æ•¸é‡')
    parser.add_argument('--users-per-guild', type=int, default=1000, help='æ¯ä¼ºæœå™¨ç”¨æˆ¶æ•¸')
    parser.add_argument('--worker-type', choices=['thread', 'process'], default='thread', help='å·¥ä½œè€…é¡å‹')
    parser.add_argument('--enable-batch', action='store_true', help='å•Ÿç”¨æ‰¹æ¬¡æ“ä½œ')
    parser.add_argument('--batch-size', type=int, default=50, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--output', default='load_test_report', help='è¼¸å‡ºå ±å‘Šè·¯å¾‘å‰ç¶´')
    parser.add_argument('--verbose', action='store_true', help='è©³ç´°è¼¸å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    
    # ç¢ºä¿è³‡æ–™åº«è·¯å¾‘æ˜¯çµ•å°è·¯å¾‘
    if not os.path.isabs(args.db_path):
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        args.db_path = os.path.join(project_root, args.db_path)
    
    config = LoadTestConfig(
        db_path=args.db_path,
        total_operations=args.operations,
        concurrent_workers=args.workers,
        guilds_count=args.guilds,
        users_per_guild=args.users_per_guild,
        worker_type=args.worker_type,
        enable_batch_operations=args.enable_batch,
        batch_size=args.batch_size
    )
    
    tester = ActivityLoadTester(config)
    report = tester.run_load_test()
    
    # ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_path = f"{args.output}_{timestamp}.md"
    
    tester.save_report(report, output_path)
    
    # æ§åˆ¶å°æ‘˜è¦
    print("\n" + "="*60)
    print("å£“æ¸¬æ‘˜è¦")
    print("="*60)
    print(f"ç¸½æ“ä½œæ•¸: {report.total_operations:,}")
    print(f"æˆåŠŸç‡: {report.success_rate:.2%}")
    print(f"å¹³å‡ TPS: {report.operations_per_second:.2f}")
    print(f"P99 å»¶é²: {report.latency_p99:.2f} ms")
    print(f"è³‡æ–™åº«è¨˜éŒ„æ•¸: {report.final_record_count:,}")
    print("="*60)


if __name__ == '__main__':
    main()