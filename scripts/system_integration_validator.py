#!/usr/bin/env python3
"""
ç³»çµ±æ•´åˆé©—è­‰è…³æœ¬
Task ID: 1 - ROAS Bot v2.4.3 Dockerå•Ÿå‹•ç³»çµ±ä¿®å¾©

é€™å€‹è…³æœ¬é©—è­‰æ•´å€‹æ™ºèƒ½éƒ¨ç½²å’Œç®¡ç†ç³»çµ±çš„å®Œæ•´æ€§ï¼Œ
ç¢ºä¿æ‰€æœ‰æ•´åˆçµ„ä»¶èƒ½å¤ æ­£ç¢ºå”ä½œå’Œäº’æ“ä½œã€‚
"""

import asyncio
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import logging
import json

# æ·»åŠ æ ¸å¿ƒæ¨¡çµ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.service_integration_coordinator import ServiceIntegrationCoordinator
from core.api_contracts import IntegrationContractValidator
from core.service_startup_orchestrator import ServiceStartupOrchestrator
from core.unified_health_checker import UnifiedHealthChecker
from core.unified_logging_integration import create_logger, get_log_handler
from core.integration_test_suite import IntegrationTestSuite
from scripts.smart_deployment import SmartDeployment

logger = logging.getLogger(__name__)


class SystemIntegrationValidator:
    """ç³»çµ±æ•´åˆé©—è­‰å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.validation_logger = create_logger("system-validation", "integration")
        self.validation_results = {}
    
    async def run_complete_validation(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„ç³»çµ±æ•´åˆé©—è­‰"""
        self.validation_logger.info("ğŸ” é–‹å§‹ç³»çµ±æ•´åˆé©—è­‰")
        start_time = time.time()
        
        validation_summary = {
            'validation_id': f"validation-{int(time.time())}",
            'start_time': datetime.now().isoformat(),
            'components_validated': [],
            'integration_tests': {},
            'overall_status': 'unknown',
            'recommendations': [],
            'duration_seconds': 0
        }
        
        # é©—è­‰éšæ®µ
        validation_phases = [
            ("çµ„ä»¶åˆå§‹åŒ–é©—è­‰", self._validate_component_initialization),
            ("APIå¥‘ç´„é©—è­‰", self._validate_api_contracts),
            ("æœå‹™ç·¨æ’é©—è­‰", self._validate_service_orchestration),
            ("å¥åº·æª¢æŸ¥é©—è­‰", self._validate_health_checking),
            ("æ—¥èªŒç³»çµ±é©—è­‰", self._validate_logging_system),
            ("éƒ¨ç½²ç³»çµ±é©—è­‰", self._validate_deployment_system),
            ("ç«¯åˆ°ç«¯æ•´åˆé©—è­‰", self._validate_end_to_end_integration),
            ("æ€§èƒ½å’Œç©©å®šæ€§é©—è­‰", self._validate_performance_stability)
        ]
        
        passed_validations = 0
        total_validations = len(validation_phases)
        
        for phase_name, validation_func in validation_phases:
            self.validation_logger.info(f"åŸ·è¡Œé©—è­‰: {phase_name}")
            
            try:
                validation_result = await validation_func()
                validation_summary['integration_tests'][phase_name] = validation_result
                
                if validation_result.get('passed', False):
                    passed_validations += 1
                    self.validation_logger.info(f"âœ… {phase_name} é©—è­‰é€šé")
                else:
                    self.validation_logger.error(f"âŒ {phase_name} é©—è­‰å¤±æ•—")
                
            except Exception as e:
                self.validation_logger.error(f"âŒ {phase_name} é©—è­‰ç•°å¸¸", exception=e)
                validation_summary['integration_tests'][phase_name] = {
                    'passed': False,
                    'error': str(e),
                    'exception': True
                }
        
        # è¨ˆç®—æ•´é«”çµæœ
        success_rate = (passed_validations / total_validations) * 100
        validation_summary.update({
            'passed_validations': passed_validations,
            'total_validations': total_validations,
            'success_rate': success_rate,
            'overall_status': 'passed' if success_rate >= 80 else 'failed',
            'duration_seconds': time.time() - start_time
        })
        
        # ç”Ÿæˆå»ºè­°
        validation_summary['recommendations'] = self._generate_validation_recommendations(validation_summary)
        
        # ä¿å­˜é©—è­‰å ±å‘Š
        await self._save_validation_report(validation_summary)
        
        return validation_summary
    
    async def _validate_component_initialization(self) -> Dict[str, Any]:
        """é©—è­‰çµ„ä»¶åˆå§‹åŒ–"""
        components_status = {}
        
        # æ¸¬è©¦æ¯å€‹æ ¸å¿ƒçµ„ä»¶çš„åˆå§‹åŒ–
        test_components = [
            ("ServiceIntegrationCoordinator", ServiceIntegrationCoordinator),
            ("IntegrationContractValidator", IntegrationContractValidator),
            ("ServiceStartupOrchestrator", ServiceStartupOrchestrator),
            ("UnifiedHealthChecker", UnifiedHealthChecker),
            ("IntegrationTestSuite", IntegrationTestSuite)
        ]
        
        for component_name, component_class in test_components:
            try:
                if component_name in ["ServiceIntegrationCoordinator", "ServiceStartupOrchestrator", "IntegrationTestSuite"]:
                    instance = component_class(self.project_root, 'dev')
                elif component_name == "UnifiedHealthChecker":
                    instance = component_class(self.project_root)
                else:
                    instance = component_class()
                
                components_status[component_name] = {
                    'initialized': True,
                    'instance_type': str(type(instance)),
                    'has_required_methods': self._check_required_methods(instance, component_name)
                }
                
            except Exception as e:
                components_status[component_name] = {
                    'initialized': False,
                    'error': str(e)
                }
        
        all_initialized = all(comp['initialized'] for comp in components_status.values())
        
        return {
            'passed': all_initialized,
            'components_status': components_status,
            'total_components': len(test_components),
            'initialized_components': sum(1 for comp in components_status.values() if comp['initialized'])
        }
    
    def _check_required_methods(self, instance, component_name: str) -> bool:
        """æª¢æŸ¥çµ„ä»¶æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•"""
        required_methods = {
            'ServiceIntegrationCoordinator': ['orchestrate_integration', 'get_integration_report'],
            'IntegrationContractValidator': ['validate_all_contracts'],
            'ServiceStartupOrchestrator': ['orchestrate_startup'],
            'UnifiedHealthChecker': ['check_all_services'],
            'IntegrationTestSuite': ['run_full_integration_test']
        }
        
        if component_name not in required_methods:
            return True
        
        return all(hasattr(instance, method) for method in required_methods[component_name])
    
    async def _validate_api_contracts(self) -> Dict[str, Any]:
        """é©—è­‰APIå¥‘ç´„ç³»çµ±"""
        try:
            contract_validator = IntegrationContractValidator()
            
            # é©—è­‰æ‰€æœ‰å¥‘ç´„
            contract_results = contract_validator.validate_all_contracts()
            
            # åˆ†æçµæœ
            valid_contracts = 0
            total_contracts = len(contract_results)
            
            for service, result in contract_results.items():
                if isinstance(result, dict) and result.get('endpoints_valid', False):
                    valid_contracts += 1
            
            return {
                'passed': valid_contracts == total_contracts,
                'contract_results': contract_results,
                'valid_contracts': valid_contracts,
                'total_contracts': total_contracts,
                'validation_details': {
                    service: result.get('issues', []) if isinstance(result, dict) else str(result)
                    for service, result in contract_results.items()
                }
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_service_orchestration(self) -> Dict[str, Any]:
        """é©—è­‰æœå‹™ç·¨æ’ç³»çµ±"""
        try:
            orchestrator = ServiceStartupOrchestrator(self.project_root, 'dev')
            
            # æ¸¬è©¦æœå‹™ç·¨æ’ï¼ˆæ¨¡æ“¬æ¨¡å¼ï¼‰
            test_services = ['redis', 'discord-bot']
            orchestration_result = await orchestrator.orchestrate_startup(test_services)
            
            return {
                'passed': orchestration_result.success,
                'orchestration_success': orchestration_result.success,
                'startup_order': orchestration_result.startup_order,
                'total_duration': orchestration_result.total_duration,
                'service_results_count': len(orchestration_result.service_results),
                'failed_services': orchestration_result.failed_services,
                'recommendations': orchestration_result.recommendations
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_health_checking(self) -> Dict[str, Any]:
        """é©—è­‰å¥åº·æª¢æŸ¥ç³»çµ±"""
        try:
            health_checker = UnifiedHealthChecker(self.project_root)
            
            # åŸ·è¡Œå¥åº·æª¢æŸ¥
            health_report = await health_checker.check_all_services()
            
            return {
                'passed': True,  # å¥åº·æª¢æŸ¥ç³»çµ±æœ¬èº«å·¥ä½œæ­£å¸¸å°±ç®—é€šé
                'health_report_generated': True,
                'overall_status': health_report.overall_status.value,
                'health_score': health_report.health_score,
                'services_checked': len(health_report.service_results),
                'response_time_stats': health_report.response_time_stats,
                'has_recommendations': len(health_report.recommendations) > 0
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_logging_system(self) -> Dict[str, Any]:
        """é©—è­‰æ—¥èªŒç³»çµ±"""
        try:
            # å‰µå»ºæ¸¬è©¦æ—¥èªŒå™¨
            test_logger = create_logger("validation-test", "logging")
            
            # æ¸¬è©¦æ—¥èªŒè¨˜éŒ„
            with test_logger.context("validation-test") as ctx:
                test_logger.info("é©—è­‰æ¸¬è©¦è³‡è¨Šæ—¥èªŒ")
                test_logger.warning("é©—è­‰æ¸¬è©¦è­¦å‘Šæ—¥èªŒ")
                test_logger.error("é©—è­‰æ¸¬è©¦éŒ¯èª¤æ—¥èªŒ", error_code="VALIDATION-001")
            
            # ç­‰å¾…æ—¥èªŒè™•ç†
            await asyncio.sleep(2)
            
            # æª¢æŸ¥æ—¥èªŒè™•ç†å™¨ç‹€æ…‹
            log_handler = get_log_handler()
            stats = log_handler.get_stats()
            
            return {
                'passed': True,  # èƒ½å‰µå»ºæ—¥èªŒå™¨ä¸¦è¨˜éŒ„æ—¥èªŒå°±ç®—é€šé
                'test_logs_recorded': 3,
                'log_handler_stats': stats,
                'thread_active': stats.get('thread_alive', False),
                'buffer_size': stats.get('buffer_size', 0)
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_deployment_system(self) -> Dict[str, Any]:
        """é©—è­‰éƒ¨ç½²ç³»çµ±"""
        try:
            # å‰µå»ºæ™ºèƒ½éƒ¨ç½²å¯¦ä¾‹
            smart_deployment = SmartDeployment(
                project_root=self.project_root,
                environment='dev',
                dry_run=True  # æ¨¡æ“¬é‹è¡Œ
            )
            
            # åŸ·è¡Œæ¨¡æ“¬éƒ¨ç½²
            deployment_report = await smart_deployment.deploy()
            
            return {
                'passed': deployment_report['status'] in ['success', 'pending'],
                'deployment_system_available': True,
                'deployment_report_generated': True,
                'phases_executed': len(deployment_report.get('phases', {})),
                'dry_run_successful': deployment_report.get('status') != 'failed'
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_end_to_end_integration(self) -> Dict[str, Any]:
        """é©—è­‰ç«¯åˆ°ç«¯æ•´åˆ"""
        try:
            # ä½¿ç”¨æ•´åˆå”èª¿å™¨
            coordinator = ServiceIntegrationCoordinator(self.project_root, 'dev')
            
            # åŸ·è¡Œæ•´åˆ
            integration_result = await coordinator.orchestrate_integration()
            
            # ç²å–æ•´åˆå ±å‘Š
            integration_report = await coordinator.get_integration_report()
            
            return {
                'passed': integration_result.success,
                'integration_success': integration_result.success,
                'integration_phase': integration_result.phase.value,
                'duration_seconds': integration_result.duration_seconds,
                'service_status': integration_result.service_status,
                'integration_health_score': integration_report.get('integration_health_score', 0),
                'contract_validation': integration_report.get('contract_validation', {}),
                'errors': integration_result.errors,
                'warnings': integration_result.warnings
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _validate_performance_stability(self) -> Dict[str, Any]:
        """é©—è­‰æ€§èƒ½å’Œç©©å®šæ€§"""
        try:
            # é‹è¡Œå¿«é€Ÿæ€§èƒ½æ¸¬è©¦
            start_time = time.time()
            
            # æ¸¬è©¦å¤šå€‹çµ„ä»¶çš„ä¸¦ç™¼åˆå§‹åŒ–
            tasks = [
                self._performance_test_health_check(),
                self._performance_test_contract_validation(),
                self._performance_test_logging()
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            total_time = time.time() - start_time
            successful_tests = sum(1 for result in results if not isinstance(result, Exception))
            
            return {
                'passed': successful_tests >= len(tasks) * 0.8,  # 80%æˆåŠŸç‡
                'total_performance_time': total_time,
                'successful_tests': successful_tests,
                'total_tests': len(tasks),
                'performance_acceptable': total_time < 30,  # 30ç§’å…§å®Œæˆ
                'test_results': [
                    result if not isinstance(result, Exception) else {'error': str(result)}
                    for result in results
                ]
            }
            
        except Exception as e:
            return {
                'passed': False,
                'error': str(e)
            }
    
    async def _performance_test_health_check(self) -> Dict[str, Any]:
        """æ€§èƒ½æ¸¬è©¦ï¼šå¥åº·æª¢æŸ¥"""
        start_time = time.time()
        
        health_checker = UnifiedHealthChecker(self.project_root)
        
        # åŸ·è¡Œå¤šæ¬¡å¥åº·æª¢æŸ¥æ¸¬è©¦æ€§èƒ½
        for i in range(3):
            await health_checker.check_all_services()
        
        return {
            'test_type': 'health_check_performance',
            'iterations': 3,
            'total_time': time.time() - start_time,
            'avg_time_per_check': (time.time() - start_time) / 3
        }
    
    async def _performance_test_contract_validation(self) -> Dict[str, Any]:
        """æ€§èƒ½æ¸¬è©¦ï¼šå¥‘ç´„é©—è­‰"""
        start_time = time.time()
        
        validator = IntegrationContractValidator()
        
        # åŸ·è¡Œå¤šæ¬¡å¥‘ç´„é©—è­‰æ¸¬è©¦æ€§èƒ½
        for i in range(5):
            validator.validate_all_contracts()
        
        return {
            'test_type': 'contract_validation_performance',
            'iterations': 5,
            'total_time': time.time() - start_time,
            'avg_time_per_validation': (time.time() - start_time) / 5
        }
    
    async def _performance_test_logging(self) -> Dict[str, Any]:
        """æ€§èƒ½æ¸¬è©¦ï¼šæ—¥èªŒç³»çµ±"""
        start_time = time.time()
        
        test_logger = create_logger("performance-test", "logging")
        
        # è¨˜éŒ„å¤§é‡æ—¥èªŒæ¸¬è©¦æ€§èƒ½
        for i in range(50):
            test_logger.info(f"æ€§èƒ½æ¸¬è©¦æ—¥èªŒ #{i}")
        
        # ç­‰å¾…è™•ç†
        await asyncio.sleep(1)
        
        return {
            'test_type': 'logging_performance',
            'log_count': 50,
            'total_time': time.time() - start_time,
            'logs_per_second': 50 / (time.time() - start_time)
        }
    
    def _generate_validation_recommendations(self, validation_summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆé©—è­‰å»ºè­°"""
        recommendations = []
        
        success_rate = validation_summary.get('success_rate', 0)
        
        if success_rate >= 90:
            recommendations.append("ç³»çµ±æ•´åˆé©—è­‰å„ªç§€ï¼Œæ‰€æœ‰çµ„ä»¶å”ä½œè‰¯å¥½")
        elif success_rate >= 80:
            recommendations.append("ç³»çµ±æ•´åˆé©—è­‰è‰¯å¥½ï¼Œéƒ¨åˆ†é …ç›®éœ€è¦é—œæ³¨")
        else:
            recommendations.append("ç³»çµ±æ•´åˆé©—è­‰éœ€è¦æ”¹é€²ï¼Œå­˜åœ¨é—œéµå•é¡Œ")
        
        # æª¢æŸ¥å¤±æ•—çš„é©—è­‰
        failed_validations = []
        for test_name, result in validation_summary.get('integration_tests', {}).items():
            if not result.get('passed', False):
                failed_validations.append(test_name)
        
        if failed_validations:
            recommendations.append(f"éœ€è¦ä¿®å¾©çš„é©—è­‰é …ç›®: {', '.join(failed_validations)}")
        
        # æ€§èƒ½å»ºè­°
        duration = validation_summary.get('duration_seconds', 0)
        if duration > 60:
            recommendations.append("é©—è­‰æ™‚é–“è¼ƒé•·ï¼Œå»ºè­°å„ªåŒ–çµ„ä»¶åˆå§‹åŒ–é€Ÿåº¦")
        
        return recommendations
    
    async def _save_validation_report(self, validation_summary: Dict[str, Any]) -> None:
        """ä¿å­˜é©—è­‰å ±å‘Š"""
        report_file = self.project_root / 'logs' / f"system-validation-{validation_summary['validation_id']}.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(validation_summary, f, indent=2, ensure_ascii=False, default=str)
        
        self.validation_logger.info(f"é©—è­‰å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")


async def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ROAS Bot ç³»çµ±æ•´åˆé©—è­‰å·¥å…·')
    parser.add_argument('--project-root', type=Path, help='å°ˆæ¡ˆæ ¹ç›®éŒ„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')
    parser.add_argument('--output', '-o', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    # è¨­ç½®æ—¥èªŒ
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ç¢ºå®šå°ˆæ¡ˆæ ¹ç›®éŒ„
    project_root = args.project_root or Path.cwd()
    
    print(f"ğŸ” ROAS Bot v2.4.3 ç³»çµ±æ•´åˆé©—è­‰")
    print(f"å°ˆæ¡ˆæ ¹ç›®éŒ„: {project_root}")
    print(f"é–‹å§‹æ™‚é–“: {datetime.now()}")
    print("=" * 60)
    
    try:
        # åŸ·è¡Œç³»çµ±æ•´åˆé©—è­‰
        validator = SystemIntegrationValidator(project_root)
        validation_summary = await validator.run_complete_validation()
        
        # è¼¸å‡ºçµæœ
        print(f"\\n{'='*60}")
        print("ğŸ“Š ç³»çµ±æ•´åˆé©—è­‰çµæœ")
        print(f"{'='*60}")
        
        status_emoji = "âœ…" if validation_summary['overall_status'] == 'passed' else "âŒ"
        print(f"æ•´é«”ç‹€æ…‹: {status_emoji} {validation_summary['overall_status'].upper()}")
        print(f"æˆåŠŸç‡: {validation_summary['success_rate']:.1f}% ({validation_summary['passed_validations']}/{validation_summary['total_validations']})")
        print(f"é©—è­‰è€—æ™‚: {validation_summary['duration_seconds']:.1f} ç§’")
        
        # é©—è­‰é …ç›®è©³æƒ…
        print(f"\\né©—è­‰é …ç›®çµæœ:")
        for test_name, result in validation_summary.get('integration_tests', {}).items():
            status = "âœ…" if result.get('passed', False) else "âŒ"
            print(f"  {status} {test_name}")
            if not result.get('passed', False) and result.get('error'):
                print(f"    éŒ¯èª¤: {result['error']}")
        
        # å»ºè­°
        recommendations = validation_summary.get('recommendations', [])
        if recommendations:
            print(f"\\nğŸ’¡ å»ºè­°:")
            for rec in recommendations:
                print(f"  â€¢ {rec}")
        
        # ä¿å­˜è¼¸å‡º
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(validation_summary, f, indent=2, ensure_ascii=False, default=str)
            print(f"\\nğŸ“„ é©—è­‰çµæœå·²ä¿å­˜åˆ°: {args.output}")
        
        return 0 if validation_summary['overall_status'] == 'passed' else 1
        
    except KeyboardInterrupt:
        print("\\nâ¹ï¸ é©—è­‰å·²å–æ¶ˆ")
        return 130
    except Exception as e:
        print(f"âŒ é©—è­‰éç¨‹ç•°å¸¸: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(asyncio.run(main()))