"""
T2 - é«˜ä½µç™¼é€£ç·šç«¶çˆ­ä¿®å¾©
é€²éšä½µç™¼æ¸¬è©¦å ´æ™¯

æä¾›é€²éšä½µç™¼æ¸¬è©¦å ´æ™¯ï¼ŒåŒ…å«ï¼š
- è¤‡é›œè®€å¯«æ··åˆæ¨¡å¼
- äº‹å‹™ä½µç™¼å£“åŠ›æ¸¬è©¦  
- é€£ç·šæ± è€—ç›¡å’Œæ¢å¾©æ¸¬è©¦
- çªç™¼è² è¼‰æ¨¡å¼æ¸¬è©¦
"""

import asyncio
import logging
import os
import sys
import tempfile
import time
import uuid
import statistics
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
from pathlib import Path

# æ·»åŠ ç³»çµ±è·¯å¾‘æ”¯æŒ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

from services.connection_pool.connection_pool_manager import ConnectionPoolManager
from services.connection_pool.models import PoolConfiguration
from test_connection_pool import TestResult, ConcurrencyTestResult

logger = logging.getLogger('tests.concurrency.advanced_scenarios')


@dataclass
class AdvancedTestResult:
    """é€²éšæ¸¬è©¦çµæœè³‡æ–™çµæ§‹"""
    test_name: str
    scenario_type: str
    duration_seconds: float
    total_operations: int
    read_operations: int
    write_operations: int
    transaction_operations: int
    successful_operations: int
    failed_operations: int
    deadlock_count: int
    timeout_count: int
    connection_errors: int
    avg_response_time_ms: float
    p95_response_time_ms: float
    p99_response_time_ms: float
    operations_per_second: float
    concurrent_workers: int
    max_connections_used: int
    memory_usage_mb: float
    peak_memory_mb: float
    errors: List[str]
    timestamp: datetime
    
    @property
    def success_rate(self) -> float:
        """è¨ˆç®—æˆåŠŸç‡"""
        if self.total_operations == 0:
            return 0.0
        return self.successful_operations / self.total_operations
    
    @property
    def error_rate(self) -> float:
        """è¨ˆç®—éŒ¯èª¤ç‡"""
        if self.total_operations == 0:
            return 0.0
        return self.failed_operations / self.total_operations


class AdvancedConcurrencyTestSuite:
    """é€²éšä½µç™¼æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self, db_path: Optional[str] = None):
        """åˆå§‹åŒ–é€²éšæ¸¬è©¦å¥—ä»¶"""
        if db_path is None:
            self.temp_db = tempfile.NamedTemporaryFile(suffix='.db', delete=False)
            self.db_path = self.temp_db.name
            self.temp_db.close()
        else:
            self.db_path = db_path
        
        self.pool_manager: Optional[ConnectionPoolManager] = None
        self.results: List[AdvancedTestResult] = []
        
        logger.info(f"é€²éšæ¸¬è©¦è³‡æ–™åº«è·¯å¾‘ï¼š{self.db_path}")
    
    async def setup(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        config = PoolConfiguration(
            min_connections=3,
            max_connections=25,
            connection_timeout=30.0,
            acquire_timeout=15.0,
            enable_monitoring=True
        )
        
        self.pool_manager = ConnectionPoolManager(
            db_path=self.db_path,
            config=config
        )
        
        await self.pool_manager.start()
        await self._create_advanced_test_tables()
        logger.info("é€²éšæ¸¬è©¦ç’°å¢ƒè¨­ç½®å®Œæˆ")
    
    async def _create_advanced_test_tables(self):
        """å»ºç«‹é€²éšæ¸¬è©¦è¡¨æ ¼"""
        async with self.pool_manager.connection() as conn:
            # ç”¨æˆ¶è¡¨
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL UNIQUE,
                    email TEXT NOT NULL,
                    balance DECIMAL(10,2) DEFAULT 0.00,
                    status TEXT DEFAULT 'active',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # äº¤æ˜“è¡¨
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS transactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    transaction_type TEXT NOT NULL,
                    amount DECIMAL(10,2) NOT NULL,
                    description TEXT,
                    status TEXT DEFAULT 'pending',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id)
                )
            """)
            
            # ç”¢å“è¡¨
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS products (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL,
                    price DECIMAL(10,2) NOT NULL,
                    stock INTEGER DEFAULT 0,
                    category TEXT,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # è¨‚å–®è¡¨
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS orders (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    product_id INTEGER NOT NULL,
                    quantity INTEGER NOT NULL,
                    total_amount DECIMAL(10,2) NOT NULL,
                    status TEXT DEFAULT 'pending',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(id),
                    FOREIGN KEY (product_id) REFERENCES products(id)
                )
            """)
            
            # å»ºç«‹ç´¢å¼•
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_status ON users(status)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_transactions_user_id ON transactions(user_id)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_transactions_type ON transactions(transaction_type)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_orders_user_id ON orders(user_id)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_orders_status ON orders(status)")
            
            await conn.commit()
        
        logger.info("é€²éšæ¸¬è©¦è¡¨æ ¼å»ºç«‹å®Œæˆ")
    
    async def test_mixed_read_write_operations(
        self,
        num_workers: int = 20,
        test_duration: float = 60.0,
        read_write_ratio: float = 0.7  # 70% è®€å–ï¼Œ30% å¯«å…¥
    ) -> AdvancedTestResult:
        """æ¸¬è©¦æ··åˆè®€å¯«æ“ä½œ"""
        logger.info(f"é–‹å§‹æ··åˆè®€å¯«æ¸¬è©¦ï¼š{num_workers} å·¥ä½œè€…ï¼ŒæŒçºŒ {test_duration} ç§’")
        
        # å…ˆå¡«å……åŸºç¤è³‡æ–™
        await self._populate_advanced_test_data(1000)
        
        start_time = time.time()
        response_times = []
        errors = []
        successful_operations = 0
        failed_operations = 0
        read_operations = 0
        write_operations = 0
        
        async def worker_mixed_task(worker_id: int):
            """æ··åˆè®€å¯«å·¥ä½œè€…"""
            nonlocal successful_operations, failed_operations, read_operations, write_operations
            nonlocal response_times, errors
            
            operation_count = 0
            while (time.time() - start_time) < test_duration:
                operation_start = time.time()
                
                try:
                    import random
                    is_read = random.random() < read_write_ratio
                    
                    async with self.pool_manager.connection() as conn:
                        if is_read:
                            # è¤‡é›œè®€å–æ“ä½œ
                            user_id = random.randint(1, 1000)
                            async with conn.execute("""
                                SELECT u.username, u.balance, 
                                       COUNT(t.id) as transaction_count,
                                       COUNT(o.id) as order_count,
                                       SUM(t.amount) as total_transactions
                                FROM users u 
                                LEFT JOIN transactions t ON u.id = t.user_id
                                LEFT JOIN orders o ON u.id = o.user_id
                                WHERE u.id = ?
                                GROUP BY u.id
                            """, (user_id,)) as cursor:
                                result = await cursor.fetchone()
                            
                            read_operations += 1
                        else:
                            # å¯«å…¥æ“ä½œ
                            operation_type = random.choice(['user_update', 'transaction_insert', 'order_create'])
                            
                            if operation_type == 'user_update':
                                user_id = random.randint(1, 1000)
                                new_balance = random.uniform(0, 1000)
                                await conn.execute("""
                                    UPDATE users SET balance = ?, updated_at = CURRENT_TIMESTAMP 
                                    WHERE id = ?
                                """, (new_balance, user_id))
                                
                            elif operation_type == 'transaction_insert':
                                user_id = random.randint(1, 1000)
                                amount = random.uniform(1, 100)
                                await conn.execute("""
                                    INSERT INTO transactions (user_id, transaction_type, amount, description)
                                    VALUES (?, ?, ?, ?)
                                """, (user_id, 'credit', amount, f'Transaction by worker {worker_id}'))
                                
                            elif operation_type == 'order_create':
                                user_id = random.randint(1, 1000)
                                product_id = random.randint(1, 100)
                                quantity = random.randint(1, 5)
                                price = random.uniform(10, 100)
                                total = quantity * price
                                
                                await conn.execute("""
                                    INSERT INTO orders (user_id, product_id, quantity, total_amount)
                                    VALUES (?, ?, ?, ?)
                                """, (user_id, product_id, quantity, total))
                            
                            await conn.commit()
                            write_operations += 1
                        
                        successful_operations += 1
                        operation_time = (time.time() - operation_start) * 1000
                        response_times.append(operation_time)
                
                except Exception as e:
                    failed_operations += 1
                    error_msg = f"Worker {worker_id} æ“ä½œå¤±æ•—ï¼š{str(e)}"
                    errors.append(error_msg)
                    logger.debug(error_msg)
                
                operation_count += 1
                
                # çŸ­æš«å»¶é²é¿å…éåº¦å ç”¨
                await asyncio.sleep(0.001)
        
        # å•Ÿå‹•å·¥ä½œè€…
        tasks = [worker_mixed_task(i) for i in range(num_workers)]
        await asyncio.gather(*tasks)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # è¨ˆç®—çµ±è¨ˆ
        total_operations = successful_operations + failed_operations
        ops_per_second = total_operations / duration if duration > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else avg_response_time
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else avg_response_time
        
        # ç²å–é€£ç·šæ± çµ±è¨ˆ
        pool_stats = self.pool_manager.get_pool_stats()
        max_connections_used = pool_stats['active_connections'] + pool_stats['idle_connections']
        
        result = AdvancedTestResult(
            test_name="mixed_read_write_operations",
            scenario_type="mixed_workload",
            duration_seconds=duration,
            total_operations=total_operations,
            read_operations=read_operations,
            write_operations=write_operations,
            transaction_operations=0,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            deadlock_count=0,
            timeout_count=0,
            connection_errors=0,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            operations_per_second=ops_per_second,
            concurrent_workers=num_workers,
            max_connections_used=max_connections_used,
            memory_usage_mb=0.0,  # TODO: å¯¦éš›è¨˜æ†¶é«”ç›£æ§
            peak_memory_mb=0.0,
            errors=errors[:10],
            timestamp=datetime.now()
        )
        
        self.results.append(result)
        
        logger.info(
            f"æ··åˆè®€å¯«æ¸¬è©¦å®Œæˆï¼š{successful_operations}/{total_operations} æˆåŠŸï¼Œ"
            f"è®€å– {read_operations}ï¼Œå¯«å…¥ {write_operations}ï¼Œ"
            f"ååé‡ {ops_per_second:.2f} ops/sï¼Œ"
            f"éŒ¯èª¤ç‡ {result.error_rate:.2%}"
        )
        
        return result
    
    async def test_transaction_stress(
        self,
        num_workers: int = 15,
        test_duration: float = 45.0
    ) -> AdvancedTestResult:
        """æ¸¬è©¦äº‹å‹™ä½µç™¼å£“åŠ›"""
        logger.info(f"é–‹å§‹äº‹å‹™ä½µç™¼æ¸¬è©¦ï¼š{num_workers} å·¥ä½œè€…ï¼ŒæŒçºŒ {test_duration} ç§’")
        
        await self._populate_advanced_test_data(500)
        
        start_time = time.time()
        response_times = []
        errors = []
        successful_operations = 0
        failed_operations = 0
        transaction_operations = 0
        deadlock_count = 0
        timeout_count = 0
        
        async def worker_transaction_task(worker_id: int):
            """äº‹å‹™å£“åŠ›å·¥ä½œè€…"""
            nonlocal successful_operations, failed_operations, transaction_operations
            nonlocal deadlock_count, timeout_count, response_times, errors
            
            while (time.time() - start_time) < test_duration:
                operation_start = time.time()
                
                try:
                    async with self.pool_manager.connection() as conn:
                        # é–‹å§‹äº‹å‹™
                        await conn.execute("BEGIN IMMEDIATE")
                        
                        try:
                            import random
                            # æ¨¡æ“¬è¤‡é›œäº‹å‹™ï¼šè½‰å¸³æ“ä½œ
                            from_user_id = random.randint(1, 500)
                            to_user_id = random.randint(1, 500)
                            if from_user_id == to_user_id:
                                continue
                            
                            amount = random.uniform(1, 50)
                            
                            # æª¢æŸ¥é¤˜é¡
                            async with conn.execute("SELECT balance FROM users WHERE id = ?", (from_user_id,)) as cursor:
                                from_balance_row = await cursor.fetchone()
                                if not from_balance_row or from_balance_row['balance'] < amount:
                                    await conn.execute("ROLLBACK")
                                    continue
                            
                            # æ‰£é™¤ç™¼é€æ–¹é¤˜é¡
                            await conn.execute("""
                                UPDATE users SET balance = balance - ?, updated_at = CURRENT_TIMESTAMP
                                WHERE id = ? AND balance >= ?
                            """, (amount, from_user_id, amount))
                            
                            # å¢åŠ æ¥æ”¶æ–¹é¤˜é¡
                            await conn.execute("""
                                UPDATE users SET balance = balance + ?, updated_at = CURRENT_TIMESTAMP
                                WHERE id = ?
                            """, (amount, to_user_id))
                            
                            # è¨˜éŒ„äº¤æ˜“
                            await conn.execute("""
                                INSERT INTO transactions (user_id, transaction_type, amount, description)
                                VALUES (?, ?, ?, ?)
                            """, (from_user_id, 'debit', -amount, f'Transfer to user {to_user_id}'))
                            
                            await conn.execute("""
                                INSERT INTO transactions (user_id, transaction_type, amount, description)
                                VALUES (?, ?, ?, ?)
                            """, (to_user_id, 'credit', amount, f'Transfer from user {from_user_id}'))
                            
                            # æäº¤äº‹å‹™
                            await conn.commit()
                            transaction_operations += 1
                            successful_operations += 1
                            
                        except Exception as tx_error:
                            await conn.execute("ROLLBACK")
                            
                            error_str = str(tx_error).lower()
                            if 'deadlock' in error_str or 'locked' in error_str:
                                deadlock_count += 1
                            elif 'timeout' in error_str:
                                timeout_count += 1
                            
                            raise tx_error
                        
                        operation_time = (time.time() - operation_start) * 1000
                        response_times.append(operation_time)
                
                except Exception as e:
                    failed_operations += 1
                    error_msg = f"Transaction Worker {worker_id} å¤±æ•—ï¼š{str(e)}"
                    errors.append(error_msg)
                    logger.debug(error_msg)
                
                # çŸ­æš«å»¶é²
                await asyncio.sleep(0.005)
        
        # å•Ÿå‹•å·¥ä½œè€…
        tasks = [worker_transaction_task(i) for i in range(num_workers)]
        await asyncio.gather(*tasks)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # è¨ˆç®—çµ±è¨ˆ
        total_operations = successful_operations + failed_operations
        ops_per_second = total_operations / duration if duration > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else avg_response_time
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else avg_response_time
        
        pool_stats = self.pool_manager.get_pool_stats()
        max_connections_used = pool_stats['active_connections'] + pool_stats['idle_connections']
        
        result = AdvancedTestResult(
            test_name="transaction_stress",
            scenario_type="transaction_concurrency",
            duration_seconds=duration,
            total_operations=total_operations,
            read_operations=0,
            write_operations=transaction_operations * 4,  # æ¯å€‹äº‹å‹™åŒ…å«å¤šå€‹å¯«å…¥
            transaction_operations=transaction_operations,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            deadlock_count=deadlock_count,
            timeout_count=timeout_count,
            connection_errors=0,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            operations_per_second=ops_per_second,
            concurrent_workers=num_workers,
            max_connections_used=max_connections_used,
            memory_usage_mb=0.0,
            peak_memory_mb=0.0,
            errors=errors[:10],
            timestamp=datetime.now()
        )
        
        self.results.append(result)
        
        logger.info(
            f"äº‹å‹™ä½µç™¼æ¸¬è©¦å®Œæˆï¼š{successful_operations}/{total_operations} æˆåŠŸï¼Œ"
            f"äº‹å‹™æ•¸ {transaction_operations}ï¼Œæ­»é– {deadlock_count}ï¼Œ"
            f"ååé‡ {ops_per_second:.2f} ops/sï¼Œ"
            f"éŒ¯èª¤ç‡ {result.error_rate:.2%}"
        )
        
        return result
    
    async def test_connection_pool_exhaustion(
        self,
        max_workers: int = 30,
        test_duration: float = 30.0
    ) -> AdvancedTestResult:
        """æ¸¬è©¦é€£ç·šæ± è€—ç›¡å ´æ™¯"""
        logger.info(f"é–‹å§‹é€£ç·šæ± è€—ç›¡æ¸¬è©¦ï¼š{max_workers} å·¥ä½œè€…ï¼ŒæŒçºŒ {test_duration} ç§’")
        
        start_time = time.time()
        response_times = []
        errors = []
        successful_operations = 0
        failed_operations = 0
        connection_errors = 0
        timeout_count = 0
        
        async def worker_exhaustion_task(worker_id: int):
            """é€£ç·šæ± è€—ç›¡æ¸¬è©¦å·¥ä½œè€…"""
            nonlocal successful_operations, failed_operations, connection_errors
            nonlocal timeout_count, response_times, errors
            
            while (time.time() - start_time) < test_duration:
                operation_start = time.time()
                
                try:
                    # æ•…æ„æŒæœ‰é€£ç·šè¼ƒé•·æ™‚é–“ä¾†è£½é€ å£“åŠ›
                    connection = await self.pool_manager.get_connection()
                    
                    try:
                        # æ¨¡æ“¬è¼ƒé•·æ™‚é–“çš„æ“ä½œ
                        await asyncio.sleep(0.1)  # 100ms çš„æ¨¡æ“¬æ“ä½œ
                        
                        async with connection.execute("SELECT COUNT(*) as count FROM users") as cursor:
                            result = await cursor.fetchone()
                        
                        successful_operations += 1
                        operation_time = (time.time() - operation_start) * 1000
                        response_times.append(operation_time)
                        
                    finally:
                        await self.pool_manager.release_connection(connection)
                
                except TimeoutError:
                    timeout_count += 1
                    failed_operations += 1
                    errors.append(f"Worker {worker_id} é€£ç·šç²å–è¶…æ™‚")
                    
                except Exception as e:
                    failed_operations += 1
                    error_str = str(e).lower()
                    if 'connection' in error_str or 'pool' in error_str:
                        connection_errors += 1
                    
                    error_msg = f"Pool Worker {worker_id} å¤±æ•—ï¼š{str(e)}"
                    errors.append(error_msg)
                    logger.debug(error_msg)
                
                # é¿å…éåº¦ç«¶çˆ­
                await asyncio.sleep(0.01)
        
        # å•Ÿå‹•å·¥ä½œè€…
        tasks = [worker_exhaustion_task(i) for i in range(max_workers)]
        await asyncio.gather(*tasks)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # è¨ˆç®—çµ±è¨ˆ
        total_operations = successful_operations + failed_operations
        ops_per_second = total_operations / duration if duration > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else avg_response_time
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else avg_response_time
        
        pool_stats = self.pool_manager.get_pool_stats()
        max_connections_used = pool_stats['active_connections'] + pool_stats['idle_connections']
        
        result = AdvancedTestResult(
            test_name="connection_pool_exhaustion",
            scenario_type="resource_stress",
            duration_seconds=duration,
            total_operations=total_operations,
            read_operations=successful_operations,
            write_operations=0,
            transaction_operations=0,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            deadlock_count=0,
            timeout_count=timeout_count,
            connection_errors=connection_errors,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            operations_per_second=ops_per_second,
            concurrent_workers=max_workers,
            max_connections_used=max_connections_used,
            memory_usage_mb=0.0,
            peak_memory_mb=0.0,
            errors=errors[:10],
            timestamp=datetime.now()
        )
        
        self.results.append(result)
        
        logger.info(
            f"é€£ç·šæ± è€—ç›¡æ¸¬è©¦å®Œæˆï¼š{successful_operations}/{total_operations} æˆåŠŸï¼Œ"
            f"é€£ç·šéŒ¯èª¤ {connection_errors}ï¼Œè¶…æ™‚ {timeout_count}ï¼Œ"
            f"ååé‡ {ops_per_second:.2f} ops/sï¼Œ"
            f"éŒ¯èª¤ç‡ {result.error_rate:.2%}"
        )
        
        return result
    
    async def test_load_burst_patterns(
        self,
        test_duration: float = 45.0,
        burst_intervals: int = 5
    ) -> AdvancedTestResult:
        """æ¸¬è©¦çªç™¼è² è¼‰æ¨¡å¼"""
        logger.info(f"é–‹å§‹çªç™¼è² è¼‰æ¸¬è©¦ï¼šæŒçºŒ {test_duration} ç§’ï¼Œ{burst_intervals} å€‹çªç™¼é€±æœŸ")
        
        await self._populate_advanced_test_data(200)
        
        start_time = time.time()
        response_times = []
        errors = []
        successful_operations = 0
        failed_operations = 0
        
        burst_duration = test_duration / burst_intervals
        
        async def burst_phase(burst_id: int, workers: int):
            """å–®å€‹çªç™¼éšæ®µ"""
            nonlocal successful_operations, failed_operations, response_times, errors
            
            logger.info(f"çªç™¼éšæ®µ {burst_id + 1}: {workers} å·¥ä½œè€…")
            
            async def burst_worker(worker_id: int):
                """çªç™¼å·¥ä½œè€…"""
                burst_start = time.time()
                burst_ops = 0
                
                while (time.time() - burst_start) < burst_duration:
                    operation_start = time.time()
                    
                    try:
                        async with self.pool_manager.connection() as conn:
                            import random
                            
                            # éš¨æ©Ÿé¸æ“‡æ“ä½œé¡å‹
                            op_type = random.choice(['read_heavy', 'write_heavy', 'mixed'])
                            
                            if op_type == 'read_heavy':
                                # é‡è®€å–æ“ä½œ
                                async with conn.execute("""
                                    SELECT u.*, 
                                           COUNT(t.id) as tx_count,
                                           AVG(t.amount) as avg_amount
                                    FROM users u
                                    LEFT JOIN transactions t ON u.id = t.user_id
                                    WHERE u.status = 'active'
                                    GROUP BY u.id
                                    ORDER BY u.balance DESC
                                    LIMIT 20
                                """) as cursor:
                                    results = await cursor.fetchall()
                                    
                            elif op_type == 'write_heavy':
                                # é‡å¯«å…¥æ“ä½œ
                                user_id = random.randint(1, 200)
                                for _ in range(3):  # æ‰¹é‡å¯«å…¥
                                    await conn.execute("""
                                        INSERT INTO transactions (user_id, transaction_type, amount)
                                        VALUES (?, ?, ?)
                                    """, (user_id, 'burst_test', random.uniform(1, 20)))
                                await conn.commit()
                                
                            else:
                                # æ··åˆæ“ä½œ
                                async with conn.execute("SELECT COUNT(*) FROM users") as cursor:
                                    count = await cursor.fetchone()
                                
                                await conn.execute("""
                                    INSERT INTO transactions (user_id, transaction_type, amount)
                                    VALUES (?, ?, ?)
                                """, (random.randint(1, 200), 'mixed_burst', 5.0))
                                await conn.commit()
                            
                            successful_operations += 1
                            burst_ops += 1
                            operation_time = (time.time() - operation_start) * 1000
                            response_times.append(operation_time)
                    
                    except Exception as e:
                        failed_operations += 1
                        error_msg = f"Burst {burst_id} Worker {worker_id} å¤±æ•—ï¼š{str(e)}"
                        errors.append(error_msg)
                        logger.debug(error_msg)
                    
                    # çŸ­æš«å»¶é²
                    await asyncio.sleep(0.002)
                
                logger.debug(f"çªç™¼å·¥ä½œè€… {worker_id} å®Œæˆ {burst_ops} æ“ä½œ")
            
            # éšæ¢¯å¼å¢åŠ å·¥ä½œè€…æ•¸é‡
            worker_counts = [5, 10, 15, 20, 25]
            current_workers = worker_counts[burst_id % len(worker_counts)]
            
            # å•Ÿå‹•çªç™¼å·¥ä½œè€…
            tasks = [burst_worker(i) for i in range(current_workers)]
            await asyncio.gather(*tasks)
            
            # çªç™¼é–“éš”
            if burst_id < burst_intervals - 1:
                await asyncio.sleep(1.0)  # çªç™¼é–“çš„å†·å»æ™‚é–“
        
        # åŸ·è¡Œçªç™¼é€±æœŸ
        for burst_id in range(burst_intervals):
            await burst_phase(burst_id, (burst_id + 1) * 5)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # è¨ˆç®—çµ±è¨ˆ
        total_operations = successful_operations + failed_operations
        ops_per_second = total_operations / duration if duration > 0 else 0
        avg_response_time = statistics.mean(response_times) if response_times else 0
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) >= 20 else avg_response_time
        p99_response_time = statistics.quantiles(response_times, n=100)[98] if len(response_times) >= 100 else avg_response_time
        
        pool_stats = self.pool_manager.get_pool_stats()
        max_connections_used = pool_stats['active_connections'] + pool_stats['idle_connections']
        
        result = AdvancedTestResult(
            test_name="load_burst_patterns",
            scenario_type="burst_load",
            duration_seconds=duration,
            total_operations=total_operations,
            read_operations=total_operations // 3,  # ä¼°ç®—
            write_operations=total_operations - (total_operations // 3),
            transaction_operations=0,
            successful_operations=successful_operations,
            failed_operations=failed_operations,
            deadlock_count=0,
            timeout_count=0,
            connection_errors=0,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            operations_per_second=ops_per_second,
            concurrent_workers=25,  # æœ€å¤§å·¥ä½œè€…æ•¸
            max_connections_used=max_connections_used,
            memory_usage_mb=0.0,
            peak_memory_mb=0.0,
            errors=errors[:15],
            timestamp=datetime.now()
        )
        
        self.results.append(result)
        
        logger.info(
            f"çªç™¼è² è¼‰æ¸¬è©¦å®Œæˆï¼š{successful_operations}/{total_operations} æˆåŠŸï¼Œ"
            f"{burst_intervals} å€‹çªç™¼é€±æœŸï¼Œ"
            f"ååé‡ {ops_per_second:.2f} ops/sï¼Œ"
            f"éŒ¯èª¤ç‡ {result.error_rate:.2%}"
        )
        
        return result
    
    async def _populate_advanced_test_data(self, num_users: int):
        """å¡«å……é€²éšæ¸¬è©¦è³‡æ–™"""
        logger.info(f"å¡«å……é€²éšæ¸¬è©¦è³‡æ–™ï¼š{num_users} å€‹ç”¨æˆ¶")
        
        async with self.pool_manager.connection() as conn:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰è³‡æ–™
            async with conn.execute("SELECT COUNT(*) as count FROM users") as cursor:
                existing = await cursor.fetchone()
                if existing and existing['count'] >= num_users:
                    logger.info("é€²éšæ¸¬è©¦è³‡æ–™å·²å­˜åœ¨ï¼Œè·³éå¡«å……")
                    return
            
            # æ‰¹é‡æ’å…¥ç”¨æˆ¶
            users_data = []
            for i in range(num_users):
                username = f"adv_user_{i:06d}"
                email = f"{username}@advanced.test"
                balance = 100.0 + (i % 500)
                status = 'active' if i % 10 != 0 else 'inactive'
                users_data.append((username, email, balance, status))
            
            # ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥
            await conn.executemany("""
                INSERT OR IGNORE INTO users (username, email, balance, status) 
                VALUES (?, ?, ?, ?)
            """, users_data)
            
            # æ’å…¥ç”¢å“è³‡æ–™
            products_data = []
            categories = ['electronics', 'books', 'clothing', 'home', 'sports']
            for i in range(100):
                name = f"Product_{i:03d}"
                price = 10.0 + (i % 200)
                stock = 100 + (i % 50)
                category = categories[i % len(categories)]
                products_data.append((name, price, stock, category))
            
            await conn.executemany("""
                INSERT OR IGNORE INTO products (name, price, stock, category)
                VALUES (?, ?, ?, ?)
            """, products_data)
            
            await conn.commit()
        
        logger.info("é€²éšæ¸¬è©¦è³‡æ–™å¡«å……å®Œæˆ")
    
    async def cleanup(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        if self.pool_manager:
            await self.pool_manager.stop()
        
        # æ¸…ç†è‡¨æ™‚è³‡æ–™åº«æª”æ¡ˆ
        if hasattr(self, 'temp_db'):
            try:
                os.unlink(self.db_path)
                logger.info("é€²éšæ¸¬è©¦è‡¨æ™‚è³‡æ–™åº«å·²æ¸…ç†")
            except OSError:
                logger.warning(f"ç„¡æ³•åˆªé™¤é€²éšæ¸¬è©¦è‡¨æ™‚è³‡æ–™åº«æª”æ¡ˆï¼š{self.db_path}")


class AdvancedPerformanceAnalyzer:
    """é€²éšæ•ˆèƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.analysis_results = {}
    
    def analyze_advanced_results(self, results: List[AdvancedTestResult]) -> Dict[str, Any]:
        """åˆ†æé€²éšæ¸¬è©¦çµæœ"""
        if not results:
            return {"error": "ç„¡æ¸¬è©¦çµæœå¯åˆ†æ"}
        
        # æŒ‰æ¸¬è©¦é¡å‹åˆ†çµ„
        by_scenario = {}
        for result in results:
            if result.scenario_type not in by_scenario:
                by_scenario[result.scenario_type] = []
            by_scenario[result.scenario_type].append(result)
        
        # ç¸½é«”æ•ˆèƒ½åˆ†æ
        total_operations = sum(r.total_operations for r in results)
        total_successful = sum(r.successful_operations for r in results)
        total_failed = sum(r.failed_operations for r in results)
        
        success_rates = [r.success_rate for r in results]
        response_times = [r.avg_response_time_ms for r in results]
        p95_times = [r.p95_response_time_ms for r in results]
        
        # T2 æ¨™æº–é©—è­‰
        t2_passing = 0
        for result in results:
            if (result.error_rate <= 0.01 and 
                result.p95_response_time_ms <= 50.0 and
                result.success_rate >= 0.99):
                t2_passing += 1
        
        analysis = {
            "analysis_timestamp": datetime.now().isoformat(),
            "overall_performance": {
                "scenarios_total": len(results),
                "scenarios_passing": t2_passing,
                "t2_compliance_rate": (t2_passing / len(results)) * 100,
                "total_operations": total_operations,
                "overall_success_rate": (total_successful / total_operations) * 100 if total_operations > 0 else 0,
                "overall_error_rate": (total_failed / total_operations) * 100 if total_operations > 0 else 0,
                "average_success_rate": statistics.mean(success_rates) * 100,
                "average_response_time_ms": statistics.mean(response_times),
                "average_p95_response_time_ms": statistics.mean(p95_times)
            },
            "scenario_analysis": {},
            "performance_insights": [],
            "recommendations": []
        }
        
        # æŒ‰å ´æ™¯åˆ†æ
        for scenario_type, scenario_results in by_scenario.items():
            scenario_analysis = self._analyze_scenario(scenario_type, scenario_results)
            analysis["scenario_analysis"][scenario_type] = scenario_analysis
        
        # ç”Ÿæˆæ´å¯Ÿå’Œå»ºè­°
        analysis["performance_insights"] = self._generate_insights(results, analysis)
        analysis["recommendations"] = self._generate_recommendations(results, analysis)
        
        return analysis
    
    def _analyze_scenario(self, scenario_type: str, results: List[AdvancedTestResult]) -> Dict[str, Any]:
        """åˆ†æç‰¹å®šå ´æ™¯"""
        if not results:
            return {}
        
        success_rates = [r.success_rate for r in results]
        error_rates = [r.error_rate for r in results]
        response_times = [r.avg_response_time_ms for r in results]
        throughputs = [r.operations_per_second for r in results]
        
        return {
            "test_count": len(results),
            "average_success_rate": statistics.mean(success_rates) * 100,
            "average_error_rate": statistics.mean(error_rates) * 100,
            "average_response_time_ms": statistics.mean(response_times),
            "average_throughput": statistics.mean(throughputs),
            "max_throughput": max(throughputs),
            "min_response_time": min(response_times),
            "max_response_time": max(response_times),
            "special_metrics": self._get_special_metrics(scenario_type, results)
        }
    
    def _get_special_metrics(self, scenario_type: str, results: List[AdvancedTestResult]) -> Dict[str, Any]:
        """ç²å–å ´æ™¯ç‰¹å®šæŒ‡æ¨™"""
        if scenario_type == "transaction_concurrency":
            return {
                "total_transactions": sum(r.transaction_operations for r in results),
                "total_deadlocks": sum(r.deadlock_count for r in results),
                "total_timeouts": sum(r.timeout_count for r in results),
                "deadlock_rate": sum(r.deadlock_count for r in results) / sum(r.total_operations for r in results) * 100
            }
        elif scenario_type == "resource_stress":
            return {
                "total_connection_errors": sum(r.connection_errors for r in results),
                "total_timeouts": sum(r.timeout_count for r in results),
                "max_connections_used": max(r.max_connections_used for r in results)
            }
        elif scenario_type == "mixed_workload":
            return {
                "total_read_ops": sum(r.read_operations for r in results),
                "total_write_ops": sum(r.write_operations for r in results),
                "read_write_ratio": sum(r.read_operations for r in results) / sum(r.write_operations for r in results) if sum(r.write_operations for r in results) > 0 else 0
            }
        else:
            return {}
    
    def _generate_insights(self, results: List[AdvancedTestResult], analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ•ˆèƒ½æ´å¯Ÿ"""
        insights = []
        
        overall = analysis["overall_performance"]
        
        if overall["t2_compliance_rate"] == 100:
            insights.append("ğŸ‰ æ‰€æœ‰é€²éšæ¸¬è©¦éƒ½ç¬¦åˆ T2 æ•ˆèƒ½æ¨™æº–")
        elif overall["t2_compliance_rate"] >= 80:
            insights.append(f"âœ… {overall['t2_compliance_rate']:.1f}% çš„æ¸¬è©¦ç¬¦åˆ T2 æ¨™æº–ï¼Œæ•´é«”è¡¨ç¾è‰¯å¥½")
        else:
            insights.append(f"âš ï¸ åƒ… {overall['t2_compliance_rate']:.1f}% çš„æ¸¬è©¦ç¬¦åˆ T2 æ¨™æº–ï¼Œéœ€è¦å„ªåŒ–")
        
        if overall["average_response_time_ms"] > 30:
            insights.append(f"ğŸ“ˆ å¹³å‡éŸ¿æ‡‰æ™‚é–“ {overall['average_response_time_ms']:.1f}ms åé«˜ï¼Œå»ºè­°å„ªåŒ–")
        
        if overall["overall_error_rate"] > 2:
            insights.append(f"ğŸš¨ éŒ¯èª¤ç‡ {overall['overall_error_rate']:.2f}% è¶…éå»ºè­°å€¼ï¼Œéœ€è¦æª¢æŸ¥ç©©å®šæ€§")
        
        # å ´æ™¯ç‰¹å®šæ´å¯Ÿ
        for scenario_type, scenario_data in analysis["scenario_analysis"].items():
            if scenario_type == "transaction_concurrency":
                special = scenario_data.get("special_metrics", {})
                if special.get("deadlock_rate", 0) > 1:
                    insights.append(f"âš¡ äº‹å‹™ä¸¦ç™¼æ­»é–ç‡ {special['deadlock_rate']:.2f}% è¼ƒé«˜ï¼Œå»ºè­°å„ªåŒ–äº‹å‹™é‚è¼¯")
            
            elif scenario_type == "resource_stress":
                if scenario_data["average_error_rate"] > 5:
                    insights.append("ğŸ’¥ è³‡æºå£“åŠ›æ¸¬è©¦éŒ¯èª¤ç‡è¼ƒé«˜ï¼Œé€£ç·šæ± é…ç½®å¯èƒ½éœ€è¦èª¿æ•´")
        
        return insights
    
    def _generate_recommendations(self, results: List[AdvancedTestResult], analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        overall = analysis["overall_performance"]
        
        # åŸºæ–¼æ•´é«”æ•ˆèƒ½çš„å»ºè­°
        if overall["average_p95_response_time_ms"] > 50:
            recommendations.append("èª¿æ•´é€£ç·šæ± å¤§å°ï¼Œå¢åŠ  max_connections åƒæ•¸")
            recommendations.append("å„ªåŒ–è³‡æ–™åº«æŸ¥è©¢ï¼Œæ·»åŠ å¿…è¦çš„ç´¢å¼•")
        
        if overall["overall_error_rate"] > 1:
            recommendations.append("å¢åŠ é‡è©¦æ©Ÿåˆ¶å’ŒéŒ¯èª¤è™•ç†é‚è¼¯")
            recommendations.append("æª¢æŸ¥é€£ç·šè¶…æ™‚è¨­å®šï¼Œé©ç•¶å¢åŠ  acquire_timeout")
        
        # åŸºæ–¼å ´æ™¯çš„å»ºè­°
        for scenario_type, scenario_data in analysis["scenario_analysis"].items():
            if scenario_type == "transaction_concurrency":
                special = scenario_data.get("special_metrics", {})
                if special.get("deadlock_rate", 0) > 0.5:
                    recommendations.append("å„ªåŒ–äº‹å‹™é‚è¼¯ï¼Œæ¸›å°‘é•·æ™‚é–“æŒæœ‰é–")
                    recommendations.append("è€ƒæ…®ä½¿ç”¨æ¨‚è§€é–æ›¿ä»£æ‚²è§€é–")
            
            elif scenario_type == "resource_stress" and scenario_data["average_error_rate"] > 3:
                recommendations.append("å¢åŠ é€£ç·šæ± ç›£æ§å’Œå‹•æ…‹èª¿æ•´æ©Ÿåˆ¶")
                recommendations.append("å¯¦æ–½é€£ç·šæ± é ç†±ç­–ç•¥")
            
            elif scenario_type == "burst_load":
                if scenario_data["max_response_time"] > 100:
                    recommendations.append("å¯¦æ–½è«‹æ±‚æ’éšŠå’Œé™æµæ©Ÿåˆ¶")
                    recommendations.append("è€ƒæ…®ä½¿ç”¨é€£ç·šæ± å½ˆæ€§æ“´ç¸®å®¹")
        
        # é€šç”¨å»ºè­°
        if len(recommendations) == 0:
            recommendations.append("ç³»çµ±æ•ˆèƒ½è¡¨ç¾è‰¯å¥½ï¼Œå¯è€ƒæ…®é€²ä¸€æ­¥èª¿æ•´ä»¥é”åˆ°æ¥µè‡´æ•ˆèƒ½")
        
        return recommendations


# è¼”åŠ©å‡½æ•¸
async def run_advanced_concurrency_tests() -> List[AdvancedTestResult]:
    """åŸ·è¡Œé€²éšä½µç™¼æ¸¬è©¦å¥—ä»¶"""
    suite = AdvancedConcurrencyTestSuite()
    
    try:
        await suite.setup()
        
        results = []
        
        # æ··åˆè®€å¯«æ¸¬è©¦
        result1 = await suite.test_mixed_read_write_operations(num_workers=20, test_duration=60.0)
        results.append(result1)
        
        # äº‹å‹™ä½µç™¼æ¸¬è©¦
        result2 = await suite.test_transaction_stress(num_workers=15, test_duration=45.0)
        results.append(result2)
        
        # é€£ç·šæ± è€—ç›¡æ¸¬è©¦
        result3 = await suite.test_connection_pool_exhaustion(max_workers=30, test_duration=30.0)
        results.append(result3)
        
        # çªç™¼è² è¼‰æ¸¬è©¦
        result4 = await suite.test_load_burst_patterns(test_duration=45.0, burst_intervals=5)
        results.append(result4)
        
        return results
        
    finally:
        await suite.cleanup()