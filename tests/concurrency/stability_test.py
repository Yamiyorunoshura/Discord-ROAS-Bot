#!/usr/bin/env python3
"""
T2 - é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦
æ¸¬è©¦é€£ç·šæ± åœ¨é•·æ™‚é–“é«˜ä½µç™¼è² è¼‰ä¸‹çš„ç©©å®šæ€§å’ŒéŒ¯èª¤ç‡æ§åˆ¶
"""

import asyncio
import logging
import sys
import tempfile
import time
import random
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from services.connection_pool.connection_pool_manager import ConnectionPoolManager
from services.connection_pool.models import PoolConfiguration
from error_rate_monitor import ErrorRateMonitor, ConcurrencyTestReporter, PerformanceThresholds

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class LongRunningStabilityTest:
    """é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self, db_path: str = None):
        if db_path is None:
            self.temp_db = tempfile.NamedTemporaryFile(suffix='.db', delete=False)
            self.db_path = self.temp_db.name
            self.temp_db.close()
        else:
            self.db_path = db_path
        
        # é…ç½®é€£ç·šæ±  - é‡å°é•·æ™‚é–“é‹è¡Œå„ªåŒ–
        self.pool_config = PoolConfiguration(
            min_connections=5,
            max_connections=30,
            connection_timeout=20.0,
            acquire_timeout=15.0,
            idle_timeout=600.0,  # 10åˆ†é˜ç©ºé–’è¶…æ™‚
            enable_monitoring=True,
            stats_collection_interval=30  # 30ç§’æ”¶é›†ä¸€æ¬¡çµ±è¨ˆ
        )
        
        self.pool_manager = None
        self.monitor = ErrorRateMonitor(
            thresholds=PerformanceThresholds(
                max_error_rate=1.0,
                max_p95_response_time_ms=100.0,  # é•·æ™‚é–“æ¸¬è©¦æ”¾å¯¬è‡³100ms
                min_success_rate=98.0,  # æ”¾å¯¬è‡³98%
                max_concurrent_failures=3,
                alert_error_rate=0.8
            )
        )
        self.reporter = ConcurrencyTestReporter()
    
    async def setup(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        logger.info(f"è¨­ç½®é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ç’°å¢ƒ - è³‡æ–™åº«: {self.db_path}")
        
        self.pool_manager = ConnectionPoolManager(
            db_path=self.db_path,
            config=self.pool_config
        )
        
        await self.pool_manager.start()
        
        # å»ºç«‹æ¸¬è©¦è¡¨
        async with self.pool_manager.connection() as conn:
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS stability_test_users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT NOT NULL UNIQUE,
                    email TEXT NOT NULL,
                    score INTEGER DEFAULT 0,
                    last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS stability_test_activities (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    activity_type TEXT NOT NULL,
                    points INTEGER DEFAULT 0,
                    metadata TEXT,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES stability_test_users(id)
                )
            """)
            
            # å»ºç«‹ç´¢å¼•
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON stability_test_users(username)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_users_score ON stability_test_users(score)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_activities_user_id ON stability_test_activities(user_id)")
            await conn.execute("CREATE INDEX IF NOT EXISTS idx_activities_timestamp ON stability_test_activities(timestamp)")
            
            await conn.commit()
        
        # å¡«å……åŸºç¤æ•¸æ“š
        await self._populate_base_data(5000)  # 5000å€‹ç”¨æˆ¶
        
        logger.info("é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ç’°å¢ƒè¨­ç½®å®Œæˆ")
    
    async def _populate_base_data(self, num_users: int):
        """å¡«å……åŸºç¤æ¸¬è©¦æ•¸æ“š"""
        logger.info(f"å¡«å……åŸºç¤æ¸¬è©¦æ•¸æ“šï¼š{num_users} å€‹ç”¨æˆ¶")
        
        async with self.pool_manager.connection() as conn:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ•¸æ“š
            async with conn.execute("SELECT COUNT(*) as count FROM stability_test_users") as cursor:
                existing = await cursor.fetchone()
                if existing and existing['count'] >= num_users:
                    logger.info("åŸºç¤æ•¸æ“šå·²å­˜åœ¨ï¼Œè·³éå¡«å……")
                    return
            
            # æ‰¹é‡æ’å…¥ç”¨æˆ¶
            users_data = []
            for i in range(num_users):
                username = f"stable_user_{i:06d}"
                email = f"{username}@stability.test"
                score = random.randint(0, 10000)
                users_data.append((username, email, score))
            
            # åˆ†æ‰¹æ’å…¥é¿å…å–®æ¬¡æ“ä½œéå¤§
            batch_size = 500
            for i in range(0, len(users_data), batch_size):
                batch = users_data[i:i + batch_size]
                await conn.executemany("""
                    INSERT OR IGNORE INTO stability_test_users (username, email, score) 
                    VALUES (?, ?, ?)
                """, batch)
                
                if i % (batch_size * 5) == 0:  # æ¯2500å€‹ç”¨æˆ¶commitä¸€æ¬¡
                    await conn.commit()
                    logger.info(f"å·²æ’å…¥ {min(i + batch_size, len(users_data))} / {len(users_data)} ç”¨æˆ¶")
            
            await conn.commit()
        
        logger.info("åŸºç¤æ¸¬è©¦æ•¸æ“šå¡«å……å®Œæˆ")
    
    async def run_stability_test(
        self,
        duration_minutes: int = 30,
        base_workers: int = 10,
        peak_workers: int = 20,
        surge_interval_minutes: int = 5
    ):
        """
        é‹è¡Œé•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦
        
        Args:
            duration_minutes: æ¸¬è©¦ç¸½æ™‚é•·ï¼ˆåˆ†é˜ï¼‰
            base_workers: åŸºç¤å·¥ä½œè€…æ•¸é‡
            peak_workers: å³°å€¼å·¥ä½œè€…æ•¸é‡  
            surge_interval_minutes: å³°å€¼è² è¼‰é–“éš”ï¼ˆåˆ†é˜ï¼‰
        """
        logger.info(
            f"é–‹å§‹é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦ï¼šæŒçºŒ {duration_minutes} åˆ†é˜ï¼Œ"
            f"åŸºç¤è² è¼‰ {base_workers} å·¥ä½œè€…ï¼Œå³°å€¼è² è¼‰ {peak_workers} å·¥ä½œè€…"
        )
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        next_surge_time = start_time + (surge_interval_minutes * 60)
        
        phase_counter = 0
        
        while time.time() < end_time:
            current_time = time.time()
            elapsed_minutes = (current_time - start_time) / 60
            
            # æ±ºå®šç•¶å‰å·¥ä½œè€…æ•¸é‡
            if current_time >= next_surge_time:
                current_workers = peak_workers
                phase_name = f"peak_load_{phase_counter}"
                next_surge_time = current_time + (surge_interval_minutes * 60)
                test_duration = 60  # å³°å€¼æŒçºŒ1åˆ†é˜
                phase_counter += 1
            else:
                current_workers = base_workers
                phase_name = f"base_load_{int(elapsed_minutes)}"
                test_duration = min(60, (next_surge_time - current_time))
            
            logger.info(
                f"[{elapsed_minutes:.1f}åˆ†é˜] åŸ·è¡Œ {phase_name}ï¼š{current_workers} å·¥ä½œè€…ï¼Œ"
                f"æŒçºŒ {test_duration:.1f} ç§’"
            )
            
            # åŸ·è¡Œæ­¤éšæ®µçš„æ¸¬è©¦
            phase_results = await self._run_test_phase(
                phase_name, current_workers, test_duration
            )
            
            # è¨˜éŒ„åˆ°ç›£æ§ç³»çµ±
            self.monitor.record_operation_batch(
                successful_ops=phase_results['successful_operations'],
                failed_ops=phase_results['failed_operations'],
                response_times=phase_results['response_times'],
                concurrent_workers=current_workers,
                error_details=phase_results['error_types'],
                phase=phase_name
            )
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æå‰çµ‚æ­¢ï¼ˆé€£çºŒå¤±æ•—éå¤šï¼‰
            current_stats = self.monitor.get_current_stats()
            if current_stats['consecutive_failures'] >= 5:
                logger.error(
                    f"é€£çºŒå¤±æ•—éå¤š ({current_stats['consecutive_failures']})ï¼Œæå‰çµ‚æ­¢æ¸¬è©¦"
                )
                break
            
            # ç°¡çŸ­çš„ä¼‘æ¯é–“éš”
            await asyncio.sleep(2)
        
        total_duration = time.time() - start_time
        logger.info(f"é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦å®Œæˆï¼Œç¸½æŒçºŒæ™‚é–“ï¼š{total_duration / 60:.1f} åˆ†é˜")
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        test_config = {
            "test_type": "long_running_stability",
            "planned_duration_minutes": duration_minutes,
            "actual_duration_minutes": total_duration / 60,
            "base_workers": base_workers,
            "peak_workers": peak_workers,
            "surge_interval_minutes": surge_interval_minutes
        }
        
        final_report = self.reporter.generate_comprehensive_report(
            self.monitor, test_config, total_duration
        )
        
        return final_report
    
    async def _run_test_phase(self, phase_name: str, num_workers: int, duration_seconds: float):
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦éšæ®µ"""
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        # çµæœæ”¶é›†
        successful_operations = 0
        failed_operations = 0
        response_times = []
        error_types = {}
        
        async def stability_worker(worker_id: int):
            """ç©©å®šæ€§æ¸¬è©¦å·¥ä½œè€…"""
            nonlocal successful_operations, failed_operations, response_times, error_types
            
            worker_ops = 0
            while time.time() < end_time:
                operation_start = time.time()
                
                try:
                    # éš¨æ©Ÿé¸æ“‡æ“ä½œé¡å‹
                    operation_type = random.choices(
                        ['read_user', 'update_score', 'add_activity', 'complex_query'],
                        weights=[50, 20, 20, 10]  # 50% è®€å–ï¼Œ20% æ›´æ–°ï¼Œ20% æ’å…¥ï¼Œ10% è¤‡é›œæŸ¥è©¢
                    )[0]
                    
                    async with self.pool_manager.connection() as conn:
                        if operation_type == 'read_user':
                            # è®€å–ç”¨æˆ¶ä¿¡æ¯
                            user_id = random.randint(1, 5000)
                            async with conn.execute(
                                "SELECT * FROM stability_test_users WHERE id = ?", 
                                (user_id,)
                            ) as cursor:
                                result = await cursor.fetchone()
                        
                        elif operation_type == 'update_score':
                            # æ›´æ–°ç”¨æˆ¶åˆ†æ•¸
                            user_id = random.randint(1, 5000)
                            score_change = random.randint(-100, 100)
                            await conn.execute("""
                                UPDATE stability_test_users 
                                SET score = score + ?, last_active = CURRENT_TIMESTAMP 
                                WHERE id = ?
                            """, (score_change, user_id))
                            await conn.commit()
                        
                        elif operation_type == 'add_activity':
                            # æ·»åŠ æ´»å‹•è¨˜éŒ„
                            user_id = random.randint(1, 5000)
                            activity_type = random.choice(['login', 'view', 'click', 'purchase'])
                            points = random.randint(1, 50)
                            await conn.execute("""
                                INSERT INTO stability_test_activities 
                                (user_id, activity_type, points, metadata)
                                VALUES (?, ?, ?, ?)
                            """, (user_id, activity_type, points, f"worker_{worker_id}"))
                            await conn.commit()
                        
                        elif operation_type == 'complex_query':
                            # è¤‡é›œæŸ¥è©¢
                            async with conn.execute("""
                                SELECT u.id, u.username, u.score,
                                       COUNT(a.id) as activity_count,
                                       AVG(a.points) as avg_points,
                                       MAX(a.timestamp) as last_activity
                                FROM stability_test_users u
                                LEFT JOIN stability_test_activities a ON u.id = a.user_id
                                WHERE u.score > ?
                                GROUP BY u.id
                                ORDER BY u.score DESC
                                LIMIT 20
                            """, (random.randint(5000, 9000),)) as cursor:
                                results = await cursor.fetchall()
                    
                    successful_operations += 1
                    worker_ops += 1
                    operation_time = (time.time() - operation_start) * 1000
                    response_times.append(operation_time)
                
                except Exception as e:
                    failed_operations += 1
                    error_str = str(e)
                    error_type = "unknown_error"
                    
                    if "timeout" in error_str.lower():
                        error_type = "timeout"
                    elif "locked" in error_str.lower() or "busy" in error_str.lower():
                        error_type = "database_lock"
                    elif "connection" in error_str.lower():
                        error_type = "connection_error"
                    
                    if error_type not in error_types:
                        error_types[error_type] = 0
                    error_types[error_type] += 1
                    
                    logger.debug(f"Worker {worker_id} æ“ä½œå¤±æ•— ({error_type}): {e}")
                
                # å‹•æ…‹å»¶é²ï¼šåŸºç¤è² è¼‰æ™‚è¼ƒé•·å»¶é²ï¼Œå³°å€¼è² è¼‰æ™‚è¼ƒçŸ­å»¶é²
                if num_workers <= 10:
                    await asyncio.sleep(random.uniform(0.1, 0.3))  # åŸºç¤è² è¼‰
                else:
                    await asyncio.sleep(random.uniform(0.01, 0.1))  # å³°å€¼è² è¼‰
            
            logger.debug(f"Stability Worker {worker_id} å®Œæˆ {worker_ops} æ“ä½œ")
        
        # å•Ÿå‹•å·¥ä½œè€…
        tasks = [stability_worker(i) for i in range(num_workers)]
        await asyncio.gather(*tasks)
        
        return {
            'successful_operations': successful_operations,
            'failed_operations': failed_operations,
            'response_times': response_times,
            'error_types': error_types,
            'duration_seconds': time.time() - start_time
        }
    
    async def cleanup(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        if self.pool_manager:
            await self.pool_manager.stop()
        
        # æ¸…ç†è‡¨æ™‚è³‡æ–™åº«
        if hasattr(self, 'temp_db'):
            try:
                import os
                os.unlink(self.db_path)
                logger.info("è‡¨æ™‚æ¸¬è©¦è³‡æ–™åº«å·²æ¸…ç†")
            except OSError:
                logger.warning(f"ç„¡æ³•åˆªé™¤è‡¨æ™‚è³‡æ–™åº«æª”æ¡ˆï¼š{self.db_path}")


async def main():
    """ä¸»å‡½æ•¸ - åŸ·è¡Œé•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦"""
    logger.info("=" * 80)
    logger.info("ğŸƒâ€â™‚ï¸ T2 é•·æ™‚é–“é‹è¡Œç©©å®šæ€§æ¸¬è©¦")
    logger.info("=" * 80)
    
    stability_test = LongRunningStabilityTest()
    
    try:
        await stability_test.setup()
        
        # åŸ·è¡Œ30åˆ†é˜ç©©å®šæ€§æ¸¬è©¦
        # å°æ–¼æ¼”ç¤ºï¼Œæˆ‘å€‘ä½¿ç”¨è¼ƒçŸ­çš„æ™‚é–“ï¼ˆ3åˆ†é˜ï¼‰
        report = await stability_test.run_stability_test(
            duration_minutes=3,    # æ¼”ç¤ºç”¨3åˆ†é˜ï¼Œå¯¦éš›å¯è¨­ç‚º30-60åˆ†é˜
            base_workers=8,
            peak_workers=15,
            surge_interval_minutes=1  # æ¼”ç¤ºç”¨1åˆ†é˜é–“éš”
        )
        
        # é¡¯ç¤ºæ¸¬è©¦çµæœæ‘˜è¦
        logger.info("=" * 80)
        logger.info("ğŸ“Š é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦çµæœ")
        logger.info("=" * 80)
        
        exec_summary = report['executive_summary']
        t2_compliance = report['t2_compliance']
        
        logger.info(f"æ¸¬è©¦æŒçºŒæ™‚é–“ï¼š{report['report_metadata']['test_duration_seconds'] / 60:.1f} åˆ†é˜")
        logger.info(f"ç¸½æ“ä½œæ•¸ï¼š{exec_summary['total_operations']}")
        logger.info(f"æˆåŠŸæ“ä½œï¼š{exec_summary['successful_operations']}")
        logger.info(f"å¤±æ•—æ“ä½œï¼š{exec_summary['failed_operations']}")
        logger.info(f"æ•´é«”æˆåŠŸç‡ï¼š{exec_summary['overall_success_rate_percent']:.2f}%")
        logger.info(f"æ•´é«”éŒ¯èª¤ç‡ï¼š{exec_summary['overall_error_rate_percent']:.2f}%")
        logger.info(f"å¹³å‡ååé‡ï¼š{exec_summary['average_throughput_ops_per_sec']:.2f} ops/s")
        
        logger.info("\nğŸ¯ T2 æ¨™æº–åˆè¦æ€§ï¼š")
        logger.info(f"éŒ¯èª¤ç‡è¦æ±‚ï¼šâ‰¤ 1.0%ï¼Œå¯¦éš›ï¼š{t2_compliance['measured_performance']['actual_error_rate_percent']:.2f}%")
        logger.info(f"æˆåŠŸç‡è¦æ±‚ï¼šâ‰¥ 98%ï¼Œå¯¦éš›ï¼š{t2_compliance['measured_performance']['actual_success_rate_percent']:.2f}%")
        logger.info(f"éŸ¿æ‡‰æ™‚é–“ï¼šå¹³å‡ {t2_compliance['measured_performance']['average_response_time_ms']:.2f}ms")
        
        if t2_compliance['overall_t2_compliant']:
            logger.info("âœ… é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦é€šé T2 æ¨™æº–ï¼")
        else:
            logger.warning("âš ï¸ é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦æœªå®Œå…¨ç¬¦åˆ T2 æ¨™æº–")
        
        logger.info(f"åˆè¦åˆ†æ•¸ï¼š{t2_compliance['compliance_score']:.1f}/100")
        
        # é¡¯ç¤ºå»ºè­°
        if report['recommendations']:
            logger.info("\nğŸ’¡ å„ªåŒ–å»ºè­°ï¼š")
            for i, rec in enumerate(report['recommendations'][:3], 1):
                logger.info(f"  {i}. {rec}")
        
        return t2_compliance['overall_t2_compliant']
        
    except Exception as e:
        logger.error(f"é•·æ™‚é–“ç©©å®šæ€§æ¸¬è©¦å¤±æ•—ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        await stability_test.cleanup()


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)