#!/usr/bin/env python3
"""
ç›£æ§æ”¶é›†å™¨ - æ”¶é›†ç³»çµ±å’Œæœå‹™çš„ç›£æ§æ•¸æ“šï¼Œæä¾›å¯¦æ™‚ç‹€æ…‹å ±å‘Š
Task ID: 1 - ROAS Bot v2.4.3 Dockerå•Ÿå‹•ç³»çµ±ä¿®å¾©

é€™å€‹æ¨¡çµ„è² è²¬æ”¶é›†å’Œåˆ†æç³»çµ±ç›£æ§æŒ‡æ¨™ï¼ŒåŒ…æ‹¬æœå‹™å¥åº·ç‹€æ…‹ã€æ€§èƒ½æŒ‡æ¨™å’Œè³‡æºä½¿ç”¨æƒ…æ³ã€‚
"""

import asyncio
import json
import logging
import time
import subprocess
import psutil
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, Tuple
import sqlite3
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)


class HealthStatus(Enum):
    """å¥åº·ç‹€æ…‹æšèˆ‰"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"


@dataclass
class ServiceMetrics:
    """æœå‹™æŒ‡æ¨™"""
    service_name: str
    status: HealthStatus
    response_time_ms: Optional[float]
    cpu_usage_percent: Optional[float]
    memory_usage_mb: Optional[float]
    error_rate: Optional[float]
    last_check: datetime
    uptime_seconds: Optional[float] = None
    restart_count: int = 0
    last_error: Optional[str] = None


@dataclass
class SystemMetrics:
    """ç³»çµ±æŒ‡æ¨™"""
    timestamp: datetime
    cpu_usage_percent: float
    memory_usage_percent: float
    memory_available_gb: float
    disk_usage_percent: float
    disk_free_gb: float
    network_bytes_sent: int
    network_bytes_recv: int
    load_average: List[float]


@dataclass
class MonitoringReport:
    """ç›£æ§å ±å‘Š"""
    timestamp: datetime
    overall_status: HealthStatus
    system_metrics: SystemMetrics
    service_metrics: List[ServiceMetrics]
    alerts: List[str]
    recommendations: List[str]
    summary: Dict[str, Any]


class MonitoringCollector:
    """
    ç›£æ§æ”¶é›†å™¨ - æ”¶é›†ç³»çµ±å’Œæœå‹™çš„ç›£æ§æ•¸æ“šï¼Œæä¾›å¯¦æ™‚ç‹€æ…‹å ±å‘Š
    
    è² è²¬ï¼š
    - æ”¶é›†ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
    - ç›£æ§Dockerå®¹å™¨ç‹€æ…‹
    - æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
    - ç”Ÿæˆç›£æ§å ±å‘Šå’Œå‘Šè­¦
    - å­˜å„²æ­·å²ç›£æ§æ•¸æ“š
    """
    
    def __init__(self, project_root: Optional[Path] = None, db_path: Optional[Path] = None):
        self.project_root = project_root or Path.cwd()
        self.db_path = db_path or (self.project_root / 'data' / 'monitoring.db')
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # ç›£æ§é…ç½®
        self.check_interval = 30  # ç§’
        self.alert_thresholds = {
            'cpu_usage': 80.0,      # CPUä½¿ç”¨ç‡ %
            'memory_usage': 85.0,   # è¨˜æ†¶é«”ä½¿ç”¨ç‡ %
            'disk_usage': 90.0,     # ç£ç›˜ä½¿ç”¨ç‡ %
            'response_time': 5000,  # éŸ¿æ‡‰æ™‚é–“ ms
            'error_rate': 5.0       # éŒ¯èª¤ç‡ %
        }
        
        self._ensure_database()
    
    def _ensure_database(self) -> None:
        """ç¢ºä¿ç›£æ§è³‡æ–™åº«å­˜åœ¨ä¸¦åˆå§‹åŒ–"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(str(self.db_path)) as conn:
            # ç³»çµ±æŒ‡æ¨™è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS system_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    cpu_usage_percent REAL,
                    memory_usage_percent REAL,
                    memory_available_gb REAL,
                    disk_usage_percent REAL,
                    disk_free_gb REAL,
                    network_bytes_sent INTEGER,
                    network_bytes_recv INTEGER,
                    load_average_1m REAL,
                    load_average_5m REAL,
                    load_average_15m REAL
                )
            ''')
            
            # æœå‹™æŒ‡æ¨™è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS service_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    service_name TEXT NOT NULL,
                    status TEXT NOT NULL,
                    response_time_ms REAL,
                    cpu_usage_percent REAL,
                    memory_usage_mb REAL,
                    error_rate REAL,
                    uptime_seconds REAL,
                    restart_count INTEGER DEFAULT 0,
                    last_error TEXT
                )
            ''')
            
            # å‘Šè­¦è¨˜éŒ„è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    alert_type TEXT NOT NULL,
                    severity TEXT NOT NULL,
                    service_name TEXT,
                    message TEXT NOT NULL,
                    resolved BOOLEAN DEFAULT FALSE,
                    resolved_at DATETIME
                )
            ''')
            
            conn.commit()
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """
        æ”¶é›†å®Œæ•´çš„ç›£æ§æŒ‡æ¨™
        
        Returns:
            Dict[str, Any]: ç›£æ§æŒ‡æ¨™æ•¸æ“š
        """
        self.logger.debug("é–‹å§‹æ”¶é›†ç›£æ§æŒ‡æ¨™")
        
        try:
            # ä¸¦è¡Œæ”¶é›†ç³»çµ±å’Œæœå‹™æŒ‡æ¨™
            system_task = asyncio.create_task(self._collect_system_metrics())
            services_task = asyncio.create_task(self._collect_services_metrics())
            
            system_metrics, service_metrics = await asyncio.gather(
                system_task, services_task
            )
            
            # åˆ†ææ•´é«”å¥åº·ç‹€æ…‹
            overall_status = self._analyze_overall_status(system_metrics, service_metrics)
            
            # ç”Ÿæˆå‘Šè­¦
            alerts = self._generate_alerts(system_metrics, service_metrics)
            
            # ç”Ÿæˆå»ºè­°
            recommendations = self._generate_recommendations(system_metrics, service_metrics)
            
            # å­˜å„²æŒ‡æ¨™åˆ°è³‡æ–™åº«
            await self._store_metrics(system_metrics, service_metrics, alerts)
            
            # æ§‹å»ºçµæœ
            result = {
                'timestamp': datetime.now(),
                'overall_status': overall_status.value,
                'system_metrics': asdict(system_metrics),
                'service_metrics': [asdict(sm) for sm in service_metrics],
                'alerts': alerts,
                'recommendations': recommendations,
                'summary': {
                    'total_services': len(service_metrics),
                    'healthy_services': len([s for s in service_metrics if s.status == HealthStatus.HEALTHY]),
                    'degraded_services': len([s for s in service_metrics if s.status == HealthStatus.DEGRADED]),
                    'unhealthy_services': len([s for s in service_metrics if s.status == HealthStatus.UNHEALTHY]),
                    'system_load': system_metrics.load_average[0] if system_metrics.load_average else 0
                }
            }
            
            self.logger.info(f"ç›£æ§æŒ‡æ¨™æ”¶é›†å®Œæˆ: {result['summary']}")
            return result
            
        except Exception as e:
            self.logger.error(f"ç›£æ§æŒ‡æ¨™æ”¶é›†å¤±æ•—: {str(e)}", exc_info=True)
            return {
                'timestamp': datetime.now(),
                'error': str(e),
                'overall_status': HealthStatus.UNKNOWN.value
            }
    
    async def check_service_health(self, service: str) -> ServiceMetrics:
        """
        æª¢æŸ¥ç‰¹å®šæœå‹™çš„å¥åº·ç‹€æ…‹
        
        Args:
            service: æœå‹™åç¨±
            
        Returns:
            ServiceMetrics: æœå‹™å¥åº·ç‹€æ…‹æŒ‡æ¨™
        """
        self.logger.debug(f"æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹: {service}")
        
        start_time = time.time()
        
        try:
            # æª¢æŸ¥å®¹å™¨ç‹€æ…‹
            container_info = await self._get_container_info(service)
            
            if not container_info:
                return ServiceMetrics(
                    service_name=service,
                    status=HealthStatus.UNHEALTHY,
                    response_time_ms=None,
                    cpu_usage_percent=None,
                    memory_usage_mb=None,
                    error_rate=None,
                    last_check=datetime.now(),
                    last_error="å®¹å™¨ä¸å­˜åœ¨æˆ–æœªé‹è¡Œ"
                )
            
            # è¨ˆç®—éŸ¿æ‡‰æ™‚é–“
            response_time = (time.time() - start_time) * 1000
            
            # ç²å–å®¹å™¨è³‡æºä½¿ç”¨æƒ…æ³
            cpu_usage, memory_usage = await self._get_container_resources(container_info['container_id'])
            
            # åˆ¤æ–·å¥åº·ç‹€æ…‹
            status = HealthStatus.HEALTHY
            if container_info.get('health_status') == 'unhealthy':
                status = HealthStatus.UNHEALTHY
            elif container_info.get('state') != 'running':
                status = HealthStatus.UNHEALTHY
            elif cpu_usage and cpu_usage > self.alert_thresholds['cpu_usage']:
                status = HealthStatus.DEGRADED
            elif memory_usage and memory_usage > 1000:  # è¶…é1GBèªç‚ºç•°å¸¸
                status = HealthStatus.DEGRADED
            
            return ServiceMetrics(
                service_name=service,
                status=status,
                response_time_ms=response_time,
                cpu_usage_percent=cpu_usage,
                memory_usage_mb=memory_usage,
                error_rate=None,  # éœ€è¦å¾æ‡‰ç”¨æ—¥èªŒåˆ†æ
                last_check=datetime.now(),
                uptime_seconds=self._parse_uptime(container_info.get('status', ''))
            )
            
        except Exception as e:
            self.logger.error(f"æœå‹™ {service} å¥åº·æª¢æŸ¥å¤±æ•—: {str(e)}")
            return ServiceMetrics(
                service_name=service,
                status=HealthStatus.UNKNOWN,
                response_time_ms=None,
                cpu_usage_percent=None,
                memory_usage_mb=None,
                error_rate=None,
                last_check=datetime.now(),
                last_error=str(e)
            )
    
    async def generate_report(self) -> MonitoringReport:
        """
        ç”Ÿæˆç›£æ§å ±å‘Š
        
        Returns:
            MonitoringReport: å®Œæ•´çš„ç›£æ§å ±å‘Š
        """
        self.logger.info("ç”Ÿæˆç›£æ§å ±å‘Š")
        
        metrics_data = await self.collect_metrics()
        
        # è½‰æ›æ•¸æ“šæ ¼å¼
        system_metrics_data = metrics_data.get('system_metrics', {})
        system_metrics = SystemMetrics(
            timestamp=system_metrics_data.get('timestamp', datetime.now()),
            cpu_usage_percent=system_metrics_data.get('cpu_usage_percent', 0.0),
            memory_usage_percent=system_metrics_data.get('memory_usage_percent', 0.0),
            memory_available_gb=system_metrics_data.get('memory_available_gb', 0.0),
            disk_usage_percent=system_metrics_data.get('disk_usage_percent', 0.0),
            disk_free_gb=system_metrics_data.get('disk_free_gb', 0.0),
            network_bytes_sent=system_metrics_data.get('network_bytes_sent', 0),
            network_bytes_recv=system_metrics_data.get('network_bytes_recv', 0),
            load_average=system_metrics_data.get('load_average', [0, 0, 0])
        )
        
        service_metrics = []
        for sm_data in metrics_data.get('service_metrics', []):
            service_metrics.append(ServiceMetrics(
                service_name=sm_data.get('service_name', 'unknown'),
                status=HealthStatus(sm_data.get('status', 'unknown')),
                response_time_ms=sm_data.get('response_time_ms'),
                cpu_usage_percent=sm_data.get('cpu_usage_percent'),
                memory_usage_mb=sm_data.get('memory_usage_mb'),
                error_rate=sm_data.get('error_rate'),
                last_check=sm_data.get('last_check', datetime.now()),
                uptime_seconds=sm_data.get('uptime_seconds'),
                restart_count=sm_data.get('restart_count', 0),
                last_error=sm_data.get('last_error')
            ))
        
        return MonitoringReport(
            timestamp=metrics_data.get('timestamp', datetime.now()),
            overall_status=HealthStatus(metrics_data.get('overall_status', 'unknown')),
            system_metrics=system_metrics,
            service_metrics=service_metrics,
            alerts=metrics_data.get('alerts', []),
            recommendations=metrics_data.get('recommendations', []),
            summary=metrics_data.get('summary', {})
        )
    
    async def collect_startup_performance_metrics(self) -> Dict[str, Any]:
        """
        æ”¶é›†å•Ÿå‹•æ•ˆèƒ½å°ˆç”¨æŒ‡æ¨™
        
        Returns:
            Dict[str, Any]: å•Ÿå‹•æ•ˆèƒ½æŒ‡æ¨™
        """
        self.logger.debug("æ”¶é›†å•Ÿå‹•æ•ˆèƒ½æŒ‡æ¨™")
        
        try:
            startup_metrics = {
                'timestamp': datetime.now(),
                'docker_stats': await self._get_docker_startup_stats(),
                'container_ready_time': await self._measure_container_ready_time(),
                'resource_consumption': await self._get_startup_resource_consumption(),
                'health_check_performance': await self._analyze_health_check_performance(),
                'startup_bottlenecks': await self._identify_startup_bottlenecks()
            }
            
            return startup_metrics
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†å•Ÿå‹•æ•ˆèƒ½æŒ‡æ¨™å¤±æ•—: {str(e)}", exc_info=True)
            return {
                'timestamp': datetime.now(),
                'error': str(e)
            }
    
    async def _get_docker_startup_stats(self) -> Dict[str, Any]:
        """ç²å–Dockerå•Ÿå‹•çµ±è¨ˆ"""
        try:
            # ç²å–æ‰€æœ‰å®¹å™¨çš„å•Ÿå‹•æ™‚é–“
            result = subprocess.run(
                ['docker', 'ps', '--format', 'json'],
                capture_output=True, text=True, timeout=30
            )
            
            if result.returncode != 0:
                return {'error': 'Dockerå‘½ä»¤åŸ·è¡Œå¤±æ•—'}
            
            containers = []
            for line in result.stdout.strip().split('\n'):
                if line:
                    try:
                        container_info = json.loads(line)
                        containers.append({
                            'name': container_info.get('Names', ''),
                            'status': container_info.get('Status', ''),
                            'created': container_info.get('CreatedAt', ''),
                            'state': container_info.get('State', '')
                        })
                    except json.JSONDecodeError:
                        continue
            
            return {
                'total_containers': len(containers),
                'running_containers': len([c for c in containers if 'Up' in c.get('status', '')]),
                'containers': containers
            }
            
        except Exception as e:
            self.logger.error(f"ç²å–Dockerå•Ÿå‹•çµ±è¨ˆå¤±æ•—: {str(e)}")
            return {'error': str(e)}
    
    async def _measure_container_ready_time(self) -> Dict[str, Any]:
        """æ¸¬é‡å®¹å™¨å°±ç·’æ™‚é–“"""
        try:
            ready_times = {}
            
            # æª¢æŸ¥æ¯å€‹ä¸»è¦æœå‹™çš„å°±ç·’æ™‚é–“
            services = ['discord-bot', 'redis', 'prometheus', 'grafana']
            
            for service in services:
                start_time = time.time()
                container_info = await self._get_container_info(service)
                
                if container_info:
                    # ç°¡åŒ–çš„å°±ç·’æ™‚é–“æ¸¬é‡ï¼ˆå¯¦éš›æ‡‰è©²è§£æå®¹å™¨å•Ÿå‹•æ—¥èªŒï¼‰
                    ready_times[service] = {
                        'container_exists': True,
                        'state': container_info.get('state', 'unknown'),
                        'health_status': container_info.get('health_status', 'unknown'),
                        'check_duration_ms': (time.time() - start_time) * 1000
                    }
                else:
                    ready_times[service] = {
                        'container_exists': False,
                        'check_duration_ms': (time.time() - start_time) * 1000
                    }
            
            return ready_times
            
        except Exception as e:
            self.logger.error(f"æ¸¬é‡å®¹å™¨å°±ç·’æ™‚é–“å¤±æ•—: {str(e)}")
            return {'error': str(e)}
    
    async def _get_startup_resource_consumption(self) -> Dict[str, Any]:
        """ç²å–å•Ÿå‹•æœŸé–“è³‡æºæ¶ˆè€—"""
        try:
            # ç²å–ç•¶å‰ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
            cpu_usage = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage(str(self.project_root))
            
            # ç²å–Dockerå®¹å™¨è³‡æºä½¿ç”¨
            container_resources = []
            
            result = subprocess.run(
                ['docker', 'stats', '--no-stream', '--format', 'json'],
                capture_output=True, text=True, timeout=30
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        try:
                            stats = json.loads(line)
                            container_resources.append({
                                'name': stats.get('Name', ''),
                                'cpu_percent': stats.get('CPUPerc', '0%'),
                                'memory_usage': stats.get('MemUsage', '0B / 0B'),
                                'memory_percent': stats.get('MemPerc', '0%'),
                                'network_io': stats.get('NetIO', '0B / 0B'),
                                'block_io': stats.get('BlockIO', '0B / 0B')
                            })
                        except json.JSONDecodeError:
                            continue
            
            return {
                'system_cpu_percent': cpu_usage,
                'system_memory_percent': memory.percent,
                'system_memory_available_gb': memory.available / (1024**3),
                'system_disk_free_gb': disk.free / (1024**3),
                'container_resources': container_resources,
                'total_containers': len(container_resources)
            }
            
        except Exception as e:
            self.logger.error(f"ç²å–å•Ÿå‹•è³‡æºæ¶ˆè€—å¤±æ•—: {str(e)}")
            return {'error': str(e)}
    
    async def _analyze_health_check_performance(self) -> Dict[str, Any]:
        """åˆ†æå¥åº·æª¢æŸ¥æ•ˆèƒ½"""
        try:
            health_performance = {}
            services = ['discord-bot', 'redis', 'prometheus', 'grafana']
            
            for service in services:
                start_time = time.time()
                service_metrics = await self.check_service_health(service)
                check_duration = (time.time() - start_time) * 1000
                
                health_performance[service] = {
                    'status': service_metrics.status.value,
                    'response_time_ms': service_metrics.response_time_ms,
                    'health_check_duration_ms': check_duration,
                    'last_error': service_metrics.last_error,
                    'is_optimal': check_duration < 5000 and service_metrics.status == HealthStatus.HEALTHY
                }
            
            # è¨ˆç®—æ•´é«”å¥åº·æª¢æŸ¥æ•ˆèƒ½
            total_checks = len(health_performance)
            optimal_checks = sum(1 for perf in health_performance.values() if perf.get('is_optimal', False))
            
            return {
                'service_performance': health_performance,
                'overall_health_check_efficiency': (optimal_checks / total_checks) * 100 if total_checks > 0 else 0,
                'total_services_checked': total_checks,
                'optimal_services': optimal_checks
            }
            
        except Exception as e:
            self.logger.error(f"åˆ†æå¥åº·æª¢æŸ¥æ•ˆèƒ½å¤±æ•—: {str(e)}")
            return {'error': str(e)}
    
    async def _identify_startup_bottlenecks(self) -> Dict[str, Any]:
        """è­˜åˆ¥å•Ÿå‹•ç“¶é ¸"""
        try:
            bottlenecks = []
            
            # æª¢æŸ¥ç³»çµ±è³‡æºç“¶é ¸
            cpu_usage = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage(str(self.project_root))
            
            if cpu_usage > 80:
                bottlenecks.append({
                    'type': 'cpu',
                    'severity': 'high',
                    'description': f'CPUä½¿ç”¨ç‡éé«˜: {cpu_usage:.1f}%',
                    'recommendation': 'è€ƒæ…®å„ªåŒ–CPUå¯†é›†å‹æ“ä½œæˆ–å¢åŠ CPUè³‡æº'
                })
            
            if memory.percent > 85:
                bottlenecks.append({
                    'type': 'memory',
                    'severity': 'high', 
                    'description': f'è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {memory.percent:.1f}%',
                    'recommendation': 'æª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼æˆ–å¢åŠ è¨˜æ†¶é«”å®¹é‡'
                })
            
            if disk.free / (1024**3) < 2:
                bottlenecks.append({
                    'type': 'disk_space',
                    'severity': 'medium',
                    'description': f'ç£ç›¤ç©ºé–“ä¸è¶³: {disk.free / (1024**3):.1f}GB',
                    'recommendation': 'æ¸…ç†ç£ç›¤ç©ºé–“æˆ–æ“´å±•å­˜å„²'
                })
            
            # æª¢æŸ¥Dockerç›¸é—œç“¶é ¸
            try:
                result = subprocess.run(
                    ['docker', 'system', 'df'],
                    capture_output=True, text=True, timeout=30
                )
                
                if result.returncode == 0:
                    # è§£æDockerç©ºé–“ä½¿ç”¨æƒ…æ³ï¼ˆç°¡åŒ–è™•ç†ï¼‰
                    if 'reclaimable' in result.stdout.lower():
                        bottlenecks.append({
                            'type': 'docker_storage',
                            'severity': 'low',
                            'description': 'Dockerå­˜åœ¨å¯å›æ”¶ç©ºé–“',
                            'recommendation': 'åŸ·è¡Œ docker system prune æ¸…ç†æœªä½¿ç”¨è³‡æº'
                        })
            except Exception:
                pass
            
            # æª¢æŸ¥ç¶²è·¯ç›¸é—œç“¶é ¸
            try:
                import socket
                test_ports = [6379, 8000, 3000, 9090]
                port_issues = []
                
                for port in test_ports:
                    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                        result = s.connect_ex(('localhost', port))
                        if result == 0:
                            # ç«¯å£å·²è¢«ä½”ç”¨ä½†ä¸æ˜¯æˆ‘å€‘çš„æœå‹™
                            port_issues.append(port)
                
                if port_issues:
                    bottlenecks.append({
                        'type': 'port_conflict',
                        'severity': 'medium',
                        'description': f'ç«¯å£è¡çª: {port_issues}',
                        'recommendation': 'æª¢æŸ¥ä¸¦é—œé–‰ä½”ç”¨ç«¯å£çš„ç¨‹åº'
                    })
                    
            except Exception:
                pass
            
            return {
                'bottlenecks_found': len(bottlenecks),
                'bottlenecks': bottlenecks,
                'high_severity_count': len([b for b in bottlenecks if b['severity'] == 'high']),
                'medium_severity_count': len([b for b in bottlenecks if b['severity'] == 'medium']),
                'low_severity_count': len([b for b in bottlenecks if b['severity'] == 'low'])
            }
            
        except Exception as e:
            self.logger.error(f"è­˜åˆ¥å•Ÿå‹•ç“¶é ¸å¤±æ•—: {str(e)}")
            return {'error': str(e)}
    
    # === å…§éƒ¨æ–¹æ³• ===
    
    async def _collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_usage = psutil.cpu_percent(interval=1)
            
            # è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            memory = psutil.virtual_memory()
            memory_usage_percent = memory.percent
            memory_available_gb = memory.available / (1024**3)
            
            # ç£ç›¤ä½¿ç”¨æƒ…æ³
            disk = psutil.disk_usage(str(self.project_root))
            disk_usage_percent = (disk.used / disk.total) * 100
            disk_free_gb = disk.free / (1024**3)
            
            # ç¶²è·¯ä½¿ç”¨æƒ…æ³
            network = psutil.net_io_counters()
            network_bytes_sent = network.bytes_sent
            network_bytes_recv = network.bytes_recv
            
            # ç³»çµ±è² è¼‰
            try:
                load_average = list(psutil.getloadavg())
            except (AttributeError, OSError):
                # Windowsä¸æ”¯æ´getloadavg
                load_average = [0.0, 0.0, 0.0]
            
            return SystemMetrics(
                timestamp=datetime.now(),
                cpu_usage_percent=cpu_usage,
                memory_usage_percent=memory_usage_percent,
                memory_available_gb=memory_available_gb,
                disk_usage_percent=disk_usage_percent,
                disk_free_gb=disk_free_gb,
                network_bytes_sent=network_bytes_sent,
                network_bytes_recv=network_bytes_recv,
                load_average=load_average
            )
            
        except Exception as e:
            self.logger.error(f"ç³»çµ±æŒ‡æ¨™æ”¶é›†å¤±æ•—: {str(e)}")
            return SystemMetrics(
                timestamp=datetime.now(),
                cpu_usage_percent=0.0,
                memory_usage_percent=0.0,
                memory_available_gb=0.0,
                disk_usage_percent=0.0,
                disk_free_gb=0.0,
                network_bytes_sent=0,
                network_bytes_recv=0,
                load_average=[0.0, 0.0, 0.0]
            )
    
    async def _collect_services_metrics(self) -> List[ServiceMetrics]:
        """æ”¶é›†æœå‹™æŒ‡æ¨™"""
        services = ['discord-bot', 'redis', 'prometheus', 'grafana']  # ä¸»è¦æœå‹™
        service_metrics = []
        
        # ä¸¦è¡Œæª¢æŸ¥æ‰€æœ‰æœå‹™
        tasks = [self.check_service_health(service) for service in services]
        service_metrics = await asyncio.gather(*tasks, return_exceptions=True)
        
        # éæ¿¾ç•°å¸¸çµæœ
        valid_metrics = []
        for metric in service_metrics:
            if isinstance(metric, ServiceMetrics):
                valid_metrics.append(metric)
            else:
                self.logger.warning(f"æœå‹™æŒ‡æ¨™æ”¶é›†ç•°å¸¸: {metric}")
        
        return valid_metrics
    
    async def _get_container_info(self, service_name: str) -> Optional[Dict[str, Any]]:
        """ç²å–å®¹å™¨è³‡è¨Š"""
        try:
            # ä½¿ç”¨docker compose psç²å–å®¹å™¨è³‡è¨Š
            result = subprocess.run(
                ['docker', 'compose', 'ps', '--format', 'json', service_name],
                capture_output=True, text=True, timeout=10,
                cwd=self.project_root
            )
            
            if result.returncode != 0:
                return None
            
            for line in result.stdout.strip().split('\n'):
                if line:
                    try:
                        container_data = json.loads(line)
                        if container_data.get('Service') == service_name:
                            return {
                                'container_id': container_data.get('ID'),
                                'name': container_data.get('Name'),
                                'state': container_data.get('State'),
                                'health_status': container_data.get('Health'),
                                'status': container_data.get('Status'),
                                'ports': container_data.get('Publishers', [])
                            }
                    except json.JSONDecodeError:
                        continue
            
            return None
            
        except Exception as e:
            self.logger.error(f"ç²å–å®¹å™¨è³‡è¨Šå¤±æ•—: {service_name}, {str(e)}")
            return None
    
    async def _get_container_resources(self, container_id: str) -> Tuple[Optional[float], Optional[float]]:
        """ç²å–å®¹å™¨è³‡æºä½¿ç”¨æƒ…æ³"""
        try:
            result = subprocess.run(
                ['docker', 'stats', '--no-stream', '--format', 'json', container_id],
                capture_output=True, text=True, timeout=10
            )
            
            if result.returncode != 0:
                return None, None
            
            stats_data = json.loads(result.stdout.strip())
            
            # è§£æCPUä½¿ç”¨ç‡
            cpu_percent_str = stats_data.get('CPUPerc', '0%').rstrip('%')
            try:
                cpu_usage = float(cpu_percent_str)
            except ValueError:
                cpu_usage = None
            
            # è§£æè¨˜æ†¶é«”ä½¿ç”¨é‡
            memory_usage_str = stats_data.get('MemUsage', '0B / 0B')
            try:
                used_memory = memory_usage_str.split(' / ')[0]
                if used_memory.endswith('MiB'):
                    memory_usage = float(used_memory[:-3])
                elif used_memory.endswith('GiB'):
                    memory_usage = float(used_memory[:-3]) * 1024
                elif used_memory.endswith('KiB'):
                    memory_usage = float(used_memory[:-3]) / 1024
                else:
                    memory_usage = None
            except (ValueError, IndexError):
                memory_usage = None
            
            return cpu_usage, memory_usage
            
        except Exception as e:
            self.logger.error(f"ç²å–å®¹å™¨è³‡æºä½¿ç”¨æƒ…æ³å¤±æ•—: {container_id}, {str(e)}")
            return None, None
    
    def _parse_uptime(self, status: str) -> Optional[float]:
        """è§£æå®¹å™¨é‹è¡Œæ™‚é–“"""
        try:
            # ç°¡å–®è§£æDockerç‹€æ…‹å­—ç¬¦ä¸²ä¸­çš„é‹è¡Œæ™‚é–“
            # ä¾‹å¦‚: "Up 2 hours", "Up 30 minutes", "Up 5 seconds"
            if 'Up' in status:
                parts = status.lower().split('up')[1].strip()
                # é€™è£¡éœ€è¦æ›´è¤‡é›œçš„è§£æé‚è¼¯
                # ç°¡åŒ–è™•ç†ï¼Œè¿”å›None
                return None
            return None
        except Exception:
            return None
    
    def _analyze_overall_status(self, system_metrics: SystemMetrics, 
                               service_metrics: List[ServiceMetrics]) -> HealthStatus:
        """åˆ†ææ•´é«”å¥åº·ç‹€æ…‹"""
        # æª¢æŸ¥ç³»çµ±æŒ‡æ¨™
        if (system_metrics.cpu_usage_percent > self.alert_thresholds['cpu_usage'] or
            system_metrics.memory_usage_percent > self.alert_thresholds['memory_usage'] or
            system_metrics.disk_usage_percent > self.alert_thresholds['disk_usage']):
            return HealthStatus.DEGRADED
        
        # æª¢æŸ¥æœå‹™ç‹€æ…‹
        unhealthy_services = [s for s in service_metrics if s.status == HealthStatus.UNHEALTHY]
        degraded_services = [s for s in service_metrics if s.status == HealthStatus.DEGRADED]
        
        if unhealthy_services:
            return HealthStatus.UNHEALTHY
        elif degraded_services:
            return HealthStatus.DEGRADED
        else:
            return HealthStatus.HEALTHY
    
    def _generate_alerts(self, system_metrics: SystemMetrics, 
                        service_metrics: List[ServiceMetrics]) -> List[str]:
        """ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        
        # ç³»çµ±å‘Šè­¦
        if system_metrics.cpu_usage_percent > self.alert_thresholds['cpu_usage']:
            alerts.append(f"CPUä½¿ç”¨ç‡éé«˜: {system_metrics.cpu_usage_percent:.1f}%")
        
        if system_metrics.memory_usage_percent > self.alert_thresholds['memory_usage']:
            alerts.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {system_metrics.memory_usage_percent:.1f}%")
        
        if system_metrics.disk_usage_percent > self.alert_thresholds['disk_usage']:
            alerts.append(f"ç£ç›¤ä½¿ç”¨ç‡éé«˜: {system_metrics.disk_usage_percent:.1f}%")
        
        # æœå‹™å‘Šè­¦
        for service in service_metrics:
            if service.status == HealthStatus.UNHEALTHY:
                alerts.append(f"æœå‹™ä¸å¥åº·: {service.service_name}")
            elif service.status == HealthStatus.DEGRADED:
                alerts.append(f"æœå‹™æ€§èƒ½ä¸‹é™: {service.service_name}")
            
            if service.response_time_ms and service.response_time_ms > self.alert_thresholds['response_time']:
                alerts.append(f"æœå‹™éŸ¿æ‡‰æ…¢: {service.service_name} ({service.response_time_ms:.0f}ms)")
        
        return alerts
    
    def _generate_recommendations(self, system_metrics: SystemMetrics, 
                                service_metrics: List[ServiceMetrics]) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        # ç³»çµ±å„ªåŒ–å»ºè­°
        if system_metrics.cpu_usage_percent > 70:
            recommendations.append("è€ƒæ…®å„ªåŒ–CPUå¯†é›†å‹æ“ä½œæˆ–å¢åŠ CPUè³‡æº")
        
        if system_metrics.memory_usage_percent > 80:
            recommendations.append("å»ºè­°æª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼æˆ–å¢åŠ è¨˜æ†¶é«”")
        
        if system_metrics.disk_free_gb < 5:
            recommendations.append("å»ºè­°æ¸…ç†ç£ç›¤ç©ºé–“æˆ–æ“´å±•å­˜å„²")
        
        # æœå‹™å„ªåŒ–å»ºè­°
        for service in service_metrics:
            if service.cpu_usage_percent and service.cpu_usage_percent > 50:
                recommendations.append(f"æœå‹™ {service.service_name} CPUä½¿ç”¨ç‡è¼ƒé«˜ï¼Œè€ƒæ…®å„ªåŒ–")
            
            if service.memory_usage_mb and service.memory_usage_mb > 500:
                recommendations.append(f"æœå‹™ {service.service_name} è¨˜æ†¶é«”ä½¿ç”¨è¼ƒå¤šï¼Œæª¢æŸ¥æ˜¯å¦æ­£å¸¸")
        
        return recommendations
    
    async def _store_metrics(self, system_metrics: SystemMetrics, 
                           service_metrics: List[ServiceMetrics], 
                           alerts: List[str]) -> None:
        """å­˜å„²æŒ‡æ¨™åˆ°è³‡æ–™åº«"""
        try:
            with sqlite3.connect(str(self.db_path)) as conn:
                # å­˜å„²ç³»çµ±æŒ‡æ¨™
                conn.execute('''
                    INSERT INTO system_metrics (
                        cpu_usage_percent, memory_usage_percent, memory_available_gb,
                        disk_usage_percent, disk_free_gb, network_bytes_sent, network_bytes_recv,
                        load_average_1m, load_average_5m, load_average_15m
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    system_metrics.cpu_usage_percent,
                    system_metrics.memory_usage_percent,
                    system_metrics.memory_available_gb,
                    system_metrics.disk_usage_percent,
                    system_metrics.disk_free_gb,
                    system_metrics.network_bytes_sent,
                    system_metrics.network_bytes_recv,
                    system_metrics.load_average[0],
                    system_metrics.load_average[1],
                    system_metrics.load_average[2]
                ))
                
                # å­˜å„²æœå‹™æŒ‡æ¨™
                for service in service_metrics:
                    conn.execute('''
                        INSERT INTO service_metrics (
                            service_name, status, response_time_ms, cpu_usage_percent,
                            memory_usage_mb, error_rate, uptime_seconds, restart_count, last_error
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        service.service_name,
                        service.status.value,
                        service.response_time_ms,
                        service.cpu_usage_percent,
                        service.memory_usage_mb,
                        service.error_rate,
                        service.uptime_seconds,
                        service.restart_count,
                        service.last_error
                    ))
                
                # å­˜å„²å‘Šè­¦
                for alert in alerts:
                    conn.execute('''
                        INSERT INTO alerts (alert_type, severity, message)
                        VALUES (?, ?, ?)
                    ''', ('system', 'warning', alert))
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"å­˜å„²æŒ‡æ¨™å¤±æ•—: {str(e)}")


# å·¥å…·å‡½æ•¸
async def quick_health_check() -> Dict[str, Any]:
    """å¿«é€Ÿå¥åº·æª¢æŸ¥"""
    collector = MonitoringCollector()
    return await collector.collect_metrics()


# å‘½ä»¤è¡Œä»‹é¢
async def main():
    """ä¸»å‡½æ•¸ - ç”¨æ–¼ç¨ç«‹åŸ·è¡Œç›£æ§æ”¶é›†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ROAS Bot ç›£æ§æ”¶é›†å·¥å…·')
    parser.add_argument('command', choices=['collect', 'report', 'health', 'startup-perf'],
                       help='åŸ·è¡Œçš„å‘½ä»¤')
    parser.add_argument('--service', '-s', help='æŒ‡å®šæœå‹™åç¨±ï¼ˆåƒ…ç”¨æ–¼healthå‘½ä»¤ï¼‰')
    parser.add_argument('--output', '-o', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')
    
    args = parser.parse_args()
    
    # è¨­ç½®æ—¥èªŒ
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # å‰µå»ºç›£æ§æ”¶é›†å™¨
    collector = MonitoringCollector()
    
    try:
        if args.command == 'collect':
            metrics = await collector.collect_metrics()
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(metrics, f, indent=2, ensure_ascii=False, default=str)
                print(f"ç›£æ§æ•¸æ“šå·²ä¿å­˜åˆ°: {args.output}")
            else:
                print(json.dumps(metrics, indent=2, ensure_ascii=False, default=str))
            return 0
            
        elif args.command == 'report':
            report = await collector.generate_report()
            print(f"\n{'='*60}")
            print("ğŸ” ROAS Bot v2.4.3 ç›£æ§å ±å‘Š")
            print(f"{'='*60}")
            print(f"å ±å‘Šæ™‚é–“: {report.timestamp}")
            print(f"æ•´é«”ç‹€æ…‹: {report.overall_status.value.upper()}")
            print(f"\nç³»çµ±æŒ‡æ¨™:")
            print(f"  CPUä½¿ç”¨ç‡: {report.system_metrics.cpu_usage_percent:.1f}%")
            print(f"  è¨˜æ†¶é«”ä½¿ç”¨ç‡: {report.system_metrics.memory_usage_percent:.1f}%")
            print(f"  ç£ç›¤ä½¿ç”¨ç‡: {report.system_metrics.disk_usage_percent:.1f}%")
            print(f"\næœå‹™ç‹€æ…‹:")
            for service in report.service_metrics:
                status_icon = {'healthy': 'âœ…', 'degraded': 'âš ï¸', 'unhealthy': 'âŒ', 'unknown': 'â“'}
                icon = status_icon.get(service.status.value, 'â“')
                print(f"  {icon} {service.service_name}: {service.status.value}")
            
            if report.alerts:
                print(f"\nâš ï¸ å‘Šè­¦:")
                for alert in report.alerts:
                    print(f"  â€¢ {alert}")
            
            if report.recommendations:
                print(f"\nğŸ’¡ å»ºè­°:")
                for rec in report.recommendations:
                    print(f"  â€¢ {rec}")
            
            return 0 if report.overall_status == HealthStatus.HEALTHY else 1
            
        elif args.command == 'health':
            if args.service:
                metrics = await collector.check_service_health(args.service)
                status_icon = {'healthy': 'âœ…', 'degraded': 'âš ï¸', 'unhealthy': 'âŒ', 'unknown': 'â“'}
                icon = status_icon.get(metrics.status.value, 'â“')
                print(f"{icon} {args.service}: {metrics.status.value}")
                if metrics.response_time_ms:
                    print(f"   éŸ¿æ‡‰æ™‚é–“: {metrics.response_time_ms:.0f}ms")
                if metrics.cpu_usage_percent:
                    print(f"   CPUä½¿ç”¨ç‡: {metrics.cpu_usage_percent:.1f}%")
                if metrics.memory_usage_mb:
                    print(f"   è¨˜æ†¶é«”ä½¿ç”¨: {metrics.memory_usage_mb:.0f}MB")
                if metrics.last_error:
                    print(f"   éŒ¯èª¤è¨Šæ¯: {metrics.last_error}")
            else:
                metrics = await collector.collect_metrics()
                print(f"æ•´é«”ç‹€æ…‹: {metrics['overall_status'].upper()}")
                for service_data in metrics.get('service_metrics', []):
                    status_icon = {'healthy': 'âœ…', 'degraded': 'âš ï¸', 'unhealthy': 'âŒ', 'unknown': 'â“'}
                    icon = status_icon.get(service_data['status'], 'â“')
                    print(f"  {icon} {service_data['service_name']}: {service_data['status']}")
            
            return 0
            
        elif args.command == 'startup-perf':
            startup_metrics = await collector.collect_startup_performance_metrics()
            
            print(f"\n{'='*60}")
            print("ğŸš€ ROAS Bot v2.4.3 å•Ÿå‹•æ•ˆèƒ½å ±å‘Š")
            print(f"{'='*60}")
            print(f"å ±å‘Šæ™‚é–“: {startup_metrics.get('timestamp', 'Unknown')}")
            
            # Dockerçµ±è¨ˆ
            docker_stats = startup_metrics.get('docker_stats', {})
            if 'error' not in docker_stats:
                print(f"\nğŸ³ Dockerçµ±è¨ˆ:")
                print(f"  ç¸½å®¹å™¨æ•¸: {docker_stats.get('total_containers', 0)}")
                print(f"  é‹è¡Œä¸­å®¹å™¨: {docker_stats.get('running_containers', 0)}")
            
            # è³‡æºæ¶ˆè€—
            resource_consumption = startup_metrics.get('resource_consumption', {})
            if 'error' not in resource_consumption:
                print(f"\nğŸ’¾ è³‡æºä½¿ç”¨:")
                print(f"  ç³»çµ±CPU: {resource_consumption.get('system_cpu_percent', 0):.1f}%")
                print(f"  ç³»çµ±è¨˜æ†¶é«”: {resource_consumption.get('system_memory_percent', 0):.1f}%")
                print(f"  å¯ç”¨è¨˜æ†¶é«”: {resource_consumption.get('system_memory_available_gb', 0):.1f}GB")
                print(f"  å¯ç”¨ç£ç›¤: {resource_consumption.get('system_disk_free_gb', 0):.1f}GB")
                print(f"  å®¹å™¨ç¸½æ•¸: {resource_consumption.get('total_containers', 0)}")
            
            # å¥åº·æª¢æŸ¥æ•ˆèƒ½
            health_perf = startup_metrics.get('health_check_performance', {})
            if 'error' not in health_perf:
                print(f"\nğŸ¥ å¥åº·æª¢æŸ¥æ•ˆèƒ½:")
                print(f"  æ•´é«”æ•ˆç‡: {health_perf.get('overall_health_check_efficiency', 0):.1f}%")
                print(f"  æœ€ä½³æœå‹™: {health_perf.get('optimal_services', 0)}/{health_perf.get('total_services_checked', 0)}")
                
                service_perf = health_perf.get('service_performance', {})
                for service, perf in service_perf.items():
                    status_icon = 'âœ…' if perf.get('is_optimal', False) else 'âš ï¸'
                    print(f"  {status_icon} {service}: {perf.get('status', 'unknown')} ({perf.get('health_check_duration_ms', 0):.0f}ms)")
            
            # ç“¶é ¸åˆ†æ
            bottlenecks = startup_metrics.get('startup_bottlenecks', {})
            if 'error' not in bottlenecks:
                bottleneck_count = bottlenecks.get('bottlenecks_found', 0)
                print(f"\nğŸ” ç“¶é ¸åˆ†æ:")
                print(f"  ç™¼ç¾ç“¶é ¸: {bottleneck_count}å€‹")
                print(f"  é«˜åš´é‡æ€§: {bottlenecks.get('high_severity_count', 0)}")
                print(f"  ä¸­åš´é‡æ€§: {bottlenecks.get('medium_severity_count', 0)}")
                print(f"  ä½åš´é‡æ€§: {bottlenecks.get('low_severity_count', 0)}")
                
                if bottleneck_count > 0:
                    print(f"\nâš ï¸ ç™¼ç¾çš„ç“¶é ¸:")
                    for bottleneck in bottlenecks.get('bottlenecks', [])[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                        severity_icon = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸ”µ'}
                        icon = severity_icon.get(bottleneck.get('severity', 'low'), 'âšª')
                        print(f"  {icon} {bottleneck.get('description', 'Unknown issue')}")
                        print(f"     å»ºè­°: {bottleneck.get('recommendation', 'No recommendation')}")
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(startup_metrics, f, indent=2, ensure_ascii=False, default=str)
                print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜: {args.output}")
            
            return 0
            
    except KeyboardInterrupt:
        print("\næ“ä½œå·²å–æ¶ˆ")
        return 130
    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {str(e)}")
        return 1


if __name__ == '__main__':
    import sys
    sys.exit(asyncio.run(main()))